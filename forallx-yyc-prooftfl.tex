%!TEX root = forallxyyc.tex
\part{Dedução Natural para a LVF}
\label{ch.NDTFL}
\addtocontents{toc}{\protect\mbox{}\protect\hrulefill\par}

 
%%%%%% ----------------------------- CAPITULO: A ideia de dedução natural  --------------------------------------------------  
\chapter{A ideia de dedução natural}\label{s:NDVeryIdea}

No  Capítulo  \ref{s:Valid}, dissemos que um argumento é válido se e somente se não existe nenhuma situação na qual todas as premissas são verdadeiras e a conclusão é falsa. Posteriormente,  apresentamos as tabelas de verdade para as sentenças da LVF, onde  cada linha de uma tabela completa corresponde a uma valoração. E vimos que uma tabela de verdade conjunta para todas as sentenças de um argumento fornece um modo direto de verificar se ele é válido ou não: basta examinar se existe alguma linha na qual as premissas são todas verdadeiras e a conclusão é falsa.

Entretanto, tabelas de verdade não nos dão necessariamente muito \emph{insight}. Considere os dois seguintes argumentos na LVF:
\begin{align*}
P \eor Q, \enot P & \therefore Q\\
P \eif Q, P & \therefore Q
\end{align*}

Claramente, esses argumentos são válidos. Você  pode verificar que eles são válidos construindo tabelas de verdade de quatro linhas, mas podemos dizer que eles fazem uso de diferentes \emph{formas}  de raciocínio. Seria bom ter controle dessas diferentes \emph{formas}  de inferência.

Um dos objetivos de um \emph{sistema em dedução natural} é de mostrar que argumentos particulares são  válidos de um modo que nos permita entender o raciocínio que os argumentos possam envolver.  De fato, a ideia é que a partir de uma pequena quantidade de regras de inferência bem básicas consigamos capturar todos os argumentos válidos.
\emph{Essa é uma maneira muito diferente de pensar sobre argumentos.} 

Apesar de funcionarem como um método seguro para decidir sobre a validade, as tabelas de verdade não nos ajudam a entender o raciocínio por trás dos argumentos válidos. Elas simplesmente explicitam de um modo bem organizado todas as diferentes circunstâncias nas quais as sentenças de um argumento são verdadeiras ou falsas. É necessário um exame exaustivo destas circunstâncias (todas as linhas da tabela) para decidir se o argumento é ou não válido.

Os sistemas de dedução natural, por sua vez, propiciam um método de verificação da validade de argumentos que nos aproxima de um entendimento de quais são os raciocínios que dão suporte aos argumentos válidos.
Parte-se de um conjunto de regras de inferência previamente reconhecidas como boas e usa-se estas regras como um estoque de mini-raciocínios que podem ser aplicados nas premissas do argumento para passo a passo obter sua conclusão.

A mudança para dedução natural pode ser motivada por mais do que uma simples busca por discernimento. Ela pode ser motivada por \emph{necessidade}. Considere o seguinte argumento:
$$A_1 \eif C_1 \therefore (A_1 \eand A_2 \eand A_3 \eand A_4 \eand A_5) \eif (C_1 \eor C_2 \eor C_3 \eor C_4 \eor C_5)$$
Para verificar a validade deste argumento, você   pode usar uma tabela de verdade com 1024 linhas. Se você fizer isto corretamente, então você verá que  não existe nenhuma linha na qual todas as premissas são verdadeiras e a conclusão seja falsa.  Assim, você saberá que o argumento é válido (como já mencionamos antes, existe um sentido no qual você não saberá por que o argumento é válido). Mas agora considere: 
\begin{align*}
A_1 \eif C_1 \therefore\ & (A_1 \eand A_2 \eand A_3 \eand A_4 \eand A_5 \eand A_6 \eand A_7 \eand A_8 \eand A_9 \eand A_{10}) \eif \phantom{(}\\
&(C_1 \eor C_2 \eor C_3 \eor C_4 \eor C_5 \eor C_6 \eor C_7 \eor C_8 \eor C_9 \eor C_{10})
\end{align*}
Este argumento também é válido---você pode provavelmente dizer---mas para testá-lo é preciso uma tabela de verdade com
 $2^{20} = 1.048.576$ linhas. Podemos, em princpipio, programar um computador para gerar tabelas de verdade e nos avisar quando o processo terminar. Mas o crescimento exponencial das tabelas de verdade é um desafio até mesmo para os computadores. O que ocorre na prática é que argumentos mais complexos na LVF são \emph{intratáveis} via tabelas de verdade. 
 
%Quando chegarmos à lógica de primeira ordem (LPO) (início do capítulo   \ref{s:FOLBuildingBlocks}),   o problema torna-se dramaticamente pior.  Não existe nada como teste de tabela de verdade para a LPO.  Para assegurar se um argumento é válido ou não,  temos que raciocinar sobre  \emph{todas}   as interpretações,  mas, como vimos no Capítulo \ref{s:InfinitInterpret}, existem  infinitas interpretações  possíveis.

No caso da lógica de primeira ordem (LPO), este problema é ainda pior, porque não existe um teste como o das tabelas de verdade e, conforme vimos no Capítulo \ref{s:InfinitInterpret}, para decidir se um argumento é válido precisamos raciocinar sobre uma quantidade infinita de interpretações possíveis.
Não dará certo programarmos um computador para gerar e avaliar as infinitas interpretações possíveis, porque mesmo o computador mais rápido do mundo precisaria de um tempo infinito para fazer isso. 

Temos então que fazer algo diferente: podemos tentar métodos heurísticos eficientes para lidar com ``todas'' as interpretações possíveis, como fizeram Evert Beth e Jaakko Hintikka, na década de 1950;  ou podemos tentar algo novo, um modo de avaliar argumentos que não usa interpretações.
É este segundo caminho que seguiremos aqui através dos sistemas de dedução natural.
 
No caso da LVF, ao invés de raciocinar diretamente sobre todas as valorações tentaremos selecionar algumas poucas regras básicas de inferência.  Algumas dessas regras  irão governar o comportamento dos conectivos sentenciais. Outras irão governar o comportamento dos quantificadores e identidade que são marcas da LPO.  
O sistema resultante de regras nos dará um novo modo de pensar sobre a validade de argumentos.  O desenvolvimento moderno de dedução natural ocorreu de modo simultâneo e independente nos artigos de Gerhard Gentzen e Stanis\l{}aw Ja\'{s}kowski de 1934.  Entretanto, o sistema de dedução natural que vamos usar  será  baseado largamente nos trabalhos de Frederic Fitch (publicado pela primeira vez em 1952). 

 %%%%%% --------------------------------   CAPITULO  27 ----------------------------------------------
\chapter{As regras básicas da LVF}\label{s:BasicTFL}

 

Neste capítulo,  apresentaremos um sistema em  \define{natural deduction} para a LVF. Para cada conectivo, teremos  \definepl{introduction rule},  que nos permitem provar uma sentença que tenha esse conectivo como operador lógico principal, e \definepl{elimination rule}, que nos permitem provar algo a partir de uma sentença que tenha esse conectivo como operador lógico principal. 

 %%%%%% --------------------------------  Seção: A  ideia de uma prova formal

\section{A  ideia de uma prova formal}
 

O objetivo dos sistemas de dedução natural é a construção de provas formais que funcionam como comprovação da validade dos argumentos. Ou seja, a ideia é que todo argumento válido tenha uma prova formal que comprova sua validade. Uma \emph{prova formal} é uma sequência de sentenças que começa com as premissas do argumento, que são as suposições iniciais da prova, e termina com a conclusão do argumento na última linha. Usaremos as expressões `provas' e `provas formais' como sinônimas, mas saiba que existem provas informais também, que não estudaremos aqui.

Como uma ilustração, considere o seguinte argumento: 
 
	$$\enot (A \eor B) \therefore \enot A \eand \enot B$$
Os primeiros elementos de qualquer prova sempre são as premissas do argumento. Neste caso escrevemos: 
\begin{fitchproof}
	\hypo{a1}{\enot (A \eor B)}
\end{fitchproof}
 
Note que numeramos a premissa, pois queremos nos referir  a ela depois. De fato, cada  linha  ao longo da prova  é numerada, assim poderemos sempre nos referir a ela novamente. 

 Note também que traçamos  uma linha sob a  premissa. Tudo que está escrito acima da linha é uma 
\emph{suposição}. Tudo o que está escrito abaixo dessa linha é algo que segue das suposições ou é uma nova suposição. No nosso exemplo, desejamos concluir 
 `$\enot A \eand \enot B$';  então esperamos por fim concluir nossa prova com
\begin{fitchproof}
	\have[n]{con}{\enot A \eand \enot B}
\end{fitchproof}
para algum número $n$. Não importa em que número de linha a prova termina, mas obviamente preferimos uma prova mais curta. 

Suponha agora que queremos comprovar a validade do seguinte argumento:
$$A\eor B, \enot (A\eand C), \enot (B \eand \enot D) \therefore \enot C\eor D$$
Esse argumento tem três premissas, então  começaremos escrevendo as premissas uma abaixo da outra, numeradas, e trançamos uma linha sob elas: 
\begin{fitchproof}
	\hypo{a1}{A \eor B}
	\hypo{a2}{\enot (A\eand C)}
	\hypo{a3}{\enot (B \eand \enot D)}
\end{fitchproof}
e esperamos concluir com alguma linha $n$:
\begin{fitchproof}
	\have[n]{con}{\enot C \eor D}
\end{fitchproof}
  O que temos que fazer agora é entender cada uma das regras que poderemos utilizar neste caminho entre as premissas e a conclusão. Estas regras estão divididas de acordo com os conectivos lógicos. 

 %%%%%% ----------------------------------------------- Seção:  Reiteracao 
\section{Reiteração}
 A primeira regra é tão incrivelmente óbvia que é surpreendente que nos importemos com ela.  Ela diz que uma sentença que já foi escrita em alguma linha anterior pode ser copiada (reiterada) em uma linha posterior. Por exemplo:

Se você já mostrou alguma coisa ao longo de uma prova, a \emph{regra de reiteração} permite você repeti-la em uma nova linha. Por exemplo:

\begin{fitchproof}
	\have[4]{a1}{A \eand B}
	\have[$\vdots$]{}{\vdots}
	\have[10]{a2}{A \eand B} \by{R}{a1}
\end{fitchproof}
Então reescrevemos a sentença `$A \eand B$'  na linha~$10$ e indicamos ao lado, como  justificativa, o rótulo `R 4', onde `R' indica que usamos a regra de reiteração (R), para reescrever a sentença da linha~$4$. Por isso `R 4'.

Abaixo uma representação esquemática desta regra:

\factoidbox{
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{c}{\meta{A}} \by{R}{a}
\end{fitchproof}}
Em resumo, o que a regra de reiteração diz e esse esquema mostra é que, se qualquer sentença $\meta{A}$ ocorre em alguma linha, então podemos repetir $\meta{A}$ em linhas posteriores. Cada linha de nossa prova deve  ser justificada por alguma regra, e aqui temos `R $m$'.   Isto significa:  Reiteração, aplicada à linha~$m$. 

 Precisamos enfatizar duas coisas.  Primeiro,   $\meta{A}$   não   é uma sentença da LVF,   mas um símbolo da metalinguagem que usamos quando queremos falar sobre qualquer sentença da LVF
 (veja o Capítulo \ref{s:UseMention}).   Segundo, similarmente,  $m$  não é um símbolo que irá aparecer em uma prova.  Ele também é um símbolo da metalinguagem, que usamos quando queremos falar sobre qualquer número de linha de uma prova. Na prova apresentada, as linhas  estão numeradas por `$1$', `$2$', `$3$', e assim por diante.  Mas quando definimos a regra, usamos variáveis como   $m$ para destacar o ponto em que a regra pode ser aplicada a qualquer momento. 

 %%%%%% --------------------------------------------------------------   Seção: .3  Conjuncao
\section{Conjunção}
  Vamos supor que queremos mostrar que Louis é reservado e leal. Um modo óbvio para fazer isto seria como segue: primeiro mostramos que Louis é reservado, em seguida mostramos que Louis é leal. Depois colocamos essas duas demonstrações juntas para obter a conjunção.

Nosso sistema de dedução natural  captura  essa ideia diretamente. No exemplo dado, podemos adotar a seguinte chave de simbolização:
	\begin{ekey}
		\item[R] Louis é reservado
		\item[L] Louis é leal
	\end{ekey}
Se, por exemplo, estamos fazendo uma prova onde obtivemos `$R$'  na linha 8 e `$L$' na linha 15,  podemos em qualquer linha subsequente escrever `$R \eand L$' da seguinte maneira:

\begin{fitchproof}
	\have[8]{a}{R}
	\have[15]{b}{L}
	\have[\ ]{c}{R \eand L} \ai{a, b}
\end{fitchproof}

 Note que cada linha de nossa prova  ou deve ser uma suposição, ou deve ser justificada por alguma regra.    Citamos  aqui   `$\eand$I 8, 15' para indicar que esta linha foi obtida pela regra da \textit{introdução da conjunção}  ($\eand$I) aplicada às linhas 8 e 15.  Poderíamos igualmente obter a conjunção com a ordem invertida:
\begin{fitchproof}
	\have[8]{a}{R}
	\have[15]{b}{L}
	\have[\ ]{c}{L \eand R} \ai{b, a}
\end{fitchproof}
 com a citação invertida para capturar a ordem  dos  conjuntos. 
Podemos representar o esquema geral da regra de introdução da conjunção assim:
\factoidbox{
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[n]{b}{\meta{B}}
	\have[\ ]{c}{\meta{A}\eand\meta{B}} \ai{a, b}
\end{fitchproof}}
Deixemos claro que o enunciado da regra não é uma prova, mas um esquema, afinal, `$\meta{A}$'  e `$\meta{B}$' não são sentenças da LVF, mas símbolos da metalinguagem (metavariáveis) que usamos quando queremos falar sobre qualquer sentenca da LVF (veja o Capítulo \ref{s:UseMention}). 

Similarmente, as indicações `$m$' e `$n$' acima não são os numerais que usaríamos em uma prova propriamente dita. Elas também são símbolos da metalinguagem, que usamos quando queremos falar sobre um número de linha não identificado de uma prova. Em uma  prova específica da LVF, as linhas  são numeradas por `$1$', `$2$', `$3$', e assim por diante.  Mas quando definimos a regra, usamos variáveis `$m$', `$n$',...  para fazer referência a linhas não especificadas em que as sentenças citadas pela regra ocorrem.
A regra $\eand$I requer apenas que tenhamos ambos os conjuntos em linhas anteriores à aplicação da regra. Eles podem estar próximos ou distantes um do outro, e podem aparecer em qualquer ordem.

A regra é chamada de \emph{introdução} da conjunção  porque  ela introduz   uma sentença cujo conectivo principal é a conjunção `$\eand$'.  Correspondentemente,  temos uma regra que \emph{elimina}  este conectivo. 

 Vamos supor que já foi mostrado que Louis é ambos  reservado e  leal.  Você   está autorizado a concluir que Louis   é reservado. Igualmente você   está autorizado a concluir que Louis é leal. Juntando tudo isto, obtemos nossa(s) regra(s) de \textit{eliminação da conjunção}:
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eand\meta{B}}
	\have[\ ]{a}{\meta{A}} \ae{ab}
\end{fitchproof}}
e igualmente, 

\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eand\meta{B}}
	\have[\ ]{b}{\meta{B}} \ae{ab}
\end{fitchproof}}
 
O propósito é simplesmente este: quando temos uma conjunção em alguma linha da prova, você pode utilizar a regra {\eand}E  para obter qualquer um dos conjuntos. 
Uma coisa importante a enfatizar: você só pode aplicar essa regra quando a conjunção é o operador lógico principal. Logo, você não pode inferir `$D$' a partir de `$C \eor (D \eand E)$' usando a regra {\eand}E.

Com apenas essas duas regras, já podemos começar a ver parte do poder do nosso sistema formal de provas.  Considere: 
\begin{earg}
\item[] $[(A\eor B)\eif(C\eor D)] \eand [(E \eor F) \eif (G\eor H)]$
\item[\therefore] $[(E \eor F) \eif (G\eor H)] \eand [(A\eor B)\eif(C\eor D)]$
\end{earg}
Note que o operador lógico principal da premissa assim como o da conclusão  desse argumento é `$\eand$'.  Para construir uma prova, começamos escrevendo a premissa, que é nossa suposição. Traçamos uma linha abaixo dela. Tudo após essa linha deve seguir de nossas suposições por  (repetidas aplicações de) nossas regras de inferência. Assim, o início da prova é da seguinte forma: 
\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
\end{fitchproof}
A partir da premissa, podemos obter cada um dos conjuntos por  {\eand}E. A prova agora segue assim: 
\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
	\have{a}{{[}(A\eor B)\eif(C\eor D){]}} \ae{ab}
	\have{b}{{[}(E \eor F) \eif (G\eor H){]}} \ae{ab}
\end{fitchproof}
Então, aplicando a regra {\eand}I  nas linhas 3 e 2 (nessa ordem), chegamos à conclusão desejada. A  prova finalizada é como segue:


\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
	\have{a}{{[}(A\eor B)\eif(C\eor D){]}} \ae{ab}
	\have{b}{{[}(E \eor F) \eif (G\eor H){]}} \ae{ab}
	\have{ba}{{[}(E \eor F) \eif (G\eor H){]} \eand {[}(A\eor B)\eif(C\eor D){]}} \ai{b,a}
\end{fitchproof}

 Esta é uma prova muito simples, entretanto ela mostra como podemos encadear regras de  prova em provas mais longas.  A propósito, note que ao investigar esse argumento com uma tabela de verdade seria necessário 256 linhas, enquanto que nossa prova formal requer apenas quatro linhas.

Vale a pena ver um outro exemplo.  Na Seção   \ref{s:MoreBracketingConventions}, vimos  que o seguinte  argumento é válido:

	$$A \eand (B \eand C) \therefore (A \eand B) \eand C$$
 Para fornecer uma prova para esse argumento,  começamos escrevendo: 
\begin{fitchproof}
	\hypo{ab}{A \eand (B \eand C)}
\end{fitchproof}
 A partir da premissa, podemos obter um dos conjuntos aplicando a regra $\eand$E duas vezes. Podemos então aplicar a regra $\eand$E mais duas vezes,  assim nossa prova é como segue: 
\begin{fitchproof}
	\hypo{ab}{A \eand (B \eand C)}
	\have{a}{A} \ae{ab}
	\have{bc}{B \eand C} \ae{ab}
	\have{b}{B} \ae{bc}
	\have{c}{C} \ae{bc}
\end{fitchproof}
 Agora podemos facilmente reintroduzir conjunções na ordem que as desejamos. Assim, nossa prova  completa é:
 
\begin{fitchproof}
	\hypo{abc}{A \eand (B \eand C)}
	\have{a}{A} \ae{abc}
	\have{bc}{B \eand C} \ae{abc}
	\have{b}{B} \ae{bc}
	\have{c}{C} \ae{bc}
	\have{ab}{A \eand B}\ai{a, b}
	\have{con}{(A \eand B) \eand C}\ai{ab, c}
\end{fitchproof}
Se você se lembrar, de acordo com nossa definição oficial das sentenças da LVF as conjunções são sempre de dois conjuntos. A prova que acabamos de apresentar sugere que poderíamos abandonar os parênteses internos em todas as conjunções com mais de dois conjuntos. Mas não vamos fazer isso. Continuaremos usar nossa convenção de parênteses, permitindo apenas a eliminação dos mais externos.

Vamos dar uma última ilustração. Ao usar a regra $\eand$I 
não há necessidade de aplicá-la a sentenças diferentes.
Assim, se quisermos, podemos provar formalmente  `$A \eand A$' a partir de `$A$' como  segue:
\begin{fitchproof}
	\hypo{a}{A}
	\have{aa}{A \eand A}\ai{a, a}
\end{fitchproof}
Simples, porém eficaz.

 %%%%%% ---------------------------------------------  Seção: .4 Condicional
\section{Condicional}
Considere o seguinte argumento:
\begin{earg}
		\item[] Se Jane é inteligente, então ela é rápida.
		\item[] Jane é inteligente.
		\item[\therefore] Ela é rápida.
\end{earg}
Este argumento certamente é valido, e ele sugere diretamente uma aplicação da  regra de \textit{eliminação do condicional}  ($\eif$E):
 
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\meta{A}}
	\have[\ ]{b}{\meta{B}} \ce{ab,a}
\end{fitchproof}}
 Esta regra também é chamada  \emph{modus ponens}. Novamente, esta é uma regra de eliminação porque ela nos permite quebrar uma sentença cujo conectivo principal é `$\eif$', eliminando este conectivo, e obtendo como resultado uma de suas partes: o consequente do condicional.
 Note que o condicional  $\meta{A}\eif\meta{B}$ e o antecedente~$\meta{A}$ podem estar separados um do outro na prova, e eles podem aparecer em qualquer ordem. Entretanto, na citação para a regra $\eif$E, sempre citamos primeiro o condicional, seguido pelo antecedente. 

A regra de \textit{introdução do condicional} também é bastante simples de motivar.  O seguinte argumento deve ser válido:
	\begin{quote}
		Louis é reservado.    Portanto, se Louis é leal, então Louis é ambos  reservado \emph{e} leal.
	\end{quote}
Se alguém duvida que este argumento é válido, podemos tentar convencê-lo do contrário, dando a seguinte explicação.
	\begin{quote}
		Assuma que  Louis é reservado.  Agora, \emph{adicionalmente}, assuma que Louis é leal.  Então, pela introdução da conjunção---que acabamos de discutir---Louis é ambos: reservado e leal.  Claramente só foi possível dizer isso porque antes assumimos que Louis é leal. E isso significa o mesmo que dizer que se Louis é leal, então Louis é ambos: reservado e leal.
	\end{quote}
Transferindo isto para o formato de dedução natural,  temos aqui o padrão do raciocínio  que acabamos de usar.  Começamos com a premissa, `Louis é reservado',  como segue: 

 
	\begin{fitchproof}
		\hypo{r}{R}
	\end{fitchproof}
Em seguida, nós fizemos, apenas para efeito de argumentação, a suposição provisória adicional de que ‘Louis é leal’. Para indicar que tudo o que se segue na prova depende desta suposição provisória adicional, nós escrevemos:

	\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
	\end{fitchproof}
Note que \emph{não}  estamos reivindicando, na linha $2$, ter provado  `$L$' a partir da linha 1, assim não escrevemos nela qualquer justificativa para a suposição inicial na linha 2. No entanto, precisamos destacar que é uma suposição adicional. Fazemos isto traçando uma linha sob ela (para indicar que ela é uma suposição), recuando-a com uma linha vertical adicional (para indicar que ela é adicional).

Com essa  suposição extra posta, estamos prontos para usar a regra  $\eand$I.  Assim, podemos continuar nossa prova: 
	\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
			\have{rl}{R \eand L}\ai{r, l}
%			\close
%		\have{con}{L \eif (R \eand L)}\ci{l-rl}
	\end{fitchproof}
A suposição adicional `$L$’, juntamente com a premissa`$R$' nos permitiu obter `$R \eand L$'.  Isso nos autoriza a dizer que se `$L$’ vigora, então `$R \eand L$' também vigora. Ou, mais brevemente, podemos concluir que  `$L \eif (R \eand L)$':	

\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
			\have{rl}{R \eand L}\ai{r, l}
			\close
		\have{con}{L \eif (R \eand L)}\ci{l-rl}
	\end{fitchproof}


Observe que na linha $4$ voltamos a usar apenas uma linha vertical na esquerda. Fizemos isso para indicar que a suposição adicional `$L$' não vigora mais nesta linha. Ela foi descartada. Repare que a diferença entre as linhas $3$ e $4$ é que na linha $3$ há uma asserção  de `$R \eand L$' justificada por duas suposições:  `$R$' e `$L$'; e na linha $4$ há uma asserção de  `$L \eif (R \eand L)$' justificada por apenas uma suposição:  `$R$'. `$L$' passou de suposição em vigor na linha $3$, para antecedente do condicional na linha $4$.

 O padrão geral usado aqui é o seguinte. Primeiro adicionamos uma suposição, $\meta{A}$;  e desta suposição  adicional, provamos~$\meta{B}$. Neste caso, sabemos o seguinte: se~$\meta{A}$ é verdadeira, então ~$\meta{B}$ também é verdadeira.  Isto está envolvido na regra de \textit{introdução do condicional}:


\factoidbox{
	\begin{fitchproof}
		\open
			\hypo[i]{a}{\meta{A}} 
			\have[j]{b}{\meta{B}}
		\close
		\have[\ ]{ab}{\meta{A}\eif\meta{B}}\ci{a-b}
	\end{fitchproof}}
Pode haver tantas linhas quantas você quiser entre as linhas $i$ e $j$.  

Apresentaremos uma segunda ilustração da regra $\eif$I em acão. Vamos considerar  agora o seguinte argumento:
	$$P \eif Q, Q \eif R \therefore P \eif R$$
Vamos começar listando \emph{ambas} as nossas premissas. Então, como queremos chegar a um condicional (nomeadamente `$P \eif R$'),  assumimos adicionalmente o antecedente deste condicional.
Nossa prova começa da seguinte forma:

\begin{fitchproof}
	\hypo{pq}{P \eif Q}
	\hypo{qr}{Q \eif R}
	\open
		\hypo{p}{P}
	\close
\end{fitchproof}
Observe que disponibilizamos `$P$',  tratando-a como uma suposição adicional.  
Agora, podemos usar a regra  {\eif}E na primeira premissa e obter `$Q$'. Novamente, podemos usar  a regra {\eif}E na segunda premissa e obter `$R$'. Assim, assumindo `$P$'  conseguimos provar `$R$',   então aplicamos a regra {\eif}I, descartando `$P$'.  Com isso, concluímos a prova.  Considerando tudo isso junto, temos: 


\label{HSproof}
\begin{fitchproof}
	\hypo{pq}{P \eif Q}
	\hypo{qr}{Q \eif R}
	\open
		\hypo{p}{P}
		\have{q}{Q}\ce{pq,p}
		\have{r}{R}\ce{qr,q}
	\close
	\have{pr}{P \eif R}\ci{p-r}
\end{fitchproof}

%%%%%% ---------------------------------  Seção: .5   Suposicoes adicionais  e subprovas 

\section{Suposições adicionais  e subprovas}
A regra $\eif$I invocou a ideia de criar  suposições adicionais.   Isto precisa ser manuseado com muito cuidado. Considere esta prova:
\begin{fitchproof}
	\hypo{a}{A}
	\open
		\hypo{b1}{B}
		\have{b2}{B} \by{R}{b1}
	\close
	\have{con}{B \eif B}\ci{b1-b2}
\end{fitchproof}
Isso está perfeitamente de acordo com as regras  que já temos disponíveis e não deve parecer particularmente estranho.   Como `$B \eif B$'  é uma tautologia, nenhuma premissa particular deve ser exigida para prová-la.

Vamos tentar agora continuar a prova como segue: 


\begin{fitchproof}
	\hypo{a}{A}
	\open
		\hypo{b1}{B}
		\have{b2}{B} \by{R}{b1}
	\close
	\have{con}{B \eif B}\ci{b1-b2}
	\have{b}{B} \by{tentativa imprópria}{}
	\have [\ ]{x}{} \by{de invocar $\eif$E}{con, b2}
\end{fitchproof}
Se pudéssemos fazer isso, seria um desastre. Poderíamos provar qualquer  letra sentencial a partir de qualquer outra. Entretanto, se  você me diz que Ana é inteligente  (simbolizada por `$A$'),  não deveríamos ser capazes de concluir que a rainha bela estava feliz (simbolizada por `$B$')!   Devemos ser proibidos de fazer isso, mas como devemos implementar essa proibição?

Podemos descrever o processo de fazer uma suposição adicional através da noção de \emph{subprova}: uma prova subordinada dentro da prova principal. 

Quando começamos a subprova, traçamos outra linha vertical para indicar que não estamos mais na prova principal. Então escrevemos a suposição sobre a qual a subprova será baseada.  Podemos entender o ato de iniciar uma subprova como similar ao de fazer a seguinte questão:  \emph{o que será que podemos concluir se também fizermos esta suposição adicional?}

Quando estamos trabalhando dentro da subprova, podemos nos referir à suposição adicional que acrescentamos ao introduzir a subprova,  e a qualquer coisa que obtivemos de nossas suposições originais (afinal de contas, essas suposições originais ainda estão em vigor). Entretanto, em algum momento,  queremos parar de usar a suposição adicional: queremos sair da subprova e retornar à prova principal. Para indicar que retornamos à prova principal, a linha vertical da subprova chega ao fim.  Nesse ponto, dizemos que a subprova está fechada. Com a subprova fechada, deixamos de lado a suposição.  Logo, será ilegítimo recorrer a ela e a qualquer coisa que dependa dessa suposição adicional. Assim, estipulamos:


\factoidbox{Para citar uma linha individual quando aplicamos uma regra:
\begin{enumerate}
\item A linha citada deve anteceder a linha da regra que a cita.
\item A linha citada não pode ocorrer dentro de uma subprova que tenha sido fechada em linha anterior à linha da regra que a cita.
\end{enumerate}}
Esta estipulação exclui a desastrosa tentativa da prova acima. A regra $\eif$E exige que citemos duas linhas anteriores da prova. Na prova pretendida, acima, uma dessas linhas (nomeadamente, linha~$4$)  ocorre dentro de uma subprova que (pela linha~$5$) já tinha sido fechada. Isto é ilegítimo. 

O fechamento de uma subprova é chamado de descarte da suposição dessa subprova. Assim, fica estabelecido: \emph{você não pode se referir a nada que foi obtido usando suposições descartadas}. 

Subprovas, então, nos permitem pensar sobre o que podemos mostrar,  se fizermos suposições adicionais.  O que podemos  tirar disso não é surpreendente: no curso de uma prova, temos que acompanhar com muito cuidado as suposições que estamos fazendo uso, em qualquer momento.  Nosso sistema de provas faz isso graficamente bem. (De fato, é exatamente por isso que escolhemos usar  \emph{este}  sistema de provas).

Uma vez que começamos a pensar sobre o que podemos mostrar fazendo suposições adicionais, nada nos impede de perguntar  o que poderíamos mostrar se fizéssemos  \emph{ainda mais}  suposições?  Isso pode nos motivar a introduzir uma subprova dentro de uma subprova.  Aqui está um exemplo usando apenas as regras que consideramos até agora:


\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
		\hypo{c}{C}
		\have{ab}{A \eand B}\ai{a,b}
	\close
	\have{cab}{C \eif (A \eand B)}\ci{c-ab}
\close
\have{bcab}{B \eif (C \eif (A \eand B))}\ci{b-cab}
\end{fitchproof}
 Observe que a citação na linha~$4$ se refere à suposição inicial (na linha 1) e uma suposição de uma subprova (na linha~$2$). Isso está perfeitamente em ordem, pois nenhuma suposição foi descartada no momento (isto é, pela linha~$4$).  

Mais uma vez, porém, precisamos acompanhar cuidadosamente o que estamos assumindo a cada momento. Suponha que tentamos continuar a prova da seguinte maneira:
\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
		\hypo{c}{C}
		\have{ab}{A \eand B}\ai{a,b}
	\close
	\have{cab}{C \eif (A \eand B)}\ci{c-ab}
\close
\have{bcab}{B \eif(C \eif (A \eand B))}\ci{b-cab}
\have{bcab}{C \eif (A \eand B)}\by{tentativa imprópria}{}
\have [\ ]{x}{} \by{de invocar $\eif$I}{c-ab}
\end{fitchproof}
 Isso seria terrível. Se tivéssemos dito  que Ana é inteligente, você não seria capaz de deduzir que, se Carla é inteligente (simbolizada por  `$C$') então \emph{ambas} Ana é inteligente  e a rainha Bela estava feliz. Mas isso é exatamente o que essa prova sugeriria, se fosse permissível.

O problema essencial é que a subprova que começou com a suposição~`$C$' dependia crucialmente do fato de termos assumido `$B$' como uma suposição na linha~$2$.  Mas na linha~$6$, \emph{descartamos} a suposição~`$B$'. Fazer isso é o mesmo que parar de perguntar sobre o que podemos concluir se também assumirmos `$B$’ como suposição adicional. Por isso, tentar justificar a linha~$7$ com a subprova das linhas $3-4$ é uma espécie de trapaça, porque a suposição adicional `$B$' que estava em vigor nas linhas $3$ e $4$, não está mais em vigor na linha~$7$, já que foi descartada na linha~$6$. Assim estipulamos, como antes, que uma subprova só pode ser citada em uma linha se ela não ocorrer dentro de outra subprova que já esteja fechada nessa linha. A tentativa desastrosa da prova viola esta estipulação.  A subprova de linhas $3$--$4$ ocorre dentro de uma subprova que termina na linha~$5$. Portanto, não pode ser invocada na linha~$7$.


Abaixo mais um exemplo de aplicação imprópria de regra:
\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
	\hypo{c}{C}
	\have{bc}{B \eand C}\ai{b,c}
	\have{c2}{C}\ae{bc}
	\close
\close
\have{bcab}{B \eif C}\by{tentativa imprópria}{}
\have [\ ]{x}{} \by{de invocar $\eif$I}{b-c2}
\end{fitchproof}
Aqui, estamos tentando citar uma subprova que começa na linha~$2$ e termina na linha~$5$---mas a sentença na linha~$5$ depende não apenas da suposição da linha~$2$, mas também de uma outra suposição (linha~$3$) que não descartamos no final da subprova.  A subprova iniciada na linha~$3$ ainda está aberta na linha~$5$.  Mas a regra $\eif$I requer que a última linha da subprova seja baseada \emph{apenas} na suposião da subprova  que está sendo citada, ou seja, a subprova começando na linha~$2$ (e qualquer coisa antes dela), e não nas suposiçõees de quaisquer subprovas dentro dela. Em particular, a última linha da subprova citada não deve estar, ela mesma, dentro de uma subprova
aninhada.

%\factoidbox{Para citar uma subprova ao aplicar uma regra:
%\begin{enumerate} 
%\item a subprova citada deve vir inteiramente antes da aplicação da regra em que é citada,
%\item a subprova citada não deve estar dentro de outra subprova fechada, que foi fechada na linha em que é citada, e
%\item  a última linha da subprova  citada não deve ocorrer dentro de uma subprova aninhada. 
%\end{enumerate}}


%%%%%% ----------------------------------------------------------  Seção: .6   Biconditional 

\section{Bicondicional}
As regras para o bicondicional serão como versões de via de mão dupla das regras para o condicional. 
Para provar `$F \eiff G$',  por exemplo, você deve ser capaz de provar `$G$' a partir da  suposição `$F$' \emph{e}  provar `$F$' a partir da suposição `$G$'. A regra de \textit{introdução do bicondicional} ({\eiff}I) requer, portanto, duas subprovas. Veja:  %Esquematicamente, a regra funciona assim: 

 

\factoidbox{
\begin{fitchproof}
	\open
		\hypo[i]{a1}{\meta{A}}
		\have[j]{b1}{\meta{B}}
	\close
	\open
		\hypo[k]{b2}{\meta{B}}
		\have[l]{a2}{\meta{A}}
	\close
	\have[\ ]{ab}{\meta{A}\eiff\meta{B}}\bi{a1-b1,b2-a2}
\end{fitchproof}}
Pode haver tantas linhas quantas você quiser entre $i$ e $j$, e tantas linhas quantas você quiser entre $k$ e $l$.  Além disso, as subprovas podem vir em qualquer ordem, e a segunda subprova não precisa vir imediatamente após a primeira.

A regra de \textit{eliminação do bicondicional} ({\eiff}E) permite fazer um pouco mais do que a regra do condicional.  Se você tem a sentença do lado esquerdo do bicondicional, você pode obter a sentença que está no lado direito. E inversamente, se você tem a sentença que está no lado direito do bicondicional, pode obter a sentença que está no lado esquerdo. Assim temos:
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eiff\meta{B}}
	\have[n]{a}{\meta{A}}
	\have[\ ]{b}{\meta{B}} \be{ab,a}
\end{fitchproof}}
\noindent e igualmente:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eiff\meta{B}}
	\have[n]{a}{\meta{B}}
	\have[\ ]{b}{\meta{A}} \be{ab,a}
\end{fitchproof}}
Observe que as sentenças citadas (nas linhas $m$ e $n$ de ambos os esquemas) podem estar separadas uma da outra e podem ocorrer em qualquer ordem.
 No entanto, na citação de $\eiff$E, sempre citamos o  bicondicional primeiro.

%%%%%% ---------------------------------------------------------------  Seção: .7 Disjunao

\section{Disjunção}
Vamos supor que Louis seja reservado.  Então Louis é reservado ou leal. Afinal, dizer que Louis é reservado ou leal é dizer algo mais fraco do que dizer que Louis é reservado. 

Vamos enfatizar esse ponto. Suponha que Louis seja reservado. Disso se segue que  Louis é \emph{ou} reservado \emph{ou} vegetariano.  Igualmente,  disso se segue que \emph{ou} Louis   é reservado \emph{ou} estudante. Também  Igualmente se segue que   \emph{ou} Louis é reservado ou a lua é redonda. Muitas dessas são inferências estranhas, mas não há nada \emph{logicamente} errado com elas, mesmo que eles violem todos os tipos de normas implícitas de conversação.

Munido com tudo isso, apresentamos as regras de \textit{introdução da disjunção}:

\factoidbox{\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{ab}{\meta{A}\eor\meta{B}}\oi{a}
\end{fitchproof}}
e
\factoidbox{\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{ba}{\meta{B}\eor\meta{A}}\oi{a}
\end{fitchproof}}

 

Observe que $\meta{B}$ pode ser \emph{qualquer} sentença, então a seguir temos uma prova perfeitamente aceit\' avel: 
\begin{fitchproof}
	\hypo{m}{M}
	\have{mmm}{M \eor ([(A\eiff B) \eif (C \eand D)] \eiff [E \eand F])}\oi{m}
\end{fitchproof}


Observamos que a tabela de verdade para mostrar isso teria 128 linhas.

A regra da eliminação da disjunção é, no entanto, um pouco mais complicada. Vamos supor que  Louis é reservado ou leal.  O que podemos concluir disso? Caso  Louis  não seja reservado; pode ser que ele seja leal.   Igualmente, caso  Louis  não seja leal, pode ser que ele seja reservado.  Disjunções, por si sós, são difíceis de trabalhar.

Mas suponha que, de alguma forma, possamos mostrar os dois seguinte fatos: primeiro, que sendo Louis reservado implica que ele seja um economista; segundo, que sendo Louis leal implica que ele seja um economista.
Então, se sabemos que Louis é reservado ou leal, então sabemos que, seja ele o que for, Louis é um economista.   Esse insight pode ser expresso na regra a seguir, que é a regra de \textit{eliminação da disjunção}  ($\eor$E):
\factoidbox{
	\begin{fitchproof}
		\have[m]{ab}{\meta{A}\eor\meta{B}}
		\open
			\hypo[i]{a}{\meta{A}} {}
			\have[j]{c1}{\meta{C}}
		\close
		\open
			\hypo[k]{b}{\meta{B}}{}
			\have[l]{c2}{\meta{C}}
		\close
		\have[ ]{c}{\meta{C}}\oe{ab, a-c1,b-c2}
	\end{fitchproof}}
Obviamente, isso é um pouco mais complicado do que as regras anteriores, mas o argumento é bastante simples. Suponha que temos uma disjunção, $\meta{A} \eor \meta{B}$. Suponha também que temos duas subprovas, mostrando que $\meta{C}$ segue da suposição $\meta{A}$, e que $\meta{C}$ segue da suposição $\meta{B}$. Então podemos deduzir o póprio $\meta{C}$. 
 Como sempre, pode haver  tantas linhas quantas  você quiser entre   $i$ e $j$,   e tantas linhas quantas você quiser entre $k$ e $l$. Além disso, as subprovas e a disjunção podem vir em qualquer ordem e não precisam ser vizinhas.

Alguns exemplos podem ajudar a ilustrar isso. Considere este argumento:
$$(P \eand Q) \eor (P \eand R) \therefore P$$
A prova desse exemplo pode ser feita assim:
	\begin{fitchproof}
		\hypo{prem}{(P \eand Q) \eor (P \eand R) }
			\open
				\hypo{pq}{P \eand Q}
				\have{p1}{P}\ae{pq}
			\close
			\open
				\hypo{pr}{P \eand R}
				\have{p2}{P}\ae{pr}
			\close
		\have{con}{P}\oe{prem, pq-p1, pr-p2}
	\end{fitchproof}
Agora temos  um exemplo um pouco mais difícil:  
	$$ A \eand (B \eor C) \therefore (A \eand B) \eor (A \eand C)$$
Aqui está uma prova correspondente a este argumento:
	\begin{fitchproof}
		\hypo{aboc}{A \eand (B \eor C)}
		\have{a}{A}\ae{aboc}
		\have{boc}{B \eor C}\ae{aboc}
		\open
			\hypo{b}{B}
			\have{ab}{A \eand B}\ai{a,b}
			\have{abo}{(A \eand B) \eor (A \eand C)}\oi{ab}
		\close
		\open
			\hypo{c}{C}
			\have{ac}{A \eand C}\ai{a,c}
			\have{aco}{(A \eand B) \eor (A \eand C)}\oi{ac}
		\close
	\have{con}{(A \eand B) \eor (A \eand C)}\oe{boc, b-abo, c-aco}
	\end{fitchproof}
 

Não se assuste se você acha que não seria capaz de fazer essa prova. A habilidade de fazer novas provas vem com a prática, e abordaremos algumas estratégias para construir provas no Capítulo \ref{s:stratTFL}. A questão principal nesta fase é se, olhando a prova, você pode reconhecer que ela está em conformidade com as regras que estabelecemos.
Fazer isso envolve apenas ser capaz de percorrer todas as linhas de uma prova e verificar se elas estão corretamente justificadas de acordo com as regras apresentadas.

%%%%%% -------- ------------- ---------- ------- ------ ------   Seção: ..8  Contradicao e negacao

\section{Contradição e negação}\label{s:contradiction}

Trataremos agora da negação, o nosso  último conectivo. Entretanto, temos que fazer mais esforços para lidar com ele, pois precisamos conectar negação e  \emph{contradição}. 

Uma forma eficaz de argumentar é demonstrar que o seus oponentes se contradizem. Nesse ponto, você os tem sob controle. Eles têm que desistir de pelo menos uma de suas suposições. Vamos usar essa ideia em nosso sistema de provas, adicionando um novo símbolo, `$\ered$', às nossas provas. Esse símbolo deve ser lido como algo como `contradição!'\ ou `isso é um absurdo!'  Podemos usar   a regra para a introdução desse símbolo sempre que nos contradizermos explicitamente, ou seja, sempre que encontrarmos uma sentença e sua negação aparecendo em nossa prova. 
\factoidbox{
\begin{fitchproof}
  \have[m]{na}{\enot\meta{A}}
  \have[n]{a}{\meta{A}}
  \have[ ]{bot}{\ered}\ne{na, a}
\end{fitchproof}}
As sentenças citadas não precisam estar em linhas vizinhas, nem importa a ordem em que aparecem na prova. O importante é que citemos primeiro a linha da sentença negada ($\enot\meta{A}$) e depois a da afirmada ($\meta{A}$). 

%Não importa em que ordem a sentença e sua negação aparecem, e elas não precisam aparecer em linhas vizinhas. No entanto, sempre citamos o número da linha da negação primeiro, seguido pelo da sentença em que foi negada.

Em muitos livros essa regra é chamada de introdução do absurdo, mas aqui nós a chamaremos de \textit{eliminação da negação}.
Obviamente, existe um vínculo estreito entre contradição e negação. 
A regra $\enot$E permite obter uma contradição explícita, ~`$\ered$',  
 a partir de duas sentenças contraditórias, $\meta{A}$ e sua negação $\enot \meta{A}$. 
Nós escolhemos classificar essa regra como uma regra de eliminação porque ela é a regra mais básica que nos permite passar de uma premissa que contém uma negação $\enot\meta{A}$ 
para uma sentença que não contém  `$\ered$'.  Portanto, é uma regra que \emph{elimina}~`$\enot$'.

Dissemos que o símbolo  `$\ered$'  deve ser lido como ‘contradição!’ ou `absurdo!', mas isso não nos diz muito sobre como este símbolo deve ser tratado na LVF. Existem, aproximadamente, três modos diferentes de abordá-lo:

	\begin{ebullet}
		\item Podemos considerar `$\ered$' como uma nova sentença atômica da LVF, mas que só pode ter o valor de verdade Falso.  
		\item Podemos considerar  `$\ered$' como uma abreviação de alguma contradição canônica, como `$A \eand \enot A$'. Isso terá o mesmo efeito que o descrito acima. Obviamente, `$A \eand \enot A$' sempre tem o valor de verdade Falso, mas, ao abordar `$\ered$' dessa forma, não precisamos adicionar um novo símbolo à LVF.
		\item Podemos considerar `$\ered$', não como um símbolo da LVF, mas como um \emph{sinal de pontuação} que aparece em nossas provas.  (Digamos que é comparável aos números das linhas e às linhas verticais.)
			\end{ebullet}
			
Existe algo filosoficamente  muito atraente na terceira opção, mas aqui adotaremos \emph{oficialmente} a primeira. `$\ered$'  deve ser lido como uma letra sentencial que é sempre falsa. Isso significa que, em nossas provas, podemos manuseá-lo do mesmo modo como fazemos com qualquer outra letra sentencial.

Ainda precisamos estabelecer uma regra para a \textit{introdução da negação}. A regra é muito simples: se assumirmos algo que leva a uma contradição, a suposição deve estar errada. Esse pensamento motiva a seguinte regra:

\factoidbox{\begin{fitchproof}
\open
	\hypo[i]{a}{\meta{A}}
	\have[j]{nb}{\ered}
\close
\have[\ ]{na}{\enot\meta{A}}\ni{a-nb}
\end{fitchproof}}
Pode haver tantas linhas quantas você desejar entre $i$ e $j$. Para ver essa regra na prática e como ela interage com a negação, considere esta prova: 
	\begin{fitchproof}
		\hypo{d}{D}
		\open
			\hypo{nd}{\enot D}
			\have{ndr}{\ered}\ne{nd, d}
		\close
		\have{con}{\enot\enot D}\ni{nd-ndr}
	\end{fitchproof}

Se a suposição de que $\meta{A}$ é verdadeira leva a uma contradição, $\meta{A}$ não pode ser verdadeira, isto é, deve ser falsa, ou seja, $\enot\meta{A}$ deve ser verdadeira. Obviamente, se a suposição de que $\meta{A}$ é falsa (ou seja, a suposição de que $\enot\meta{A}$ é verdadeira)  leva a uma contradição, então $\meta{A}$ não pode ser falsa, ou seja, $\meta{A}$ deve ser verdadeira. Podemos, portanto, incluir ao nosso estoque a seguinte regra:

\factoidbox{\begin{fitchproof}
\open
	\hypo[i]{a}{\enot\meta{A}}
	\have[j]{nb}{\ered}
\close
\have[\ ]{na}{\meta{A}}\ip{a-nb}
\end{fitchproof}}
Essa regra é chamada de \emph{prova indireta}, pois permite provar $\meta{A}$  indiretamente, assumindo sua negação. Formalmente, a regra é muito semelhante a $\enot$I, mas $\meta{A}$ e $\enot\meta{A}$ mudaram de lugar. Como $\enot\meta{A}$ não é a conclusão da regra, não estamos introduzindo~`$\enot$', então  PI não é uma regra que introduz qualquer conectivo. Também não elimina um conectivo, pois não possui premissas autônomas que contenham~`$\enot$', apenas uma subprova com uma suposição da forma~$\enot\meta{A}$. Por outro lado, $\enot$E tem uma premissa da forma $\enot\meta{A}$: é por isso que $\enot$E elimina~`$\enot$', mas a regra PI não.\footnote{
	Existem lógicos que não aceitam a regra PI, mas aceitam $\enot$E. Eles são chamados de \textit{intuicionistas}. Os intuicionistas não aceitam nossa suposição básica de que cada sentença tem um dos dois valores de verdade, verdadeiro ou falso. Eles também acham que  `$\enot$' funciona diferentemente. Para eles, uma prova do `$\ered$' a partir de $\meta{A}$ garante $\enot \meta{A}$, mas uma prova do `$\ered$' a partir de $\enot\meta{A}$ não garante que~$\meta{A}$, mas apenas $\enot\enot\meta{A}$. Portanto, para eles, $\meta{A}$ e $\enot\enot\meta{A}$ não são equivalentes.}


Usando $\enot$I, fomos capazes de dar uma prova de $\enot\enot\meta{D}$ a partir de $\meta{D}$. Usando PI, podemos ir na outra direção (com essencialmente a mesma prova).
	\begin{fitchproof}
		\hypo{d}{\enot\enot D}
		\open
			\hypo{nd}{\enot D}
			\have{ndr}{\ered}\ne{d, nd}
		\close
		\have{con}{D}\ip{nd-ndr}
	\end{fitchproof}

A nossa última regra de inferência é uma espécie de regra de eliminação para `$\ered$', conhecida como \emph{explosão} ou \emph{trivialização}\footnote{O nome latino para esse princípio é  \emph{ex contradictione quod libet}, ``da contradição, qualquer coisa''.}.  Intuitivamente, ela nos permite concluir o que quisermos a partir de uma contradição. Mas, qual a motivação dessa regra de inferência? A expressão retórica `... e se isso for verdade, eu comerei o meu chapéu' captura, de certa forma, a ideia desse raciocínio. Ora, as contradições simplesmente não podem ser verdadeiras. A motivação da regra pode então ser descrita mais ou menos assim: como as contradições nunca ocorrem, aceitar uma contradição é aceitar o impossível. Mas quem aceita até o impossível, aceita qualquer coisa. Portanto, de uma contradição podemos inferir qualquer sentença.

Agora apresentamos formalmente a regra da \textit{eliminação do absurdo} ($\ered$E):

\factoidbox{\begin{fitchproof}
\have[m]{bot}{\ered}
\have[ ]{}{\meta{A}}\re{bot}
\end{fitchproof}}
Observe que  \meta{A} pode ser \emph{qualquer} sentença.

A regra de explosão é um pouco estranha. Parece que  \meta{A}  chega em nossa prova como um coelho que sai de uma cartola. Ao tentar encontrar provas, é muito tentador querer usá-la em qualquer lugar, pois parece muito poderosa. Resista a essa tentação: você só pode aplicá-la quando já tiver~`$\ered$'!   E você obtém `$\ered$'   somente quando suas suposições são contraditórias.
 

Ainda assim, não é estranho que, de uma contradição, alguma coisa deva seguir? Não de acordo com nossa noção de sustentação e validade. \meta{A} sustenta \meta{B} se e somente se não existe nenhuma valoração de letras sentenciais que tornam \meta{A} verdadeira e \meta{B} falsa ao mesmo tempo. Mas `$\ered$' é uma contradição, nunca é verdadeiro, seja qual for a valoração das letras sentenciais.  Como não existe nenhuma valoração que faz  `$\ered$' verdadeiro, claro que também não existe nenhuma valoração que faz  `$\ered$'  verdadeiro e \meta{B} falsa! Então, de acordo com a nossa definição de sustentação,  $\ered \entails \meta{B}$,  para qualquer que seja \meta{B}. Uma contradição sustenta qualquer coisa.\footnote{
	%Existem alguns lógicos que não aceitam isso. Eles acham que se \meta{A} implica \meta{B}, deve haver alguma \emph{conexão relevante} entre \meta{A} e \meta{B}, mas não há uma entre `$\ered$' e alguma sentença arbitrária~\meta{B}. Portanto, esses lógicos desenvolvem outras lógicas "relevantes" nas quais  a regra de explosão não é permitida.
	Existem lógicos que rejeitam a regra de explosão. Eles não aceitam que de uma contradição tudo se segue. Esses lógicos e seus sistemas são, de modo abrangente, chamados de \textit{paraconsistentes}. Um dos pioneiros nos estudos da paraconsistência  é o brasileiro Newton da Costa, com seus trabalhos do início dos anos de 1960. Não há consenso entre eles sobre quais são as principais motivações para a rejeição da regra de explosão. Um grupo radical acredita que a realidade contém contradições, e que portanto não temos motivos para rejeitá-las, nem para assumir que tudo se segue delas. Esses paraconsistentes radicais são conhecidos como \textit{dialeteístas} e o filósofo Graham Priest é um de seus principais representantes. Um outro grupo rejeita a regra de explosão com base na ideia de que se \meta{B} se segue de \meta{A}, então deve haver uma conexão relevante entre \meta{A} e \meta{B}. Mas não há conexão relevante entre `$\ered$' e um sentença arbitrária \meta{B}. Por isso eles rejeitam a regra de explosão. As lógicas propostas por esse grupo são chamadas de \textit{lógicas relevantes} e dois de seus proponentes mais representativos são os lógicos Nuel Belnap e Alan Anderson.}

\emph{Estas são todas as regras básicas para o sistema de provas da LVF.}

%%%%%% ----------------------------------------——- -  EXERCICIOS   ------- -------   

\practiceproblems

\problempart
As duas ``provas'' a seguir estão  \emph{incorretas}. Explique quais são os seus erros.
\begin{fitchproof}
\hypo{abc}{(\enot L \eand A) \eor L}
\open
\hypo{nla}{\enot L \eand A}
\have{nl}{\enot L}\ae{nl}
	\have{a}{A}\ae{abc}
\close
\open
	\hypo{l}{L}
	\have{red}{\ered}\ne{nl, l}
	\have{a2}{A}\re{red}
\close
\have{con}{A}\oe{abc, nla-a, l-a2}
\end{fitchproof}

\begin{fitchproof}
\hypo{abc}{A \eand (B \eand C)}
\hypo{bcd}{(B \eor C) \eif D}
\have{b}{B}\ae{abc}
\have{bc}{B \eor C}\oi{b}
\have{d}{D}\ce{bc, bcd}
\end{fitchproof}

\problempart
As três provas a seguir estão sem citações (números de regra e linha). Adicione-os, para transformá-las  em provas fidedignas.  Além disso, anote o argumento que corresponde a cada prova.
\begin{multicols}{2}
\begin{fitchproof}
\hypo{ps}{P \eand S}
\hypo{nsor}{S \eif R}
\have{p}{P}%\ae{ps}
\have{s}{S}%\ae{ps}
\have{r}{R}%\ce{nsor, s}
\have{re}{R \eor E}%\oi{r}
\end{fitchproof}

\begin{fitchproof}
\hypo{ad}{A \eif D}
\open
	\hypo{ab}{A \eand B}
	\have{a}{A}%\ae{ab}
	\have{d}{D}%\ce{ad, a}
	\have{de}{D \eor E}%\oi{d}
\close
\have{conc}{(A \eand B) \eif (D \eor E)}%\ci{ab-de}
\end{fitchproof}

\begin{fitchproof}
\hypo{nlcjol}{\enot L \eif (J \eor L)}
\hypo{nl}{\enot L}
\have{jol}{J \eor L}%\ce{nlcjol, nl}
\open
	\hypo{j}{J}
	\have{jj}{J \eand J}%\ai{j}
	\have{j2}{J}%\ae{jj}
\close
\open
	\hypo{l}{L}
	\have{red}{\ered}%\ne{nl, l}
	\have{j3}{J}%\re{red}
\close
\have{conc}{J}%\oe{jol, j-j2, l-j3}
\end{fitchproof}
\end{multicols}

\solutions
\problempart
\label{pr.solvedTFLproofs}
Apresente uma prova para cada um dos doze seguintes argumentos:
\begin{earg}
\item $J\eif\enot J \therefore \enot J$
\item $Q\eif(Q\eand\enot Q) \therefore \enot Q$
\item $A\eif (B\eif C) \therefore (A\eand B)\eif C$
\item $K\eand L \therefore K\eiff L$
\item $(C\eand D)\eor E \therefore E\eor D$
\item $A\eiff B, B\eiff C \therefore A\eiff C$
\item $\enot F\eif G, F\eif H \therefore G\eor H$
\item $(Z\eand K) \eor (K\eand M), K \eif D \therefore D$
\item $P \eand (Q\eor R), P\eif \enot R \therefore Q\eor E$
\item $S\eiff T \therefore S\eiff (T\eor S)$
\item $\enot (P \eif Q) \therefore \enot Q$
\item $\enot (P \eif Q) \therefore P$
\end{earg}

%%%%%% ---------------------------------------------------CAPITULO    -   Construindo provas 

\chapter{Construindo provas}\label{s:stratTFL}

 Não existe uma receita simples para encontrar provas e não há substituto para a prática. Aqui, entretanto, apresentaremos algumas regras práticas e estratégias a serem lembradas.

%%%%%% ----------------   Seção:  Trabalhando do fim para o começo para chegar onde queremos. 
\section{Trabalhando do fim para o começo para chegar onde queremos}

 Você está tentando encontrar uma prova de alguma conclusão~$\meta{C}$, que será a última linha da sua prova. A primeira coisa que você faz é olhar para~$\meta{C}$ e perguntar qual é a regra de introdução para seu operador lógico principal. Isso lhe dá uma ideia do que deve acontecer \emph{antes} da última linha da prova. 

 As justificativas para a regra de introdução requerem uma ou duas outras sentenças acima da última linha, ou uma ou duas subprovas. Além disso, você pode dizer a partir de~$\meta{C}$ quais são essas sentenças ou quais são as suposições e conclusões das subprovas. Em seguida, você pode escrever essas sentenças ou delinear as subprovas acima da última linha e tratá-las como seus novos objetivos.

 Por exemplo, se sua conclusão é um condicional $\meta{A}\eif\meta{B}$,  tente usar a regra {\eif}I.  Isso requer iniciar uma subprova na qual você assume~\meta{A}. A subprova deve terminar com~\meta{B}. Depois, continue pensando no que você deve fazer para obter $\meta{B}$ dentro dessa subprova,  e como você pode usar a suposição~$\meta{A}$.

 Se seu objetivo for provar uma conjunção, um condicional ou uma sentença negada, você deve começar trabalhando dessa maneira, do fim para o começo. Descreveremos o que você deve fazer em cada um desses casos em detalhes.
 
\subsection*{Provando uma conjunção do fim para o começo}

Suponha que queremos provar $\meta{A} \eand \meta{B}$. Trabalhar do fim para o começo neste caso significa que temos que escrever $\meta{A} \eand \meta{B}$ na parte inferior da prova, e tentar provar esta conjunção usando a regra  $\eand$I.
No topo de uma folha de papel, escreveremos as premissas  da prova, se houver alguma. E  na parte inferior, escrevemos a sentença que queremos provar. Se for uma conjunção, vamos prová-la usando $\eand$I.
  \begin{fitchproof}
	\have{1}{\meta{P}_1}
	\ellipsesline 
	\hypo[k]{k}{\meta{P}_k}
\ellipsesline
    \have[n]{n}{\meta{A}}{} 
    \ellipsesline 
	\have[m]{m}{\meta{B}}
    \have{4}{\meta{A} \eand \meta{B}}\ai{n,m}
  \end{fitchproof}
Para usar a regra  $\eand$I, precisamos provar primeiro $\meta{A}$, depois provar $\meta{B}$. Na última linha, temos que citar as linhas em que provamos $\meta{A}$ e  $\meta{B}$, e usar a regra~$\eand$I. As partes da prova marcadas por $\vdots$ ainda precisam ser preenchidas.
Por enquanto vamos marcar os números de linha $m$, $n$ e $k$, e quando a prova estiver concluída, essas letras serão substituídas por números.

\subsection*{Provando um condicional do fim para o começo}

Se nosso objetivo for provar um condicional,  $\meta{A} \eif \meta{B}$, teremos que usar a regra $\eif$I. Isso requer uma subprova começando com $\meta{A}$ e terminando com~$\meta{B}$. Vamos configurar nossa prova da seguinte forma:
\begin{fitchproof}
\open
\hypo[n]{2}{\meta{A}}
\ellipsesline 
\have[m]{3}{\meta{B}}
\close
\have{4}{\meta{A} \eif \meta{B}}\ci{2-3}
\end{fitchproof} 
Mais uma vez, deixaremos espaços reservados entre as  linhas numeradas por $m$ e $n$. Vamos registrar a última inferência como uma aplicação da regra $\eif$I, citando a subprova.

\subsection*{Provando uma sentença negada do fim para o começo}

Se queremos provar $\enot \meta{A}$, devemos usar a regra $\enot$I.
\begin{fitchproof}
\open
\hypo[n]{2}{\meta{A}}
\ellipsesline 
\have[m]{3}{\ered}
\close
\have{4}{\enot \meta{A}}\ni{2-3}
\end{fitchproof} 
Para aplicar a regra $\enot$I, temos que iniciar uma subprova com a suposição $\meta{A}$; a última linha da subprova tem que ser $\ered$.  Vamos citar a subprova e usar~$\enot$I como regra.  

Aconselhamos a trabalhar do fim para o começo,  o máximo que puder. Assim, se você está trabalhando do fim para o começo para provar $\meta{A} \eif \meta{B}$ e construiu uma subprova com o objetivo de  provar $\meta{B}$,  olhe  agora para a sentença~$\meta{B}$. Se ela for uma conjunção, por exemplo, trabalhe do fim para o começo e insira na subprova os dois conjuntos dessa conjunção,  etc.


\subsection*{Provando uma disjunção do fim para o começo}

Obviamente, você também pode trabalhar do fim para o começo para provar  uma disjunção $\meta{A} \eor \meta{B}$, se esse for seu objetivo. A regra
 $\eor$I exige que você tenha um dos disjuntos para obter $\meta{A} \eor \meta{B}$.
 Assim, escolha um dos disjuntos e,  em seguida,  procure uma prova para esse  disjunto  que você escolheu:
\begin{fitchproof}
	\ellipsesline
	\have[n]{2}{\meta{A}} 
	\have{3}{\meta{A} \eor \meta{B}}\oi{2}
\end{fitchproof}
 No entanto, você pode não conseguir provar o  disjunto que escolheu.  Neste caso você precisa voltar atrás e tentar com o outro disjunto. Apague tudo o que está acima da linha $n$ e tente novamente com o outro disjunto:

\begin{fitchproof}
	\ellipsesline 
	\have[n]{2}{\meta{B}} 
	\have{3}{\meta{A} \eor \meta{B}}\oi{2}
\end{fitchproof}
 Obviamente, apagar tudo e recomeçar é um pouco frustrante. Ao invés de trabalhar do fim para o começo, uma tática melhor para provar uma disjunção é trabalhar do começo para o fim. Veremos logo mais os detalhes de como fazer isso.

%(e trabalhar do fim para o começo quando aplicar as regras $\eand$I, $\eif$I, e $\enot$I) 

%%%%%% -------------------   Seção:   Trabalhando do começo para o fim a partir do que você tem

\section{Trabalhando do começo para o fim a partir do que você tem}

Sua prova pode ter premissas. E se você trabalhou de trás para frente para provar um condicional ou uma sentença negada, você inseriu subprovas com uma suposição e tentou provar uma sentença final na subprova. Essas premissas e suposições são sentenças com que você pode trabalhar do começo para o fim para preencher as etapas ausentes na sua prova. Isso significa aplicar regras de eliminação para os principais operadores dessas sentenças. A forma das regras dirá o que você pode fazer. 

\subsection*{Trabalhando do começo para o fim a partir de uma conjunção}

Para usar a estratégia de provar do  começo para fim a partir de uma sentença da forma $\meta{A} \eand \meta{B}$, usamos a regra $\eand$E. Essa regra nos permite fazer duas coisas: deduzir $\meta{A}$, e deduzir $\meta{B}$. Assim, em uma prova em que temos $\meta{A} \eand \meta{B}$, podemos avançar escrevendo $\meta{A}$ ou $\meta{B}$  imediatamente abaixo da conjunção:

\begin{fitchproof}
  \have[n]{1}{\meta{A} \eand \meta{B}}
  \have{2}{\meta{A}}\ae{1}
  \have{3}{\meta{B}}\ae{1}
\end{fitchproof}
Geralmente fica claro a situação específica que você vai  precisar usar uma das sentenças \meta{A} ou \meta{B}.  Mas, não custa nada escrever as  duas sentenças. 

\subsection*{Trabalhando do começo para o fim a partir de uma disjunção}

Trabalhar do começo para o fim a partir de uma disjunção funciona um pouco diferente. Para usar uma disjunção, usamos a regra $\eor$E e para aplicar essa regra não basta saber quais são os disjuntos da disjunção que queremos usar. Também devemos ter em mente o que queremos provar. Suponha que queremos provar~$\meta{C}$,  e temos $\meta{A} \eor \meta{B}$ para trabalhar. ($\meta{A} \eor \meta{B}$ pode ser uma premissa da prova, uma suposição de uma subprova ou algo já provado.) Para poder aplicar a regra $\eor$E teremos de inserir duas subprovas:
 

\begin{fitchproof}
	\have[n]{1}{\meta{A} \eor \meta{B}}
	\open
	\hypo{2}{\meta{A}} 
	\ellipsesline 
	\have[m]{3}{\meta{C}}
	\close 
	\open
	\hypo{4}{\meta{B}}
	\ellipsesline
	\have[k]{5}{\meta{C}}
	\close
	\have{6}{\meta{C}}\oe{1,(2)-3,(4)-5} 
\end{fitchproof} 
A primeira subprova começa com o primeiro disjunto $\meta{A}$, e termina com a sentença que estamos procurando, $\meta{C}$. A segunda subprova começa com o outro disjunto $\meta{B}$, e também termina com  a sentença~$\meta{C}$. Cada uma dessas subprovas deve ser preenchida ainda mais. Podemos então justificar a sentença $\meta{C}$ usando a regra $\eor$E, citando a linha com $\meta{A} \eor \meta{B}$ e as duas subprovas.

\subsection*{ Trabalhando do começo para o fim a partir de um condicional}

 
Dado um condicional $\meta{A} \eif \meta{B}$, a regra~$\eif$E nos permite concluir o consequente $\meta{B}$ a partir do condicional $\meta{A} \eif \meta{B}$ e do antecedente $\meta{A}$. Então, para trabalhar do começo para o fim a partir de um condicional $\meta{A} \eif \meta{B}$ que ocorre em uma prova, devemos escrever na prova o antecedente $\meta{A}$ e aplicar a regra~$\eif$E para obter $\meta{B}$, conforme ilustrado neste esquema:

\begin{fitchproof}
	\have[n]{1}{\meta{A} \eif \meta{B}}
	\ellipsesline 
	\have[m]{2}{\meta{A}}
	\have{3}{\meta{B}}\ce{1,2} 
\end{fitchproof}

\subsection*{ Trabalhando do começo para o fim a partir de uma sentença negada}

Finalmente, para usar uma sentença negada $\enot \meta{A}$, você deve aplicar a regra $\enot$E. Isto requer, além de  $\enot \meta{A}$,  também a sentença correspondente~$\meta{A}$ sem a negação. A sentença que você irá obter é sempre a mesma: `$\ered$'. Assim, trabalhar do começo para o fim a partir de uma sentença negada funciona especialmente bem dentro de uma subprova que você deseja usar em uma aplicação da regra $\enot$I (ou PI).  Se $\enot \meta{A}$ ocorre em sua prova e você quer provar~`$\ered$', então você insere $\meta{A}$ na prova e aplica a regra $\enot$E para concluir `$\ered$'. A tarefa agora passa a ser justificar $\meta{A}$.

\begin{fitchproof}
	\have[n]{1}{\enot \meta{A}}
	\ellipsesline 
	\have[m]{2}{\meta{A}}
	\have{3}{\ered}\ne{1,2} 
\end{fitchproof}

%%%%%% -----------------------         Seção:   Estratégias  -----------------------

\section{Estratégias }

Vamos supor que queremos mostrar que o argumento $(A \eand B) \eor (A \eand C) \therefore A \eand (B \eor C)$ é válido. Começamos a prova escrevendo a premissa e a conclusão em baixo. (Com o máximo de espaço possível entre elas.) 
\begin{fitchproof}
   \hypo{1}{(A \eand B) \eor (A \eand C)}
\ellipsesline
  \have[n]{2}{A \eand (B \eor C)}
\end{fitchproof}
Agora, temos duas opções: trabalhar do fim para o começo a partir da conclusão, ou do começo para o fim a partir da premissa. Escolheremos a segunda estratégia: usamos a disjunção na linha~$1$ e configuramos as subprovas que precisamos para usa a regra $\eor$E. A disjunção na linha~$1$ tem dois disjuntos, `$A \eand B$' e `$A \eand C$'.  O nosso objetivo é provar a sentença `$A \eand (B \eor C)$'. Assim, neste caso, você  deve criar duas subprovas:  uma com a suposição `$A \eand B$' e a última linha `$A \eand (B \eor C)$', e a  outra com a suposição `$A \eand C$' e a última linha `$A \eand (B \eor C)$'. A justificativa para a conclusão na linha $n$  será  $\eor$E,  citando a disjunção na linha~$1$ e as duas subprovas. Após fazer isso sua prova fica com o seguinte aspecto:
 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline 
	\have[n]{6}{A \eand (B \eor C)}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,7-11}
\end{fitchproof}
Agora você tem duas tarefas separadas, a saber,  preencher cada uma das duas subprovas. Na primeira subprova, trabalhamos do fim para o começo a partir da conclusão $A \eand (B \eor C)$. Isso é uma conjunção, assim dentro da primeira subprova, você terá dois subobjetivos separados: provar $A$, e provar $B \eor C$. Esses subobjetivos permitem justificar a linha $n$ usando a regra~$\eand$I. A sua prova agora fica assim: 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline
	\have[i]{4}{A}
	\ellipsesline
	\have[n][-1]{5}{B \eor C}
	\have[n]{6}{A \eand (B \eor C)}\ai{4,5}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,(7)-11}
\end{fitchproof}

Note que nossa prova estará completa quando preenchermos todos os espaços marcados com os três pontos verticais, ou seja, quando justificarmos todas as linhas que não forem suposições.

No esquema acima é fácil notar que podemos obter a linha $i$ a partir da linha~$2$ por $\eand$E.  Então, a linha $i$ é na verdade a linha~$3$ e pode ser justificada com $\eand$E  da linha~$2$. O outro subobjetivo desta subprova é a disjunção `$B \eor C$' na linha $n-1$. Usaremos aqui a estratégia de trabalhar do fim para o começo.
Temos que escolher um dos disjuntos, `$B$' ou~`$C$'. 
Escolher `$C$' não funcionaria e teríamos de voltar atrás. E já dá para ver que se você escolher `$B$' você vai conseguir justificá-lo, trabalhando do começo para o fim a partir da conjunção `$A \eand B$' da linha~$2$.



\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\have{3}{A}\ae{2}
	\have{4}{B}\ae{2}
	\have{5}{B \eor C}\oi{4}
	\have{6}{A \eand (B \eor C)}\ai{3,5}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,7-11}
\end{fitchproof}
Na primeira subprova, obtivemos as linha $3$ e $4$ da mesma forma, i.e.,  de $2$ por       $\eand$E. 
 A linha $5$  é justificada com a regra $\eor$I na linha~$4$, já que neste passo estamos trabalhando do fim para o começo a partir da disjunção `$B \eor C$'.
Na linha $6$ apenas ajustamos o número da linha e as referências da justificativa, substituindo as indicações $i$, $n$ e $n-1$ respectivamente pelos números correspondentes das linhas de nossa prova: $3$, $6$ e $5$.


Lembre-se que quando começamos a fazer esta prova optamos por trabalhar do começo para o fim a partir da premissa. Se tivéssemos optado por trabalhar do fim para o começo a partir da conclusão, também conseguiríamos provar a validade do argumento, mas a prova resultante ficaria diferente. Se quisermos fazer isso nosso primeiro passo é escrever os dois conjuntos da conclusão  `$A$' e `$B \eor C$', justificar a conclusão a partir deles por $\eand$I e tentar prová-los a partir da premissa `$(A\eand B) \eor (A\eand C)$', que é uma disjunção. Após este início nossa prova fica com o seguinte aspecto:

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline
	\have[k]{3}{A}
	\close
	\open
	\hypo{4}{A \eand C}
	\ellipsesline
	\have[n][-1]{5}{A}
	\close
	\have{6}{A}\oe{1,2-3,(4)-(5)}
	\open
	\hypo{7}{A \eand B}
	\ellipsesline
	\have[l]{8}{B \eor C}
	\close
	\open
	\hypo{9}{A \eand C}
	\ellipsesline
	\have[m][-1]{10}{B \eor C}
	\close
	\have{11}{B \eor C}\oe{1,(7)-8,(9)-(10)}	
	\have{12}{A \eand (B \eor C)}\ai{6,11}
\end{fitchproof}
Examine com calma o esquema acima e tente entender tudo o que foi feito. Deixaremos a tarefa de finalizar esta prova preenchendo as linhas ausentes indicadas por~$\vdots$ como um exercício para você. É importante tentar fazê-lo e, caso tenha problemas, procurar ajuda de professores, monitores e colegas.

Vamos dar outro exemplo para ilustrar como aplicar as estratégias ao lidar com condicionais e negação. A sentença `$(A \eif B) \eif (\enot B \eif \enot A)$' é uma tautologia.  Vamos ver se conseguimos encontrar uma prova disso, sem premissas, usando as estratégias. Primeiro escrevemos a sentença no final de uma folha de papel. 
Como não dá para trabalhar do começo para o fim, já que não há nenhuma premissa de onde partir, trabalhamos do fim para o começo e criamos uma subprova para obter a  sentença que queremos `$(A \eif B) \eif (\enot B \eif \enot A)$' usando a regra  $\eif$I. A sua suposição deve ser o antecedente do condicional que queremos provar, ou seja, `$A \eif B$', e sua última linha, o consequente `$\enot B \eif \enot A$'.
 

\begin{fitchproof}
\open
\hypo{1}{A \eif B}
\ellipsesline
\have[n]{7}{\enot B \eif \enot A}
\close
\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
O novo objetivo, `$\enot B \eif \enot A$' é  também  um  condicional, assim, trabalhando do fim para o começo, criamos outra subprova:

\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\ellipsesline
	\have[n][-1]{6}{\enot A}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-(6)}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
Trabalhamos novamente do fim para o começo a partir de `$\enot A$'.  Para fazer isso, veja a regra $\enot$I. Ela requer uma subprova com~`$A$' como suposição, e `$\ered$' como sua última linha. Nossa prova fica, então, com a seguinte aparência:
 
\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\open\hypo{3}{A}
	\ellipsesline
	\have[n][-2]{5}{\ered}
	\close
	\have{6}{\enot A}\ni{3-(5)}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-(6)}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
 
Agora nosso objetivo é provar~`$\ered$'. E, conforme vimos na Seção Seção \ref{s:contradiction},  se obtivermos uma sentença e sua negação, podemos usar a regra $\enot$E e inferir `$\ered$'.
Mas note que nas linhas~$1$ e $3$ temos `$A \eif B$' e `$A$', donde podemos obter `$B$' pela regra $\eif$E e na linha~$2$ temos `$\enot B$'. Então podemos concluir nossa prova, que ficará assim:

\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\open\hypo{3}{A}
	\have{4}{B}\ce{1,3}
	\have{5}{\ered}\ne{2,4}
	\close
	\have{6}{\enot A}\ni{3-5}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-6}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}

%%%%%% ----------------------- Seção:  Trabalhando do começo para o fim a partir de absourdo

\section{Trabalhando do começo para o fim a partir de `$\ered$'}\label{sec:backred}

Ao aplicar as estratégias, às vezes você se encontra em uma situação em que pode justificar~`$\ered$'. Usando a regra de explosão, isso permitiria justificar \emph{qualquer coisa}. Assim `$\ered$' funciona como um curinga nas provas. Por exemplo, suponha que você queira fornecer uma prova do argumento $A \eor B, \enot A \therefore B$. Você configura sua prova, escrevendo as premissas `$A \eor B$' e `$\enot A$' na parte superior das linhas $1$ e $2$ e a conclusão `$B$' na parte inferior da página. `$B$' não tem conectivo principal, então você não pode usar a estratégia do fim para o começo. Em vez disso, você deve trabalhar a partir de `$A \eor B$', o que requer duas subprovas, tais como:


\begin{fitchproof}
	\hypo{1}{A \eor B}
	\hypo{7}{\enot A}
	\open
	\hypo{2}{A} 
	\ellipsesline 
	\have[m]{3}{B}
	\close 
	\open
	\hypo{4}{B}
	\ellipsesline
	\have[k]{5}{B}
	\close
	\have{6}{B}\oe{1,2-3,(4)-5} 
\end{fitchproof} 
Observe que você possui   `$\enot A$' na linha~$2$ e `$A$' como suposição da sua primeira subprova. Isso lhe dá  `$\ered$'  usando $\enot$E, e de `$\ered$' você obtém a conclusão~`$B$' da primeira subprova usando a regra~$\ered$E . Lembre-se de que você pode repetir uma sentença que já apareceu na prova  usando a regra de reiteração~R. Portanto, a prova completa fica:
\begin{fitchproof}
	\hypo{1}{A \eor B}
	\hypo{7}{\enot A}
	\open
	\hypo{2}{A} 
	\have{8}{\ered}\ne{7,2} 
	\have{3}{B}\re{8}
	\close 
	\open
	\hypo{4}{B}
	\have{5}{B}\by{R}{4}
	\close
	\have{6}{B}\oe{1,2-3,4-5} 
\end{fitchproof} 
%%%%%% ---------------------------------------------------- Seção:   Seguindo indiretamente
\section{Seguindo indiretamente}

Em muitos casos, as estratégias de trabalhar do começo para o fim  e do fim para o começo dão certo. Mas há casos em que elas não funcionam. Se você não conseguir encontrar uma maneira de mostrar $\meta{A}$ diretamente usando essas estratégias,  use a regra PI. Para fazer isso, configure uma subprova na qual você assume  $\enot\meta{A}$  e procure uma prova para `$\ered$' dentro dessa subprova.

\begin{fitchproof}
\open
\hypo[n]{2}{\enot\meta{A}}
\ellipsesline 
\have[m]{3}{\ered}
\close
\have{4}{\meta{A}}\ip{2-3}
\end{fitchproof}
Aqui, temos que iniciar uma subprova com a suposição $\enot \meta{A}$;
a última linha da subprova deve ser~`$\ered$'. Vamos citar a subprova e usar  PI como regra. Na subprova, agora temos uma suposição adicional (na linha $n$) para trabalhar.
 

Neste ponto, parece que uma estratégia óbvia para tentar justificar  `$\ered$' através da regra $\enot$E seria inserir $\meta{A}$ na prova, aplicar a regra $\enot$E para justificar  `$\ered$' e tentar agora provar $\meta{A}$. O esquema da sua prova ficaria, então, com a seguinte aparência:


\begin{fitchproof}
\open
\hypo[n]{2}{\enot \meta{A}}
\ellipsesline
\have[m][-1]{3}{\meta{A}}
\have{4}{\ered}\ne{2,3}
\close
\have{5}{\meta{A}}\ip{2-4}
\end{fitchproof} 

Isso parece bem estranho: lembre que estamos considerando uma situação onde as estratégias de trabalhar do começo para o fim e do fim para o começo não nos levaram a lugar nenhum e, por isso, propusemos uma nova estratégia: fazer uma prova indireta com a regra PI. A estratégia consiste em supor $\enot \meta{A}$ como hipótese de uma subprova e provar `$\ered$'. Aí, com PI, fechamos esta subprova e concluímos $\meta{A}$. Mas esta estratégia nos trouxe à situação (indicada na linha~$m - 1$ acima) onde o subobjetivo que temos que provar para completar a prova de `$\ered$' é o prórprio $\meta{A}$. Ou seja, parece que andamos em círculos. Queríamos, inicialmente, provar $\meta{A}$ e para para conseguir isso, nosso passo intermediário exige que provemos a mesma sentença $\meta{A}$.

Apesar desta situação parecer estranha e circular, ela não é. Note que a prova de $\meta{A}$ que precisamos fazer no passo intermediário está dentro de uma subprova onde temos uma suposição adicional ($\enot \meta{A}$) para trabalhar, que não estava disponível antes. Então a situação é diferente. Vamos ver na seção seguinte um famoso exemplo de uma prova onde isso ocorre.

 

%%%%%% ---------------------- Seção:   Prova indireta do terceiro excluido ---------- ---------

\section{Prova indireta da lei do terceiro excluído}\label{s:proofLEM}

A sentença `$A \eor \enot A$' é uma tautologia e, portanto, deve ter uma prova mesmo sem quaisquer premissas. Mas trabalhar do fim para o começo falha nessa situação: para obter `$A \eor \enot A$' usando $\eor$I teríamos que provar `$A$' ou `$\enot A$'; novamente, sem premissas. Mas nem `$A$' nem  `$\enot A$' é tautologia, então não conseguimos provar nenhuma das duas sem premissas. Trabalhar  do começo para o fim também não funciona, já que não há nada para assumir. Portanto, a única opção é a prova indireta.
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\ellipsesline
	\have[m]{8}{\ered}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}

Precisamos agora justificar `$\ered$' a partir de `$\enot(A \eor \enot A)$'. Para fazer isso incluímos a sentença sem a negação   `$A \eor\enot A$' e usamos a regra  $\enot$E, obtendo o seguinte:
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\ellipsesline
	\have[m][-1]{7}{A \eor \enot A}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}

Note que o que temos que fazer agora é provar `$A \eor\enot A$', que é exatamente a sentença original que queremos provar. Só que agora estamos em uma situação diferente: queremos provar `$A \eor\enot A$’  dentro de uma subprova que tem uma suposição para nos auxiliar.   Em geral, ao lidar com novas metas, devemos voltar e começar com as estratégias básicas. Nesse caso, devemos primeiro tentar trabalhar do fim para o começo a partir da disjunção `$A \eor \enot A$', ou seja, precisamos escolher um dos disjuntos  e tentar prová-lo. Vamos escolher~`$\enot A$'. Isso permitiria justificar `$A \eor \enot A$' na linha~$m - 1$ usando a regra $\eor$I. Feito isso, trabalhando novamente de fim para o começo a partir de `$\enot A$', iniciamos outra subprova a fim de justificar `$\enot A$' usando a regra  $\enot$I. Essa subprova deve ter `$A$' como suposição e~`$\ered$' como sua última linha.
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\open
	\hypo{3}{A}
	\ellipsesline
	\have[m][-3]{5}{\ered}
	\close
	\have{6}{\enot A}\ni{3-(5)}
	\have{7}{A \eor \enot A}\oi{6}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}
Dentro dessa nova subprova, precisamos novamente justificar `$\ered$'. A melhor maneira de fazer isso é começar com uma sentença negada; `$\enot(A \eor \enot A)$' na linha~$1$ é a única sentença negada que podemos usar. A sentença não negada correspondente, `$A \eor \enot A$', no entanto, segue diretamente de `$A$' (que temos na linha~$2$) por $\eor$I. Nossa prova completa é:
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\open
	\hypo{3}{A}
	\have{4}{A \eor \enot A}\oi{3}
	\have{5}{\ered}\ne{2,4}
	\close
	\have{6}{\enot A}\ni{3-5}
	\have{7}{A \eor \enot A}\oi{6}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}

%%%%%% ----------------------------- -   EXERCICIOS  --------------------------------------------------  

\practiceproblems

\problempart
Use as estratégias  para encontrar provas para cada um dos oito seguintes argumentos:
\begin{earg}
\item $A \eif B, A \eif C \therefore A \eif (B \eand C)$
\item $(A \eand B) \eif C \therefore A \eif (B \eif C)$
\item $A \eif (B \eif C) \therefore (A \eif B) \eif (A \eif C)$
\item $A \eor (B \eand C) \therefore (A \eor B) \eand (A \eor C)$
\item $(A \eand B) \eor (A \eand C) \therefore A \eand (B \eor C)$
\item $A \eor B, A \eif C, B \eif D \therefore C \eor D$
\item $\enot A \lor \enot B \therefore \enot(A \eand B)$
\item $A \eand \enot B \therefore \enot(A \eif B)$
\end{earg}

\problempart
Formule estratégias para trabalhar do fim para o começo e do começo para o fim a partir de $\meta{A} \eiff \meta{B}$.

\problempart
Use as estratégias para encontrar provas para cada uma das cinco seguintes sentenças:
\begin{earg}
\item $\enot A \eif (A \eif \ered)$
\item $\enot(A \eand \enot A)$
\item $[(A \eif C) \eand (B \eif C)] \eif [(A \lor B) \eif C]$
\item $\enot(A \eif B) \eif (A \eand \enot B)$
\item $(A \eor \enot B) \eif (A \eif B)$
\end{earg}


Como essas devem ser provas de sentenças a partir de nenhuma premissa, você começará com a respectiva sentença \emph{na parte inferior} da prova, as quais não terão premissas.

\problempart
Use as estratégias para encontrar provas para cada um dos sete seguintes argumentos e sentenças:
\begin{earg}
\item $\enot\enot A \eif A$
\item $\enot A \eif \enot B \therefore B \eif A$
\item $A \eif B \therefore \enot A \eor B$
\item $\enot(A \eand B) \eif (\enot A \eor \enot B)$
\item $A \eif (B \eor C) \therefore (A \eif B) \eor (A \eif C)$
\item $(A \eif B) \lor (B \eif A)$
\item $((A \eif B) \eif A) \eif A$
\end{earg}
Todos exigirão a estratégia de PI. Os últimos três especialmente são bastante difíceis!

%%%%%%------------------------   CAPITULO    -   Regras adicionais da LVF    --------------------- 

\chapter{Regras adicionais da LVF}\label{s:Further}
No Capítulo \ref{s:BasicTFL}, introduzimos as regras básicas de nosso sistema de provas para a LVF e nesta seção, apresentaremos algumas regras adicionais a esse sistema.  Veremos que em  nosso sistema de provas estendido é um pouco mais fácil de trabalhar.  No entanto, veremos, no Capítulo \ref{s:Derived} que essas regras adicionais não são, estritamente falando, \emph{necessárias}.

% \section{Reiteration}
% The first additional rule is \emph{reiteration} (R). This just allows us to repeat ourselves:
% \factoidbox{\begin{fitchproof}
% 	\have[m]{a}{\meta{A}}
% 	\have[\ ]{b}{\meta{A}} \by{R}{a}
% \end{fitchproof}}
% Such a rule is obviously legitimate; we could have used it in our proof in \S\ref{sec:backred}:
% \begin{fitchproof}
% 	\hypo{1}{A \eor B}
% 	\hypo{7}{\enot A}
% 	\open
% 	\hypo{2}{A} 
% 	\have{8}{\ered}\ne{7,2} 
% 	\have{3}{B}\re{8}
% 	\close 
% 	\open
% 	\hypo{4}{B}
% 	\have{5}{B}\by{R}{4}
% 	\close
% 	\have{6}{B}\oe{1,2-3,4-5} 
% \end{fitchproof}
% This is a fairly typical use of the R rule.

%%%%%%———————————  --------   Seção:   Silogismo disjuntivo  ---------------------
\section{Silogismo disjuntivo}
Vejamos uma forma de argumento muito natural.
	\begin{quote}
		Maria está em Natal ou em Lisboa. Ela não está em Lisboa. Portanto, ela está em Natal.
	\end{quote}
Isso é chamado  \emph{silogismo disjuntivo}. Nós o adicionamos ao nosso sistema de provas da seguinte maneira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A} \eor \meta{B}}
	\have[n]{nb}{\enot \meta{A}}
	\have[\ ]{con}{\meta{B}}\by{SD}{ab, nb}
\end{fitchproof}}
e
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A} \eor \meta{B}}
	\have[n]{nb}{\enot \meta{B}}
	\have[\ ]{con}{\meta{A}}\by{SD}{ab, nb}
\end{fitchproof}}

Como usual, a disjunção e a negação de um dos disjuntos podem ocorrer em qualquer ordem e não precisam estar vizinhas. No entanto, sempre citamos a disjunção primeiro.

 %%%%%% ----------------------------------  Seção:  Modus tollens   ---------------------
\section{Modus tollens}
Outro padrão  útil de inferência é incorporado no seguinte argumento:
	\begin{quote}
		Se Carlos venceu a eleição, ele está em Natal. Ele não está em Natal. Portanto ele não venceu a eleição.
	\end{quote}
Este padrão de inferência é chamado \emph{modus tollens}. A regra correspondente é:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\enot\meta{B}}
	\have[\ ]{b}{\enot\meta{A}}\mt{ab,a}
\end{fitchproof}}
Como sempre, as premissas podem ocorrer em qualquer ordem, mas sempre citamos o condicional primeiro. 
 %%%%%% ----------------------------------  Seção:     Eliminação da dupla negação

\section{Eliminação da dupla negação}
Outra regra  útil é a  \emph{eliminação da dupla negação}. Faz exatamente o que seu nome diz:
\factoidbox{\begin{fitchproof}
		\have[m]{dna}{\enot \enot \meta{A}}
		\have[ ]{a}{\meta{A}}\dne{dna}
	\end{fitchproof}}
A justificativa para isso é que, em linguagem natural, as duplas negações tendem a se anular.

Mas, é bom lembrar que em algumas situações o contexto pode nos impedir de fazer isso. Considere a sentença `Jane \emph{não} é infeliz’.  A partir dessa afirmação  não podemos necessariamente concluir `Jane é feliz’, pois a primeira sentença deve ser entendida como  `Jane está em um estado de profunda indiferença’. 
  Como sempre, mudar para a LVF nos obriga a sacrificar certas nuances das expressões em português. 

%%%%%%———————————   Seção:  Terceiro excluido
\section{Lei do Terceiro excluído}

Suponha que possamos mostrar que, se estiver ensolarado lá fora, Bento levará um guarda-chuva (por medo de se queimar). Suponha   também que possamos mostrar que, se não estiver ensolarado lá fora, Bento levará um guarda-chuva (por medo de se molhar). Bem, não há um terceiro caminho para o clima. Portanto, \emph{qualquer que seja} o clima, Bento levará um guarda-chuva.

Essa linha de pensamento motiva a seguinte regra:

\factoidbox{\begin{fitchproof}
		\open
			\hypo[i]{a}{\meta{A}}
			\have[j]{c1}{\meta{B}}
		\close
		\open
			\hypo[k]{b}{\enot\meta{A}}
			\have[l]{c2}{\meta{B}}
		\close
		\have[\ ]{ab}{\meta{B}}\tnd{a-c1,b-c2}
	\end{fitchproof}}
 Essa regra é às vezes chamada de \emph{lei do terceiro excluído}, pois encapsula a ideia de que \meta{A} pode ser verdadeira ou $\enot \meta{A}$ pode ser verdadeira, mas não há meio caminho em que nenhuma das duas seja verdadeira.\footnote{Você pode às vezes encontrar lógicos ou filósofos falando sobre ``tertium non datur''. Esse é o mesmo princípio que o terceiro excluído; significa ``não há terceira via''. Lógicos que têm dúvidas sobre provas indiretas também têm dúvidas sobre a LTE.} Pode haver tantas linhas quantas você quiser entre $i$ e $j$, e tantas linhas quantas quiser entre $k$ e $l$.  Além disso, as subprovas podem vir em qualquer ordem, e a segunda subprova não precisa vir imediatamente após a primeira.

Para ver a regra em ação, considere:
 
	$$P \therefore (P \eand D) \eor (P \eand \enot D)$$
Aqui está uma prova correspondente ao argumento:
	\begin{fitchproof}
		\hypo{a}{P}
		\open
			\hypo{b}{D}
			\have{ab}{P \eand D}\ai{a, b}
			\have{abo}{(P \eand D) \eor (P \eand \enot D)}\oi{ab}
		\close
		\open
			\hypo{nb}{\enot D}
			\have{anb}{P \eand \enot D}\ai{a, nb}
			\have{anbo}{(P \eand D) \eor (P \eand \enot D)}\oi{anb}
		\close
		\have{con}{(P \eand D) \eor (P \eand \enot D)}\tnd{b-abo, nb-anbo}
	\end{fitchproof}
Aqui está outro exemplo:
\begin{fitchproof}
	\hypo{ana}{A \eif \enot A}
	\open
		\hypo{a}{A}
		\have{na}{\enot A}\ce{ana, a}
	\close
	\open
		\hypo{na1}{\enot A}
		\have{na2}{\enot A}\by{R}{na1}
	\close
	\have{na3}{\enot A}\tnd{a-na, na1-na2}
\end{fitchproof}

%%%%%%———————--------------——  Seção:  Regras De Morgan  --------- ---------

\section{Regras de De Morgan}
Nossas regras adicionais finais são chamadas de Leis de De~Morgan (em homenagem a Augustus De~Morgan). A forma das regras deve ser familiar nas tabelas de verdade.

 A primeira regra de De~Morgan é:
 
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot (\meta{A} \eand \meta{B})}
	\have[\ ]{dm}{\enot \meta{A} \eor \enot \meta{B}}\dem{ab}
\end{fitchproof}}
A segunda regra de De~Morgan é o inverso da primeira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot \meta{A} \eor \enot \meta{B}}
	\have[\ ]{dm}{\enot (\meta{A} \eand \meta{B})}\dem{ab}
\end{fitchproof}}
A terceira regra de De~Morgan é dual da primeira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot (\meta{A} \eor \meta{B})}
	\have[\ ]{dm}{\enot \meta{A} \eand \enot \meta{B}}\dem{ab}
\end{fitchproof}}
E a quarta regra de De~Morgan é o inverso da terceira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot \meta{A} \eand \enot \meta{B}}
	\have[\ ]{dm}{\enot (\meta{A} \eor \meta{B})}\dem{ab}
\end{fitchproof}}
\emph{Essas são todas as regras adicionais do nosso sistema de provas para a  LVF.}

 %%%%%% -------------------------  - EXERCICIOS   ------------------------------------------------ 
\practiceproblems
\solutions
\problempart
\label{pr.justifyTFLproof}
As provas a seguir estão sem citações (números de regra e linha). Adicione-os sempre que necessário:

\begin{itemize}
\item[1.] 
	\begin{fitchproof}
\hypo{1}{W \eif \enot B}
\hypo{2}{A \eand W}
\hypo{2b}{B \eor (J \eand K)}
\have{3}{W}{}
\have{4}{\enot B} {}
\have{5}{J \eand K} {}
\have{6}{K}{}
\end{fitchproof}

\item[]

\item[2.]
\begin{fitchproof}
\hypo{1}{L \eiff \enot O}
\hypo{2}{L \eor \enot O}
\open
	\hypo{a1}{\enot L}
	\have{a2}{\enot O}{}
	\have{a3}{L}{}
	\have{a4}{\ered}{}
\close
\have{3b}{\enot\enot L}{}
\have{3}{L}{}
\end{fitchproof}

\item[]

\item[3.]
\begin{fitchproof}
\hypo{1}{Z \eif (C \eand \enot N)}
\hypo{2}{\enot Z \eif (N \eand \enot C)}
\open
	\hypo{a1}{\enot(N \eor  C)}
	\have{a2}{\enot N \eand \enot C} {}
	\have{a6}{\enot N}{}
	\have{b4}{\enot C}{}
		\open
		\hypo{b1}{Z}
		\have{b2}{C \eand \enot N}{}
		\have{b3}{C}{}
		\have{red}{\ered}{}
	\close
	\have{a3}{\enot Z}{}
	\have{a4}{N \eand \enot C}{}
	\have{a5}{N}{}
	\have{a7}{\ered}{}
\close
\have{3b}{\enot\enot(N \eor C)}{}
\have{3}{N \eor C}{}
\end{fitchproof}
\end{itemize}

\problempart 
Faça uma prova para cada um dos quatro argumentos seguintes:
\begin{earg}
\item $E\eor F$, $F\eor G$, $\enot F \therefore E \eand G$
\item $M\eor(N\eif M) \therefore \enot M \eif \enot N$
\item $(M \eor N) \eand (O \eor P)$, $N \eif P$, $\enot P \therefore M\eand O$
\item $(X\eand Y)\eor(X\eand Z)$, $\enot(X\eand D)$, $D\eor M \therefore M$
\end{earg}

%%%%%% ----------------------------  Conceitos de teoria da prova ------------------

\chapter{Conceitos de teoria da prova}\label{s:ProofTheoreticConcepts}

 Neste capítulo, apresentaremos um novo vocabulário. A seguinte expressão:
 
$$\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n \proves \meta{C}$$
significa que existe uma prova que termina com $\meta{C}$  cujas suposições não descartadas estão entre $\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n$. Quando queremos dizer que  \emph{não} é o caso que existe uma prova que termine com $\meta{C}$ a partir de $\meta{A}_1$, $\meta{A}_2$, \dots,~$\meta{A}_n$, escrevemos:  $$\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n \nproves \meta{C}$$  

O símbolo `$\proves$'  é chamado de  \emph{roleta simples}. Queremos enfatizar que este não é o símbolo da roleta dupla (`$\entails$') que introduzimos no Capítulo~\ref{s:SemanticConcepts}  para simbolizar sustentação. O símbolo roleta simples, `$\proves$', diz respeito à existência de provas; enquanto que a roleta dupla, `$\entails$', diz respeito à existência de valorações (ou interpretações, quando usadas na LPO). \emph{Elas são noções muito diferentes}.

Com o nosso símbolo  `$\proves$',  podemos introduzir um pouco mais de terminologia. Para dizer que existe uma prova de $\meta{A}$ sem suposições não descartadas, ou seja, dizer que a sentença $\meta{A}$  pode ser provada sem nenhuma premissa, escrevemos: ${} \proves \meta{A}$. Nesse caso, dizemos que $\meta{A}$ é um \define{teorema}.
	\factoidbox{\label{def:syntactic_tautology_in_sl}
		$\meta{A}$ é um  \define{teorema} se e somente se $\proves \meta{A}$
	}

Para ilustrar isso, suponha que desejamos mostrar que `$\enot (A \eand \enot A)$' é um teorema. Assim, precisamos de uma prova de `$\enot(A \eand \enot A)$' que \emph{não} tenha suposições não descartadas. No entanto, como queremos provar uma sentença cujo operador lógico principal é uma negação, vamos começar com uma \emph{subprova}  dentro da qual assumimos `$A \eand \enot A$', e mostrar que essa suposição leva a uma contradição. Levando em consideração tudo isso, a prova é assim:
	\begin{fitchproof}
		\open
			\hypo{con}{A \eand \enot A}
			\have{a}{A}\ae{con}
			\have{na}{\enot A}\ae{con}
			\have{red}{\ered}\ne{na, a}
		\close
		\have{lnc}{\enot (A \eand \enot A)}\ni{con-red}
	\end{fitchproof}
Provamos então `$\enot (A \eand \enot A)$' sem nenhuma suposição (não descartada).  Esse teorema em particular é uma instância do que às vezes é chamado de \emph{Lei da Não Contradição}.

Para mostrar que algo é um teorema, você apenas precisa encontrar uma prova adequada. Normalmente, é muito mais difícil mostrar que algo \emph{não} é um teorema. Para fazer isso, você precisaria demonstrar, não apenas que certas estratégias de prova falham, mas que \emph{nenhuma} prova é possível. Mesmo que você tente mil vezes e não consiga provar uma sentença, isso não significa que ela não é um teorema. Talvez sua prova seja longa e complexa demais para você entender ou talvez você não tenha se esforçado o suficiente.

Aqui temos um pouco mais de terminologia:
	\factoidbox{
		Duas sentenças \meta{A} e \meta{B} são \definepl{dedutivamente equivalente} se e somente se cada  uma puder ser provada a partir da outra.   i.e,  ambas $\meta{A}\proves\meta{B}$ e $\meta{B}\proves\meta{A}$.
	}

Assim como no caso de mostrar que uma sentença é um teorema, é relativamente fácil mostrar que duas sentenças são dedutivamente equivalentes: isto requer apenas um par de provas. Entretanto, mostrar que sentenças \emph{não} são dedutivamente equivalentes seria muito mais difícil: é tão difícil quanto mostrar que uma sentença não é um teorema.

Um pouco mais de terminologia:
	\factoidbox{
		As sentenças  $\meta{A}_1,\meta{A}_2,\ldots, \meta{A}_n$  são \definepl{dedutivamente inconsistente} se e somente se uma  contradição puder ser provada a partir delas, ou seja, $\meta{A}_1,\meta{A}_2,\ldots, \meta{A}_n \proves \ered$. Se elas não são inconsistentes, dizemos que elas são \textit{dedutivamente consistentes}.
	}
        
        É fácil mostrar que um conjunto de sentenças é dedutivamente inconsistente: você só precisa provar uma contradição a partir delas.  Entretanto,  mostrar que um conjunto de sentenças não é dedutivamente inconsistente é muito mais difícil. Exigiria mais do que apenas fornecer uma ou duas provas; exigiria mostrar que nenhuma prova de um determinado tipo é \emph{possível}.

\
\\
A tabela abaixo resume se para responder afirmativamente ou negativamente às perguntas da esquerda, uma ou duas provas são suficientes ou se precisamos raciocinar sobre todas as provas possíveis.
{ %\small
\begin{center}
\begin{tabular}{l l l}
\cline{1-3}
 \textbf{Teste}& \textbf{Sim} & \textbf{ Não}\\
 \hline
%\cline{2-3}
teorema? & uma prova & todas as provas possíveis\\
inconsistente? &  uma prova  & todas as provas possíveis\\
equivalente? & duas provas & todas as provas possíveis\\
consistente? & todas as provas possíveis & uma prova\\
\cline{1-3}
\end{tabular}
\end{center}}


 
 %%%%%% -----------------------  - EXERCICIOS   ------------------------------------------------ 
\practiceproblems
\problempart
Mostre que cada uma das quatro seguintes sentenças é um teorema:
\begin{earg}
\item $O \eif O$
\item $N \eor \enot N$
\item $J \eiff [J\eor (L\eand\enot L)]$
\item $((A \eif B) \eif A) \eif A$ 
\end{earg}

\problempart
Forneça provas para cada um dos quatro argumentos seguintes:
\begin{earg}
\item $C\eif(E\eand G), \, \,  \enot C \eif G \proves G$
\item $M \eand (\enot N \eif \enot M) \proves (N \eand M) \eor \enot M$
\item $(Z\eand K)\eiff(Y\eand M), \, \,  D\eand(D\eif M) \proves Y\eif Z$
\item $(W \eor X) \eor (Y \eor Z), \, \, X\eif Y, \enot Z \proves W\eor Y$
\end{earg}

\problempart
Mostre que as sentenças de cada um dos seguintes seis pares são dedutivamente equivalentes:
\begin{earg}
\item $R \eiff E$, $E \eiff R$
\item $G$, $\enot\enot\enot\enot G$
\item $T\eif S$, $\enot S \eif \enot T$
\item $U \eif I$, $\enot(U \eand \enot I)$
\item $\enot (C \eif D), C \eand \enot D$
\item $\enot G \eiff H$, $\enot(G \eiff H)$ 
\end{earg}

\problempart
 Se você sabe que $\meta{A}\proves\meta{B}$, o que você pode dizer sobre $(\meta{A}\eand\meta{C})\proves\meta{B}$? E quanto a $(\meta{A}\eor\meta{C})\proves\meta{B}$? Explique suas respostas.

\

\problempart Neste capítulo, alegamos que é muito difícil mostrar que duas sentenças não são dedutivamente equivalentes, assim como mostrar que uma sentença não é um teorema. Por que afirmamos isso? (\emph{Sugestão}: pense em uma sentença que seria um teorema se e somente se \meta{A} e \meta{B} fossem dedutivamente equivalentes.)


 %%%%%% --------------------------  CAP  -   Regras derivadas--------------------------------------

\chapter{Regras derivadas}\label{s:Derived}
Nesta seção, veremos por que introduzimos as regras do nosso sistema de provas em dois lotes separados. Em particular, queremos mostrar que as regras adicionais do Capítulo \ref{s:Further} não são estritamente necessárias, mas podem ser derivadas das regras básicas aprestadas no Capítulo \ref{s:BasicTFL}. 

%%%%%% ———— -- - - - - -  -  —   Seção:   Derivcao de reiteracao  - ---- - - - -  ---- 
\section{Derivação da Reiteração}
Para ilustrar o que significa derivar uma   \emph{regra} de outras regras, primeiro considere a reiteração. Ela é uma regra básica do nosso sistema, mas também não é necessária. Suponha que você tenha alguma sentença em alguma linha de sua dedução:
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
\end{fitchproof}
Agora você deseja repeti-la em alguma linha~$k$. Você poderia simplesmente invocar a regra~R. Mas igualmente bem, você pode fazer isso com outras regras básicas do Capítulo \ref{s:BasicTFL}:
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[k]{aa}{\meta{A} \eand \meta{A}}\ai{a, a}
	\have{a2}{\meta{A}}\ae{aa}
\end{fitchproof}


Para ser claro: isso não é uma prova, mas um \emph{esquema} de prova. Afinal, foi usada  uma variável, $\meta{A}$, da metalinguagem  em vez de uma sentença da LVF, entretanto o ponto é simples: quaisquer que sejam as sentenças da LVF que atribuímos a $\meta{A}$, e quaisquer que sejam as linhas em que estivéssemos trabalhando, poderíamos produzir uma  prova genuína. Assim, você pode pensar nisso como uma receita para produzir provas.

De fato, é uma receita que nos mostra o seguinte: qualquer coisa que possamos provar usando a regra R, podemos provar (com mais uma linha) usando apenas as regras básicas do Capítulo \ref{s:BasicTFL} sem R. É isso que significa dizer que a regra R pode ser derivada de outras regras básicas: qualquer coisa que possa ser justificada usando R pode ser justificada usando apenas as outras regras básicas.

%%%%%% ——— - - - ——-------------——   Seção:   Derivacao de silogismo disjuntivo  -------
\section{Derivação do Silogismo Disjuntivo}
Suponha que você esteja em uma prova e tenha algo desta forma:
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eor\meta{B}}
	\have[n]{na}{\enot \meta{A}}
\end{fitchproof}
Agora você deseja, na linha~$k$, provar $\meta{B}$. Você pode fazer isso com a regra SD, introduzida no Capítulo \ref{s:Further}, mas igualmente, você pode fazer isso com as regras  \emph{básicas} do Capítulo \ref{s:BasicTFL}:
 

	\begin{fitchproof}
		\have[m]{ab}{\meta{A}\eor\meta{B}}
		\have[n]{na}{\enot \meta{A}}
		\open
			\hypo[k]{a}{\meta{A}}
			\have{red}{\ered}\ne{na, a}
			\have{b1}{\meta{B}}\re{red}
		\close
		\open
			\hypo{b}{\meta{B}}
			\have{b2}{\meta{B}}\by{R}{b}
		\close
	\have{con}{\meta{B}}\oe{ab, a-b1, b-b2}
\end{fitchproof}
Esse esquema de prova mostra que a regra SD é desnecessária e pode ser derivada de nossas regras mais básicas. Adicioná-la ao nosso sistema não possibilita novas provas. Sempre  que você usar a regra SD, você pode provar a mesma coisa usando algumas linhas extras aplicando apenas as nossas regras básicas. Assim, SD é uma regra \emph{derivada}.

%%%%%% ——— - - - ————  Seção:   Derivacao de Modus Tollens  ----- - - ---  -- - - 
\section{Derivação de Modus Tollens}
Suponha que você tenha o seguinte em sua prova:
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\enot\meta{B}}
\end{fitchproof}
Agora você deseja, na linha~$k$, provar $\enot \meta{A}$. Você pode fazer isso com a regra  MT, introduzida no Capítulo \ref{s:Further}.  Igualmente aqui, você pode fazer isso com as regras  \emph{básicas} do Capítulo \ref{s:BasicTFL}:
 
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{nb}{\enot\meta{B}}
		\open
		\hypo[k]{a}{\meta{A}}
		\have{b}{\meta{B}}\ce{ab, a}
		\have{nb1}{\ered}\ne{nb, b}
		\close
	\have{no}{\enot\meta{A}}\ni{a-nb1}
\end{fitchproof}
Novamente, esta prova esquemática mostra que a regra MT é desnecessária e pode ser derivada das regras  \emph{básicas} do Capítulo \ref{s:BasicTFL}.

%%%%%% ——— - - - ——   Seção:   Derivacao da Eliminacao da dupla negacao

\section{Derivação da Eliminação da Dupla Negação}
Considere o seguinte esquema de dedução:
	\begin{fitchproof}
	\have[m]{m}{\enot \enot \meta{A}}
	\open
		\hypo[k]{a}{\enot\meta{A}}
		\have{a1}{\ered}\ne{m, a}
	\close
	\have{con}{\meta{A}}\ip{a-a1}
\end{fitchproof}
Aqui também conseguimos derivar a regra EDN das regras \emph{básicas} do Capítulo \ref{s:BasicTFL}.

%%%%%% ——— - - - ——   Seção:    Derivacao do terceiro excluido  ----------------------
\section{Derivação do terceiro excluído}
Suponha que você queira provar algo usando a regra LTE, ou seja, você tem em sua prova
 
\begin{fitchproof}
  \open
  \hypo[m]{a}{\meta{A}}
  \have[n]{aaa}{\meta{B}}
  \close
  \open
  \hypo[k]{b}{\enot\meta{A}}
  \have[l]{bbb}{\meta{B}}
  \close
\end{fitchproof}
Agora você deseja, na linha~$l+1$, provar $\meta{B}$. A regra LTE do Capítulo \ref{s:Further} permitiria que você fizesse isso. Mas, você pode obter $\meta{B}$ usando apenas as regras  \emph{básicas} do Capítulo \ref{s:BasicTFL}.

Um modo de fazer isso é provar $\meta{A} \eor \enot\meta{A}$ e depois usar a regra $\eor$E citando $\meta{A} \eor \enot\meta{A}$ e as duas subprovas acima. Veja abaixo uma representação esquemática deste procedimento, onde no lugar dos três pontos você deve inserir a prova de $\meta{A} \eor \enot\meta{A}$ que fizemos na Seção \ref{s:proofLEM}:

\begin{fitchproof}
  \open
  \hypo[m]{a}{\meta{A}}
  \have[n]{aaa}{\meta{B}}
  \close
  \open
  \hypo[k]{b}{\enot\meta{A}}
  \have[l]{bbb}{\meta{B}}
  \close
  \ellipsesline
  \have[i]{tnd}{\meta{A} \eor \enot \meta{A}}
  \have[i+1]{fin}{\meta{B}}\oe{tnd, a-aaa,b-bbb}
\end{fitchproof}

 


Uma outra maneira um pouco mais complicada de obter o mesmo resultado da regra LTE (terceiro excluído) usando apenas as regras básicas é obtido incorporando as duas subprovas acima dentro de uma outra subprova cuja suposição é $\enot \meta{B}$ e a última linha é `$\ered$'. Se você fizer isso, você poderá concluir \meta{B} e completar sua prova usando PI. Dentro da subprova você precisa trabalhar um pouco para obter `$\ered$'. Todo este procedimento está explicitado no esquema abaixo. Examine-o com calma.

\begin{fitchproof}
  \open
  \hypo[m]{nb}{\enot\meta{B}}
  \open
  \hypo{a}{\meta{A}}
  \ellipsesline
  \have[n]{aaa}{\meta{B}}
  \have{aaaa}{\ered}\ne{nb, aaa}
  \close
  \open
  \hypo{b}{\enot\meta{A}}
  \ellipsesline
  \have[l]{bbb}{\meta{B}}
  \have{bbbb}{\ered}\ne{nb, bbb}
  \close
  \have{na}{\enot\meta{A}}\ni{(a)-(aaaa)}
  \have{nna}{\enot\enot\meta{A}}\ni{(b)-(bbbb)}
  \have{bot}{\ered}\ne{nna, na}
  \close
  \have{B}{\meta{B}}\ip{nb-(bot)}
\end{fitchproof}
Observe que, como adicionamos uma suposição na parte superior e conclusões adicionais dentro das subprovas, os números das linhas mudam.

%%%%%% ——— - - - ——   Seção:   Derivacao das regras de De Morgan ___________
\section{Derivação das regras de De Morgan}
Aqui está uma demonstração de como poderíamos derivar a primeira regra de De Morgan:
 
 	\begin{fitchproof}
		\have[m]{nab}{\enot (\meta{A} \eand \meta{B})}
		\open
			\hypo[k]{a}{\meta{A}}
			\open
				\hypo{b}{\meta{B}}
				\have{ab}{\meta{A} \eand \meta{B}}\ai{a,b}
				\have{nab1}{\ered}\ne{nab, ab}
			\close
			\have{nb}{\enot \meta{B}}\ni{b-nab1}
			\have{dis}{\enot\meta{A} \eor \enot \meta{B}}\oi{nb}
		\close
		\open
			\hypo{na1}{\enot \meta{A}}
			\have{dis1}{\enot\meta{A} \eor \enot \meta{B}}\oi{na1}
		\close
		\have{con}{\enot \meta{A} \eor \enot \meta{B}}\tnd{a-dis, na1-dis1}
	\end{fitchproof}
E agora, veremos como poderíamos derivar a segunda regra de De Morgan:
 	\begin{fitchproof}
		\have[m]{nab}{\enot \meta{A} \eor \enot \meta{B}}
		\open
			\hypo[k]{ab}{\meta{A} \eand \meta{B}}
			\have{a}{\meta{A}}\ae{ab}
			\have{b}{\meta{B}}\ae{ab}
			\open
				\hypo{na}{\enot \meta{A}}
				\have{c1}{\ered}\ne{na, a}
			\close
			\open
				\hypo{nb}{\enot \meta{B}}
				\have{c2}{\ered}\ne{nb, b}
			\close
			\have{con2}{\ered}\oe{nab, na-c1, nb-c2}
		\close
		\have{nab}{\enot (\meta{A} \eand \meta{B})}\ni{ab-con2}
	\end{fitchproof}
 
Demonstrações semelhantes podem ser apresentadas, explicando como poderíamos derivar a terceira e a quarta regra de De Morgan. Estas são deixadas como exercícios.

%%%%%% ---------------------------   EXECICIOS  -----------------------------------------------  
\practiceproblems

\problempart
Forneça esquemas de prova que justifiquem a adição da terceira e quarta regras de De Morgan como regras derivadas.

\

\problempart
As provas que você ofereceu em resposta aos exercícios dos Capítulos  \ref{s:Further} e \ref{s:ProofTheoreticConcepts} usavam regras derivadas. Substitua o uso de regras derivadas, nessas provas, por apenas regras básicas. Você encontrará algumas `repetições' nas provas resultantes; nesses casos, apresentar uma prova simplificada usando apenas regras básicas. (Isso lhe dará uma idéia, do poder das regras derivadas e de como todas as regras interagem.)

\

\problempart
Faça uma prova para $\meta{A} \eor \enot\meta{A}$ usando a regra LTE. Em seguida faça outra prova de $\meta{A} \eor \enot\meta{A}$ que \emph{use apenas as regras básicas}.
 
\

\problempart
Mostre que se você tivesse LTE como regra básica, poderia justificar PI  como regra derivada. Ou seja, suponha que você tenha a prova:
\begin{fitchproof}
  \open
  \hypo[m]{a}{\enot\meta{A}}
  \have[\ ]{aa}{\dots}
  \have[n]{aaa}{\ered}
  \close
\end{fitchproof}
Sua tarefa é tentar provar \meta{A}, a partir desta prova, com a seguinte restrição: você não pode usar a regra PI. Pode usar apenas a regra LTE e todas as outras regras básicas.

\

\problempart
Dê uma prova da primeira regra de De Morgan, mas usando apenas as regras básicas, em particular,  \emph{sem} usar a regra LTE. (Obviamente, você pode combinar a prova usando LTE com a prova  \emph{da}~LTE. Tente encontrar uma prova diretamente.)


 
%%%%%% ----------------------   CAPITULO -   Correcao e completude  --------------------------

\chapter{Correção e completude}
\label{sec:soundness_and_completeness}

 
No Capítulo \ref{s:ProofTheoreticConcepts}, vimos que podemos usar provas para testar os mesmos conceitos que antes testávamos com tabelas de verdade. Vimos que podemos não apenas usar provas para comprovar que um argumento é válido, como também para verificar se uma sentença é uma tautologia ou se duas sentenças são ou não equivalentes. Também começamos a usar a roleta simples de maneira análoga ao uso da roleta dupla. Por exemplo, do mesmo modo que  $\entails \meta{A}$ denota que temos uma tabela de verdade que mostra que \meta{A} é uma tautologia, de modo similar $\proves$~$\meta{A}$ passou a denotar que temos uma prova de \meta{A} sem premissas não descartadas.

Você pode ter se perguntado naquele ponto se os dois tipos de roletas sempre funcionam da mesma maneira. Será que sempre que você consegue mostrar que \meta{A} é uma tautologia usando tabelas de verdade, conseguirá também mostrar que \meta{A} é um teorema usando uma prova? E o inverso, também é verdadeiro? Será que essa correspondência entre os testes que fazemos com tabelas de verdade e aqueles feitos com provas em dedução natural vale também para as noções de argumentos válidos, ou de pares de sentenças equivalentes? O fato é que a resposta para todas essas perguntas e muitas outras questões semelhantes é sim. E isso pode ser demonstrado. Primeiro temos que definir cada uma destas noções de dois modos separados, um modo via valorações (tabelas de verdade) e outro via provas formais em dedução natural. Depois temos que provar que estas diferentes definições são equivalentes. Por exemplo, imaginamos que temos duas noções de validade, a validade$_{\entails}$ e a validade$_{\proves}$ e, em seguida, mostramos que essas duas validades aplicam-se exatamente aos mesmos argumentos.

Para começar, precisamos definir todos os nossos conceitos lógicos separadamente para tabelas de verdade e  para provas. Muito deste trabalho já foi feito. 
Todas as definições dessas noções lógicas feitas através de tabelas de verdade (chamadas de definições semânticas) foram apresentadas no  Capítulo \ref{s:SemanticConcepts}. Além disso também já vimos algumas definições correspondentes feitas via provas formais (chamadas de definições sintáticas), como a definição de teorema e de sentenças dedutivamente equivalentes que correspondem respectivamente às definições de tautologia e de sentenças logicamente equivalentes.
Para a maioria das propriedades lógicas, podemos testá-las usando provas, e aquelas que não podemos testar diretamente podem ser definidas em termos dos conceitos que podemos definir.

Por exemplo, definimos um teorema como uma sentença que pode ser provada sem quaisquer premissas (p.~\pageref{def:syntactic_tautology_in_sl}). Como a negação de uma contradição é uma tautologia, podemos definir uma \define{syntactic contradiction in TFL} \label{def:syntactic_contradiction_in_sl} como uma sentença cuja negação pode ser provada sem quaisquer premissas. A definição sintática de uma sentença contingente é um pouco diferente. Não temos nenhum método prático e finito para provar que uma sentença é contingente usando provas, da mesma maneira que fizemos usando tabelas de verdade. Portanto, precisamos nos contentar em definir ``sentença contingente'' negativamente. Uma sentença é \define{syntactic contingency in TFL} \label{def:syntactically_contingent_in_sl} na LVF se ela  não for um teorema ou uma contradição. 
 

Um  conjunto de sentenças é \define{dedutivamente inconsistente} na LVF \label{def:syntactically_inconsistent_ in_sl}  se e somente se pode-se provar uma contradição a partir dele. A consistência, por outro lado, é como contingência na medida em que não temos um método finito prático para testá-la diretamente. Então, novamente, temos que definir um termo negativamente. Um  conjunto de sentenças é \textit{dedutivamente consistente} na LVF\label{def:syntactically consistent in SL} se e somente se ele não for dedutivamente inconsistente.
    
Finalmente, um argumento é  \define{deductive validity in TFL} \label{def:syntactically_valid_in_SL}se e somente se houver uma prova de sua conclusão a partir de suas premissas. Todas essas definições são apresentadas na Tabela \ref{table:truth_tables_or_derivations}.

\begin{sidewaystable}\small
\tabulinesep=1ex
\begin{tabu}{X[.5,c,m] ||X[1,l,m] |X[1,l,m]}
\textbf{Conceito} 		&	\textbf{Definição (semântica): tabela de verdade} 	&	\textbf{ Definição  (sintática):  teoria da prova} \\ \hline \hline

Tautologia / Teorema  &	Uma sentença cuja tabela de verdade só tem Vs sob o conectivo principal  & Uma sentença que pode ser provada sem nenhuma premissa	 \\ \hline
 
Contradição		&	Uma sentença cuja tabela de verdade só tem Fs sob o conectivo principal  &	Uma sentença cuja negação pode ser provada sem quaisquer premissas\\ \hline

Sentença contingente	&	Uma sentença cuja tabela de verdade contém Vs e Fs sob o  conectivo principal & Uma sentença que não é um teorema nem uma contradição \\ \hline

Sentenças equivalentes  &	As colunas sob os conectivos principais são idênticas & As sentenças podem ser provadas uma da outra	\\ \hline

Sentenças  incompatíveis (inconsistentes)	&	Sentenças que não possuem uma única linha na tabela de verdade, onde todas são verdadeiras	& Sentenças a partir das quais se pode provar uma contradição \\ \hline

Sentenças  compatíveis (consistentes)	&	Sentenças que tenham pelo menos uma linha na tabela de verdade onde elas todas são verdadeiras & Sentenças  a partir das quais não se pode provar uma contradição.	\\ \hline

Argumento válido 		&	Um argumento cuja tabela de verdade não tem  nenhuma linha  na qual  tem Vs sob todos os conectivos principais das premissas e F sob o conectivo principal da conclusão  & Um argumento em que se pode provar a conclusão a partir das premissas	\\ 
\end{tabu}
\caption{Duas maneiras de definir conceitos lógicos.}
\label{table:truth_tables_or_derivations}
\end{sidewaystable}


Todos os nossos conceitos foram definidos agora semântica e sintaticamente. Como podemos provar que essas definições sempre funcionam da mesma maneira? Uma prova completa aqui vai muito além do escopo deste livro. No entanto, podemos dar uma ideia como ela seria. Vamos nos concentrar em mostrar que as duas noções de validade são equivalentes. A partir disso, os outros conceitos seguirão rapidamente. A  prova vai em duas direções. Primeiro, devemos mostrar que tudo que é sintaticamente válido também é semanticamente válido.  
Em outras palavras, tudo o que podemos provar usando provas também pode ser comprovado usando tabelas de verdade. Simbolicamente,  queremos mostrar que  válido$_{\proves}$ implica válido$_{\entails}$. Depois, mostraremos a outra  direção, válido$_{\entails}$ implica válido$_{\proves}$


Mostrar que $\proves $ implica  $\entails $  é  o problema da \define{soundness}. \label{def:soundness} Um sistema de provas é  \definepl{soundness} se não houver provas de argumentos que possam ser mostrados inválidos pelas tabelas de verdade. 
 \label{def_Soundness} 

Para garantir a correção de provas não é suficiente que você sempre tenha conseguido provar todos os argumentos válidos que já tentou e que nunca tenha conseguido provar os argumentos inválidos que já tentou. Demonstrar que o sistema de provas é correto exige mostrar que qualquer prova que possa ser produzida nele é a prova de um argumento válido.  No  Capítulo \ref{ch:Soundness}, apresentaremos uma prova detalhada de  que o sistema formal de provas da LVF é correto.  

A outra direção seria pensar que \emph{todo} argumento que pode ser mostrado válido usando tabelas de verdade também pode ser mostrado usando uma prova.
Esse é o problema da completude. Um sistema de provas tem a propriedade da   \define{completude} \label{def:completeness} se e somente se houver uma prova de todo argumento semanticamente válido. Provar que um sistema é completo é geralmente mais difícil do que provar que é correto. Provar que um sistema é correto significa mostrar que todas as regras do seu sistema de provas funcionam da maneira como deveriam.
Mostrar que um sistema é completo significa mostrar que você incluiu \emph{todas} as regras necessárias e que não deixou nada de fora. Mostrar isso está além do escopo deste livro. O ponto importante é que, felizmente, o sistema de provas da LVF é coreto e completo. Este não é o caso de todos os sistemas de prova ou todas as linguagens formais. Como a LVF satisfaz a completude e a correção,  podemos optar por fornecer provas ou fornecer tabelas de verdade, o que for mais fácil para a tarefa em questão.

Agora que sabemos que o método das tabelas de verdade é intercambiável com o método de provas, você pode escolher qual método deseja usar para qualquer problema. Os alunos geralmente preferem usar tabelas de verdade, porque elas podem ser produzidas apenas mecanicamente, e isso parece ``mais fácil''. No entanto, já vimos que as tabelas de verdade se tornam impossivelmente grandes com um pouco mais de letras sentenciais.
Por outro lado, existem algumas situações em que o uso de provas simplesmente não é possível. Definimos sintaticamente uma sentença contingente como uma sentença que não pode ser provada ser uma tautologia ou uma contradição. Não existe um modo prático de provar esse tipo de declaração negativa. Nunca saberemos se não existe alguma prova de que uma declaração é uma contradição e ainda não a encontramos. Não temos nada a fazer nessa situação, senão recorrer a tabelas de verdade. Da mesma forma, podemos usar provas para mostrar que duas sentenças são equivalentes, mas e se quisermos provar que elas \emph{não} são equivalentes? Não temos como mostrar que nunca encontraremos a prova relevante. Então, temos que voltar às tabelas de verdade de novo.

A tabela \ref{table.ProofOrModel} resume quando é melhor usar provas e quando é melhor usar tabelas de verdade. 

\begin{table}[H]\scriptsize
\tabulinesep=1ex
\begin{tabu}{X[.7,c,m] ||X[1,l,m] |X[1,l,m]}
\textbf{Propriedade lógica} 	&	\textbf{Provar que é satisfeita} 	&	\textbf{Provar que não é satisfeita} \\ \hline \hline
É um teorema ou uma tautologia  &  Provar a sentença 	& Encontrar uma linha falsa na tabela de verdade para a sentença \\ \hline
É uma contradição  &  Provar a negação da sentença   &  Encontrar uma linha verdadeira na tabela de verdade para a sentença\\ \hline
É uma contingência			&  Encontrar uma linha falsa e uma linha verdadeira na tabela de verdade para a sentença & Provar a sentença ou sua negação \\ \hline

São sentenças equivalentes	& Fazer uma prova de cada uma das sentenças na qual a única hipótese é a outra sentença 	 & Encontrar uma linha na tabela de verdade conjunta para as sentenças na qual as sentenças tenham valores diferentes na coluna de seus conectivos principais. \\ \hline
São sentenças incompatíveis ou inconsistentes		& Encontrar uma linha em uma tabela de verdade conjunta para as sentenças na qual a coluna do conectivo principal de todas elas tem valor verdadeiro.
 & Fazer uma prova cuja última linha é uma contradição e cujas premissas não descartadas são as sentenças em questão. \\ \hline
O argumento é válido &  Fazer uma prova da conclusão a partir das premissas & Encontrar uma linha em uma tabela de verdade conjunta para as sentenças do argumento na qual as premissas são todas verdadeiras e a conclusão é falsa. \\ 
\end{tabu}
\caption{Quando fornecer uma tabela de verdade e quando fornecer uma prova.}
\label{table.ProofOrModel}
\end{table}

 %%%%%% ---------------------------   EXECICIOS  -----------------------------------------------  
 
\practiceproblems
\noindent\problempart Em cada um dos doze casos abaixo, use uma  prova ou uma tabela de verdade para mostrar que: 
\begin{enumerate}%[label=(\arabic*)]
\item  A sentença $A \eif [((B \eand C) \eor D) \eif A]$  é um teorema.
\item  A sentença $A \eif (A \eif B)$  não é um teorema.
\item  A sentença $A \eif \enot{A}$ não é uma contradição. 
\item  A sentença $A \eiff \enot A$ é uma contradição.  
\item  A sentença $ \enot (W \eif (J \eor J)) $  é contingente.
\item  A sentença $ \enot(X \eor (Y \eor Z)) \eor (X \eor (Y \eor Z))$  não é contingente.
\item  A sentença $B \eif \enot S$  é equivalente à sentença $\enot \enot B \eif \enot S$.
\item  A sentença $ \enot (X \eor O) $ não é equivalente à sentença $X \eand O$.
\item  As sentenças $\enot(A \eor B)$, $C$, $C \eif A$  são incompatíveis.
\item  As sentenças $\enot(A \eor B)$, $\enot{B}$, $B \eif A$ são compatíveis.
\item  O argumento $\enot(A \eor (B \eor C)) $ \therefore $ \enot{C}$ é válido.
\item  O argumento $\enot(A \eand (B \eor C))$ \therefore $ \enot{C}$ é  inválido.
\end{enumerate}


\noindent\problempart Em cada um dos doze casos abaixo, use uma  prova ou uma tabela de verdade para mostrar que:
\begin{enumerate}%[label=(\arabic*)]
\item A sentença $A \eif (B \eif A)$ é um teorema.
\item A sentença$\enot (((N \eiff Q) \eor Q) \eor N)$ não é um teorema.
\item A sentença $ Z \eor (\enot Z \eiff Z) $ é contingente.
\item A sentença $ (L \eiff ((N \eif N) \eif L)) \eor H $ não é contingente.
\item A sentença $ (A \eiff A) \eand (B \eand \enot B)$ é uma contradição.
\item A sentença$ (B \eiff (C \eor B)) $ não é uma contradição. 
\item A sentença$ ((\enot X \eiff X) \eor X) $  é equivalente à sentença $X$.
\item A sentença $F \eand (K \eand R) $ não  é equivalente à sentença $ (F \eiff (K \eiff R)) $.
\item As sentenças $ \enot (W \eif W)$, $(W \eiff W) \eand W$, $E \eor (W \eif \enot (E \eand W))$ são incompatíveis. 

\item As sentenças  $\enot R \eor C $, $(C \eand R) \eif \enot R$, $(\enot (R \eor R) \eif R) $ são compatíveis.
\item O argumento $\enot \enot (C \eiff \enot C), ((G \eor C) \eor G) \therefore ((G \eif C) \eand G) $ é válido.
\item O argumento $ \enot \enot L,  (C \eif \enot L) \eif C) \therefore \enot C$  é  inválido.
\end{enumerate}

