%!TEX root = forallxyyc.tex
\part{Dedu\c c\~ao Natural para LVF}
\label{ch.NDTFL}
\addtocontents{toc}{\protect\mbox{}\protect\hrulefill\par}

%%%%%% ----------------------------- CAPITULO 25  --------------------------------------------------  
\chapter{A ideia de dedu\c c\~ao natural}\label{s:NDVeryIdea}

No  Cap\'itulo  \ref{s:Valid}, dissemos que um argumento \'e v\'alido se e somente se n\~ao existe nenhuma situa\c c\~ao na qual todas as premissas s\~ao verdadeiras e a conclus\~ao \'e falsa. Posteriormente,  apresentamos as tabelas de verdade para as senten\c cas da LVF,  onde  cada linha de uma tabela completa corresponde a uma valora\c c\~ao. Assim, diante de um argumento da LVF,  temos um modo direto para asserir se existe uma valora\c c\~ao na qual as premissas s\~ao todas verdadeiras e a conclus\~ao falsa, isto \'e, apenas averiguando as tabelas de verdade. 

Entretanto, tabelas de verdade n\~ao nos d\~ao necessariamente muito  \emph{insight}. Considere os dois seguintes argumentos na LVF:
\begin{align*}
P \eor Q, \enot P & \therefore Q\\
P \eif Q, P & \therefore Q
\end{align*}

Claramente, esses argumentos s\~ao v\'alidos. Voc\^e  pode verificar que ele s\~ao v\'alidos construindo tabelas de verdade de quatro linhas, mas podemos dizer que eles fazem uso de diferentes \emph{formas}  de recioc\'inio. Seria bom ter controle dessas diferentes \emph{formas}  de infer\^encia.

Um dos  objetivos de um  \emph{sistema em dedu\c c\~ao natural} \'e de mostrar que argumentos particulares s\~ao  v\'alidos de um modo que nos permita entender o racioc\'inio que os argumentos possam envolver.  Vamos come\c car com regras de infer\^encias muito b\'asicas. Essas regras podem ser combinadas para oferecer  argumentos mais complexos.  De fato,  a partir de uma pequena quantidade  de regras de infer\^encia, esperamos capturar todos argumentos v\'alidos.


\emph{Essa \'e uma maneira muito diferente de pensar sobre argumentos.} 

Com tabelas de verdade,  consideramos diferentes maneiras  para obter senten\c cas verdadeiras ou falsas. Com sistemas de dedu\c c\~ao natural, manipulamos  senten\c cas de acordo com as regras que estabelecemos como boas regras e isto nos possibilita um melhor insight, ou pelo menos, um insight diferente,  de como os argumentos funcionam. 

A mudan\c ca para dedu\c c\~ao natural pode ser motivada por mais do que uma simples busca por um insight. Ela pode ser motivada por  \emph{necessidade}. Considere o seguinte argumento:
$$A_1 \eif C_1 \therefore (A_1 \eand A_2 \eand A_3 \eand A_4 \eand A_5) \eif (C_1 \eor C_2 \eor C_3 \eor C_4 \eor C_5)$$
Para verificar a validade deste argumento, voc\^e   pode usar uma tabela de verdade com 1024 linhas. Se voc\^e fizer isto corretamente, ent\~ao voc\^e ver\'a que  n\~ao existe nenhuma linha na qual todas as premissas s\~ao verdadeiras e a conclus\~ao seja falsa.  Assim, voc\^e saber\'a que o argumento \'e v\'alido.  (Mas,  como  j\'a mencionamos antes, existe um sentido no qual voc\^e n\~ao saber\'a porque o argumento \'e v\'alido). Mas agora considere: 
\begin{align*}
A_1 \eif C_1 \therefore\ & (A_1 \eand A_2 \eand A_3 \eand A_4 \eand A_5 \eand A_6 \eand A_7 \eand A_8 \eand A_9 \eand A_{10}) \eif \phantom{(}\\
&(C_1 \eor C_2 \eor C_3 \eor C_4 \eor C_5 \eor C_6 \eor C_7 \eor C_8 \eor C_9 \eor C_{10})
\end{align*}
Este argumento tamb\'em \'e v\'alido - voc\^e pode provavelmente dizer - mas para test\'a-lo \'e preciso uma tabela de verdade com
 $2^{20} = 1048576$ inhas.  A princ\'ipio, podemos configurar uma m\'aquina para gerar tabelas de verdade e nos relatar quando o processo terminar. Na pr\'atica, argumentos mais complexos na LVF pode torna-se \emph{intrat\'avel} se usamos tabelas de verdades. 
 
 Quando chegarmos \`a l\'ogica de primeira ordem (LPO) (in\'icio do cap\'itulo   \ref{s:FOLBuildingBlocks}),   o problema torna-se dramaticamente pior.  N\~ao existe nada como teste de tabela de verdade para a LPO.  Para assegurar se um argumento \'e v\'alido ou n\~ao,  temos que raciocinar sobre  \emph{todas}   as interpreta\c c\~oes,  mas, como iremos ver, existem  infinitas interpreta\c c\~oes  poss\'iveis.   Em princ\'ipio, n\~ao podemos configurar uma m\'aquina para tratar as infinitas interpreta\c c\~oes poss\'iveis e relatar quando estiver  concluido:  isto  \emph{nunca}  terminar\'a. Ou precisamos desenvolver modos de racioc\'inios mais eficientes para tratar todas as interpreta\c c\~oes, ou precisamos procurar algo diferente. 

Existem de fato, sistemas que  codificam modos de raciocinar sobre todas as interpreta\c c\~oes poss\'iveis. Eles foram desenvolvidos nos ano 1950s por Evert Beth e  Jaakko Hintikka.  Mas n\~ao iremos segui este caminho.  Ao inv\'es disto,  nossa aten\c c\~ao ser\'a voltada para dedu\c c\~ao natural. 
 
Antes de raciocinar diretamente sobre todas as valora\c c\~oes  (no caso da LVF) tentaremos selecionar algumas poucas regras b\'asicas de infer\^encia.  Algumas dessas regras  ir\~ao governar o comportamento dos conectivos sentenciais. Outras ir\~ao governar o comportamento dos quantificadores e identidade que s\~ao marcas da LPO.  
O sistema resultante de regras nos dar\'a um novo modo de pensar sobre a validade de argumentos.  O desenvolvimento moderno de dedu\c c\~ao  natural data dos simult\^aneos  e n\~ao relacionadas artigos de  
 Gerhard Gentzen e Stanis\l{}aw Ja\'{s}kowski (1934).  Entretanto, o sistema de dedu\c c\~ao natural que vamos usar  ser\'a  baseado largamente nos trabalhos de Frederic Fitch (publicado pela primeira vez em 1952). 

 %%%%%% --------------------------------   CAPITULO  26 ----------------------------------------------
\chapter{As regras b\'asicas da LVF}\label{s:BasicTFL}

 

Neste cap\'itulo,  apresentaremos um sistema em  \define{dedu\c  c\~ao natural}. Para cada conectivo, teremos regras de  \define{introdu\c  c\~ao},  que nos permite provar uma senten\c ca que tenha esse conectivo como operador l\'ogico principal, e regras de \define{elimina\c  c\~ao}, que nos permite provar  algo a partir de  uma senten\c ca que tenha esse  conectivo como operador l\'ogico principal. 

 %%%%%% --------------------------------  26.1 A  ideia de uma prova formal

\section{A  ideia de uma prova formal}
Uma \emph{prova formal} \'e uma sequ\^encia de senten\c cas,  dentre as quais, algumas s\~ao  chamadas suposi\c c\~oes iniciais (ou premissas).  A \'ultima linha da prova formal \'e a conclus\~ao.  (A partir de agora, chamaremos simplesmente de `provas',  mas estejam cientes que existem \emph{provas informais} tamb\'em.)

Como uma ilustra\c c\~ao, considere: 
 
	$$\enot (A \eor B) \therefore \enot A \eand \enot B$$
Come\c caremos uma prova escrevendo a premissa: 
\begin{fitchproof}
	\hypo{a1}{\enot (A \eor B)}
\end{fitchproof}
 
Note que numeramos a premissa, pois queremos nos referir  a ela depois. De fato, cada  linha  ao longo da prova  \'e numerada, assim poderemos sempre nos referir a ela novamente. 

 Note tamb\'em que tra\c camos  uma linha sob a  premissa. Tudo que est\'a escrito acima da linha \'e uma 
\emph{suposi\c c\~ao}.  Tudo que est\'a escrito abaixo dessa linha \'e, ou algo que segue das suposi\c c\~oes, ou ser\'a uma nova suposi\c c\~ao.   No nosso exemplo, desejamos concluir 
 `$\enot A \eand \enot B$';  ent\~ao esperamos por fim concluir nossa prova com
\begin{fitchproof}
	\have[n]{con}{\enot A \eand \enot B}
\end{fitchproof}
para algum n\'umero $n$.  N\~ao importa que n\'umero linha a  prova termina. Mas obviamente preferimos uma prova mais curta a  uma longa. 

Similarmente,  suponha que queremos considerar:
$$A\eor B, \enot (A\eand C), \enot (B \eand \enot D) \therefore \enot C\eor D$$
Esse argumento tem tr\^es premissas, ent\~ao  come\c caremos escrevendo as premissas uma abaixo da outra, numeradas, e tran\c camos uma linha sob elas: 
\begin{fitchproof}
	\hypo{a1}{A \eor B}
	\hypo{a2}{\enot (A\eand C)}
	\hypo{a3}{\enot (B \eand \enot D)}
\end{fitchproof}
e esperamos concluir com alguma linha $n$:
\begin{fitchproof}
	\have[n]{con}{\enot C \eor D}
\end{fitchproof}
  Tudo que resta a fazer \'e explicar cada uma das regras que podemos usar ao longo do caminho entre as premissas e a conclus\~ao.  As regras s\~ao  discriminadas gradativamente  (broken down) por nossos conectivos l\'ogicos. 

 %%%%%% -----------------------------------------------26.2 Reiteracao 
\section{Reitera\c c\~ao}
 A primeira regra \'e t\~ao incrivelmente \'obvia que \'e surpreendente que nos importemos com ela.

Se voc\^e j\'a mostrou alguma coisa ao longo de uma prova, a  \emph{regra de  reitera\c c\~ao} permite voc\^e repeti-la em uma nova linha.  Por exemplo:
\begin{fitchproof}
	\have[4]{a1}{A \eand B}
	\have[$\vdots$]{}{\vdots}
	\have[10]{a2}{A \eand B} \by{R}{a1}
\end{fitchproof}
Isto indica que temos escrito `$A \eand B$' na linha~$4$. Agora, em uma linha posterior - linha~$10$, por exemplo - decidimos que queremos repetir esta senten\c ca na prova. Assim, a escrevemos abaixo novamente.  Tamb\'em adicionamos uma cita\c c\~ao que justifica o que temos escrito. Neste caso, escrevemos  `R',  para indicar que estamos usando a regra de reitera\c c\~ao,  e escrevemos  $4$ para indicar  que ela j\'a foi usada na linha $4$.

 Aqui est\'a uma ilustra\c c\~ao generalizada da regra:

\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{c}{\meta{A}} \by{R}{a}
\end{fitchproof}
O importante \'e que, se qualquer senten\c ca $\meta{A}$ ocorre em alguma linha, ent\~ao podemos repetir $\meta{A}$ em linhas posteriores. Cada linha de nossa prova deve  ser justificada por alguma regra, e aqui temos `R $m$'.   Isto significa:  Reitera\c c\~ao, aplicada a linha~$m$. 

 Precisamos enfatizar duas coisa.  Primeiro,   `$\meta{A}$'   n\~ao   \'e uma senten\c ca da LVF,   mas um s\'imbolo da metalinguagem que usamos quando queremos falar sobre qualquer senten\c ca da LVF
 (veja cap\'itulo \ref{s:UseMention}).   Segundo, similarmente,  `$m$'  n\~ao \'e um s\'imbolo que ir\'a aparecer em uma prova.  Ele tamb\'em \'e um s\'imbolo da metalinguagem, o qual usamos quando queremos falar sobre qualquer n\'umero linha  de uma prova. Na prova apresentada, as linhas  est\~ao numeradas por `$1$', `$2$', `$3$', e assim por diante.  Mas quando definimos a regra, usamos vari\'aveis como   `$m$' para destacar o ponto em que a regra pode ser aplicada a qualquer momento. 

 %%%%%% --------------------------------------------------------------  26.3  Conjuncao
\section{Conjun\c c\~ao}
  Vamos supor que queremos mostrar que Louis \'e reservado e leal. Um modo \'obvio para fazer isto seria como segue: primeiro mostramos que Louis \'e reservado, em seguida mostramos que Louis \'e leal. Depois colocamos essas duas demonstra\c c\~oes juntas para obter a conjun\c c\~ao.

Nosso sistema de dedu\c c\~ao natural  captura  essa ideia diretamente. No exemplo dado, podemos adotar a seguinte simboliza\c c\~ao:
	\begin{ekey}
		\item[R] Louis \'e reservado
		\item[L] Louis \'e leal
	\end{ekey}
 Talvez estejamos trabalhando em uma prova, e j\'a temos obtido `$R$'  na linha 8 e `$L$' na linha 15. Ent\~ao  em alguma linha subsequente podemos obter  `$R \eand L$' como segue:
\begin{fitchproof}
	\have[8]{a}{R}
	\have[15]{b}{L}
	\have[\ ]{c}{R \eand L} \ai{a, b}
\end{fitchproof}

 Note que cada linha de nossa prova  ou deve ser uma suposi\c c\~ao, ou deve ser justificada por alguma regra.    Citamos  aqui   `$\eand$I 8, 15' para indicar que a linha obtida pela regra da introdu\c c\~ao  da conjun\c c\~ao  ($\eand$I) aplicada as linhas 8 e 15.  Poder\'iamos igualmente obter:
\begin{fitchproof}
	\have[8]{a}{R}
	\have[15]{b}{L}
	\have[\ ]{c}{L \eand R} \ai{b, a}
\end{fitchproof}
 
 com a cita\c c\~ao invertida para capturar a ordem  dos  conjuntos. 
De maneira mais geral, aqui est\'a  a nossa regra de introdu\c c\~ao da  conjun\c c\~ao:
\factoidbox{
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[n]{b}{\meta{B}}
	\have[\ ]{c}{\meta{A}\eand\meta{B}} \ai{a, b}
\end{fitchproof}}
Para ser claro, o enunciado da regra \'e esquem\'atico.  Isto n\~ao \'e propriamente uma prova,      `$\meta{A}$'  e `$\meta{B}$'  n\~ao s\~ao senten\c cas da LVF, mas s\'imbolos da metalinguagem, que usamos quando queremos falar sobre qualquer sentenca da LVF (veja cap\'itulo \ref{s:UseMention}). 

Similarmente,  `$m$' e `$n$' n\~ao s\~ao numerais  que ir\~ao aparecer em uma prova real. Eles tamb\'em s\~ao s\'imbolos da metalinguagem, os quais usamos quando queremos falar sobre qualquer numero linha  de uma prova. Em uma  prova real, as linhas  s\~ao numeradas por `$1$', `$2$', `$3$', e assim por diante.  Mas quando definimos a regra, usamos vari\'aveis   para destacar o ponto que a regra pode ser aplicada a qualquer momento.  A regra requer somente que temos ambos os conjuntos dispon\'iveis para ser usados em qualquer parte da prova. Eles podem ser separados um do outro, e podem aparecer em qualquer ordem.

A regra \'e chamada `\emph{introdu\c c\~ao} da conjun\c c\~ao'  porque  ela introduz  o s\'imbolo `$\eand$' na nossa  prova onde ele pode ter sido ausente.  Correspondentemente,  temos uma regra que \emph{elimina}  este  s\'imbolo.  Vamos supor que temos mostrado que Louis \'e ambos  reservado e  leal.  Voc\^e   est\'a autorizado a concluir que Louis   \'e reservado. Igualmente voc\^e   est\'a autorizado a concluir que Louis   \'e leal.  Juntando tudo isto, obtemos nossa(s) regra(s) de elimina\c c\~ao da conjun\c c\~ao:
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eand\meta{B}}
	\have[\ ]{a}{\meta{A}} \ae{ab}
\end{fitchproof}}
e igualmente, 

\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eand\meta{B}}
	\have[\ ]{b}{\meta{B}} \ae{ab}
\end{fitchproof}}
 
O prop\'osito \'e simplesmente este,  quando temos uma conjun\c c\~ao em alguma linha da prova, voc\^e pode obter qualquer um dos conjuntos  por {\eand}E.  Uma coisa importante a enfatizar:  voc\^e s\'o pode aplicar essa regra quando a conjun\c c\~ao \'e o operador l\'ogico principal. Assim voc\^e n\~ao pode inferir `$D$'  apenas de `$C \eor (D \eand E)$'!

Com apenas essas duas regras, j\'a podemos come\c car a ver parte do poder do nosso sistema formal de provas.  Considere: 
\begin{earg}
\item[] $[(A\eor B)\eif(C\eor D)] \eand [(E \eor F) \eif (G\eor H)]$
\item[\therefore] $[(E \eor F) \eif (G\eor H)] \eand [(A\eor B)\eif(C\eor D)]$
\end{earg}
Note que o operador l\'ogico principal em ambas a premissa e conclus\~ao  desse argumento \'e `$\eand$'.  Para construir uma prova, come\c camos escrevendo a premissa, que \'e nossa suposi\c c\~ao. Tra\c camos uma linha abaixo dela. Tudo ap\'os essa linha deve seguir de nossas suposi\c c\~oes por  (repetidas aplica\c c\~oes de) nossas regras de infer\^encia. Assim, o in\'icio da prova \'e da seguinte forma: 
\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
\end{fitchproof}
A partir da premissa, podemos obter cada um dos conjuntos por  {\eand}E. A prova agora segue assim: 
\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
	\have{a}{{[}(A\eor B)\eif(C\eor D){]}} \ae{ab}
	\have{b}{{[}(E \eor F) \eif (G\eor H){]}} \ae{ab}
\end{fitchproof}
Ent\~ao, aplicando a regra {\eand}I  nas linhas 3 e 2 ( nesta ordem), chegamos a conclus\~ao desejada. A  prova finalizada \'e como segue:


\begin{fitchproof}
	\hypo{ab}{{[}(A\eor B)\eif(C\eor D){]} \eand {[}(E \eor F) \eif (G\eor H){]}}
	\have{a}{{[}(A\eor B)\eif(C\eor D){]}} \ae{ab}
	\have{b}{{[}(E \eor F) \eif (G\eor H){]}} \ae{ab}
	\have{ba}{{[}(E \eor F) \eif (G\eor H){]} \eand {[}(A\eor B)\eif(C\eor D){]}} \ai{b,a}
\end{fitchproof}

 Esta \'e uma prova muito simples, entretanto ela mostra como podemos encadear regras de  prova em provas mais longas.  A prop\'osito, note que ao investigar esse argumento com uma tabela de verdade seria necess\'ario 256 linhas, enquanto que nossa prova formal requer apenas quatro linhas.

Vale a pena ver um outro exemplo.  Na Se\c c\~ao   \ref{s:MoreBracketingConventions}, vimos  que o seguinte  argumento \'e v\'alido:

	$$A \eand (B \eand C) \therefore (A \eand B) \eand C$$
 Para fornecer uma prova para esse argumento,  come\c camos escrevendo: 
\begin{fitchproof}
	\hypo{ab}{A \eand (B \eand C)}
\end{fitchproof}
 A partir da premissa, podemos obter um dos conjuntos aplicando $\eand$E duas vezes. Podemos ent\~ao aplicar $\eand$E mais duas vezes,  assim nossa prova \'e como segue: 
\begin{fitchproof}
	\hypo{ab}{A \eand (B \eand C)}
	\have{a}{A} \ae{ab}
	\have{bc}{B \eand C} \ae{ab}
	\have{b}{B} \ae{bc}
	\have{c}{C} \ae{bc}
\end{fitchproof}
 Agora podemos facilmente reintroduzir conjun\c c\~oes na ordem que as desejamos. Assim, nossa prova  completa \'e:
 
\begin{fitchproof}
	\hypo{abc}{A \eand (B \eand C)}
	\have{a}{A} \ae{abc}
	\have{bc}{B \eand C} \ae{abc}
	\have{b}{B} \ae{bc}
	\have{c}{C} \ae{bc}
	\have{ab}{A \eand B}\ai{a, b}
	\have{con}{(A \eand B) \eand C}\ai{ab, c}
\end{fitchproof}
Lembre-se que nossa defini\c c\~ao oficial de senten\c cas na LVF somente admite conjun\c c\~oes com dois conjuntos.  A prova que acabamos de apresentar sugere que podemos abandonar  os par\^enteses em todas as nossas provas. Entretanto, isto n\~ao \'e o padr\~ao e  n\~ao iremos fazer isto.  De fato, manteremos nossa conven\c c\~ao do uso de par\^enteses mais severa. (Entretanto, iremos permitir o abandono dos par\^enteses mais externos, por legitimidade.)  

Vamos dar uma \'ultima ilustra\c c\~ao. Ao usar a regra $\eand$I 
n\~ao h\'a necessidade de aplic\'a-la a senten\c cas diferentes.
Assim, se quisermos, podemos provar formalmente  `$A \eand A$' a partir de `$A$' como  segue:
\begin{fitchproof}
	\hypo{a}{A}
	\have{aa}{A \eand A}\ai{a, a}
\end{fitchproof}
Simples, por\'em eficaz.

 %%%%%% --------------------------------------------- 26.4 Condicional
\section{Condicional}
Considere o seguinte argumento::
\begin{earg}
		\item[] Se Jane \'e inteligente, ent\~ao ela \'e r\'apida.
		\item[] Jane \'e inteligente.
		\item[\therefore] ela \'e r\'apida.
\end{earg}
Este argumento certamente \'e valido, e ele sugere diretamente uma aplica\c c\~ao da  regra de elimina\c c\~ao do condicional  ($\eif$E):
 
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\meta{A}}
	\have[\ ]{b}{\meta{B}} \ce{ab,a}
\end{fitchproof}}
 Esta regra tamb\'em \'e chamada  \emph{modus ponens}. 
Novamente, esta \'e uma regra de elimina\c c\~ao porque ela nos permite obter uma senten\c ca que pode n\~ao conter `$\eif$', tendo come\c cado com uma senten\c ca que continha este s\'imbolo. Note que o condicional  $\meta{A}\eif\meta{B}$ e o antecedente~$\meta{A}$ podem estar separados um do outro na prova, e eles podem aparecer em qualquer ordem. Entretanto, na cita\c c\~ao para $\eif$E, sempre citamos primeiro o condicional, seguido pelo antecedente. 

 A regra para introdu\c c\~ao do condicional \'e tamb\'em facilmente  motivada.  O seguinte argumento deve ser v\'alido:
	\begin{quote}
		Louis \'e reservado.    Portanto, se Louis \'e leal, ent\~ao Louis \'e ambos  reservado \emph{e} leal.
	\end{quote}
Se algu\'em duvidou que este argumento era v\'alido, podemos tentar convenc\^e-lo o contr\'ario, dando a seguinte explica\c c\~ao.
	\begin{quote}
		Assuma que  Louis \'e reservado.  Agora, \emph{adicionalmente} assuma que Louis \'e leal.  Ent\~ao, pela introdu\c c\~ao da conjun\c c\~ao  - que acabamos de discutir -  Louis \'e ambos  reservado e leal.  Claramente, isto depende da suposi\c c\~ao que Louis \'e leal.  Mas isto significa apenas que, se Louis \'e  leal,  ent\~ao Louis \'e ambos   reservado e leal. 
	\end{quote}
Transferindo isto para o formato de dedu\c c\~ao natural,  temos aqui o padr\~ao do racioc\'inio  que acabamos de usar.  Come\c camos com a premissa, 'Louis \'e reservado',  como segue: 

 
	\begin{fitchproof}
		\hypo{r}{R}
	\end{fitchproof}
A pr\'oxima coisa que fizemos foi  criar uma suposi\c c\~ao \emph{adicional} ('Louis \'e   leal'),  por uma quest\~ao de argumento. Para indicar que n\~ao estamos mais lidando  \emph{meramente} com nossa suposi\c c\~ao original, (`$R$'),  mas com alguma suposi\c c\~ao adicional,  continuamos  nossa prova como segue:
	\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
	\end{fitchproof}
Note que \emph{n\~ao}  estamos reivindicando, na linha 2, ter provado  `$L$' a partir da linha 1, assim n\~ao escrevemos nela qualquer justificativa para a suposi\c c\~ao inicial na linha 2. No entanto, precisamos destacar que \'e uma suposi\c c\~ao adicional. Fazemos isto tra\c cando uma linha sob ela (para indicar que ela \'e uma suposi\c c\~ao), recuando-a com uma linha vertical adicional (para indicar que ela \'e adicional).

Com essa  suposi\c c\~ao extra posta, estamos prontos para usar  $\eand$I.  Assim, podemos continuar nossa prova: 
	\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
			\have{rl}{R \eand L}\ai{r, l}
%			\close
%		\have{con}{L \eif (R \eand L)}\ci{l-rl}
	\end{fitchproof}
Mostramos  agora  que,  com a suposi\c c\~ao adicional `$L$', podemos obter `$R \eand L$'. Assim, podemos concluir que, se temos `$L$', ent\~ao obtemos `$R \eand L$'. Ou, mais brevemente, podemos concluir  `$L \eif (R \eand L)$':
	\begin{fitchproof}
		\hypo{r}{R}
		\open
			\hypo{l}{L}
			\have{rl}{R \eand L}\ai{r, l}
			\close
		\have{con}{L \eif (R \eand L)}\ci{l-rl}
	\end{fitchproof}
Observe que voltamos a usar uma linha vertical na esquerda.   \emph{Descartamos}   a suposi\c c\~ao adicional, `$L$',  pois o condicional ele pr\'oprio segue apenas de nossa suposi\c c\~ao original, `$R$'.

 O padr\~ao geral usado aqui \'e o seguinte. Primeiro adicionamos uma suposi\c c\~ao, $\meta{A}$; 
e desta suposi\c c\~ao  adicional, provamos~$\meta{B}$. Neste caso, sabemos o seguinte: se~$\meta{A}$ \'e verdadeira, ent\~ao ~$\meta{B}$ tamb\'em \'e verdadeira.  Isto est\'a envolvido na regra de introdu\c c\~ao do condicional:


\factoidbox{
	\begin{fitchproof}
		\open
			\hypo[i]{a}{\meta{A}} 
			\have[j]{b}{\meta{B}}
		\close
		\have[\ ]{ab}{\meta{A}\eif\meta{B}}\ci{a-b}
	\end{fitchproof}}
Pode haver tantas linhas quantas voc\^e quiser entre as linhas $i$ and $j$.  

Apresentaremos uma segunda ilustra\c c\~ao da regra $\eif$I em ac\~ao. Vamos considerar  agora o seguinte argumento:
	$$P \eif Q, Q \eif R \therefore P \eif R$$
Vamos come\c car listando \emph{ambas} as nossas premissas. Ent\~ao, como queremos chegar a um condicional (nomeadamente `$P \eif R$'),  assumimos adicionalmente o antecedente deste condicional. Assim nossa prova principal come\c ca: 

\begin{fitchproof}
	\hypo{pq}{P \eif Q}
	\hypo{qr}{Q \eif R}
	\open
		\hypo{p}{P}
	\close
\end{fitchproof}
Observe que disponibilizamos `$P$',  tratando-a como uma suposi\c c\~ao adicional.  
Agora, podemos usar a regra  {\eif}E na primeira premissa e obter `$Q$'. Novamente, podemos usar  a regra {\eif}E na segunda premissa e obter R. Assim, assumindo `$P$'  conseguimos provar `$R$',   ent\~ao aplicamos a regra {\eif}I  - descartando `$P$' - com isso, conclu\'imos a prova.  Considerando tudo isso junto, temos: 


\label{HSproof}
\begin{fitchproof}
	\hypo{pq}{P \eif Q}
	\hypo{qr}{Q \eif R}
	\open
		\hypo{p}{P}
		\have{q}{Q}\ce{pq,p}
		\have{r}{R}\ce{qr,q}
	\close
	\have{pr}{P \eif R}\ci{p-r}
\end{fitchproof}

%%%%%% --------------------------------- 26.5   Suposicoes adicionais  e subprovas 

\section{Suposi\c c\~oes adicionais  e subprovas}
A regra $\eif$I invocou a ideia de criar  suposi\c c\~oes adicionais.   Isto precisa ser manuseado com muito cuidado. Considere esta prova:
\begin{fitchproof}
	\hypo{a}{A}
	\open
		\hypo{b1}{B}
		\have{b2}{B} \by{R}{b1}
	\close
	\have{con}{B \eif B}\ci{b1-b2}
\end{fitchproof}
Isso est\'a perfeitamente de acordo com as regras  que j\'a temos dispon\'iveis e n\~ao deve parecer particularmente estranho.   Como `$B \eif B$'  \'e uma tautologia, nenhuma premissa particular deve ser exigida para prov\'a-la.

Vamos tentar agora continuar a prova como segue: 


\begin{fitchproof}
	\hypo{a}{A}
	\open
		\hypo{b1}{B}
		\have{b2}{B} \by{R}{b1}
	\close
	\have{con}{B \eif B}\ci{b1-b2}
	\have{b}{B} \by{tentativa impr\'opria}{}
	\have [\ ]{x}{} \by{de invocar $\eif$E}{con, b2}
\end{fitchproof}
Se pud\'essemos fazer isso, seria um desastre. Poder\'iamos provar qualquer  letra sentencial a partir de qualquer outra. Entretanto, se  voc\^e me diz que Ana \'e inteligente  (simbolizada por `$A$'),  n\~ao dever\'iamos ser capazes de concluir que a rainha bela estava feliz (simbolizada por `$B$')!   Devemos ser proibidos de fazer isso, mas como devemos implementar essa proibi\c c\~ao?

Podemos descrever o processo de fazer uma suposi\c c\~ao adicional como um de efetuar  uma \emph{subprova}: uma prova subsidi\'aria dentro da prova principal. Quando come\c camos a subprova, tra\c camos uma outra linha vertical para indicar que n\~ao estamos mais na prova principal. Ent\~ao, escrevemos uma suposi\c c\~ao sobre qual a subprova ser\'a baseada.  Uma subprova pode ser essencialmente pensada como esta quest\~ao: \emph{o que poder\'iamos mostrar se tamb\'em fizermos esta suposi\c c\~ao adicional?}

Quando estamos trabalhando dentro da subprova, podemos nos referir a suposi\c c\~ao adicional que colocamos ao introduzir a subprova,  e a qualquer coisa que obtivemos de nossas suposi\c c\~oes originais (afinal de contas, essas suposi\c c\~oes originais ainda est\~ao em vigor). Entretanto, em algum momento,  queremos parar de usar a suposi\c c\~ao adicional: queremos sair da subprova e retornar a prova principal. Para indicar que retornamos a prova principal, a linha vertical da subprova chega ao fim.  Neste ponto, dizemos que a subprova est\'a \define{fechada}. Com a subprova fechada, deixamos de lado a suposi\c c\~ao.  Logo ser\'a ileg\'itimo recorrer a qualquer coisa que dependa dessa suposi\c c\~ao adicional. Assim, estipulamos:


\factoidbox{Para citar uma linha individual quando aplicamos uma regra:
\begin{enumerate}
\item a linha deve vir antes da linha onde a regra \'e aplicada, e
\item n\~ao ocorrer dentro de uma subprova que j\'a tenha sido fechada antes da linha onde a regra foi aplicada.
\end{enumerate}}
Esta estipula\c c\~ao exclui a desastrosa tentativa da prova acima. A regra $\eif$E exige que citemos duas linhas anteriores da prova. Na prova pretendida, acima, uma dessas linhas (nomeadamente, linha~$4$)  ocorre dentro de uma subprova que (pela linha~$5$) j\'a tinha sido fechada. Isto \'e ileg\'itimo. 

O fechamento de uma subprova \'e chamado de \define{descarte} da suposi\c c\~ao desta subprova. Assim, fica estabelecido: \emph{voc\^e n\~ao pode se referir a nada que foi obtido usando suposi\c c\~oes descartadas}. 

Subprovas, ent\~ao, nos permitem pensar sobre o que poder\'iamos mostrar,  se fizermos suposi\c c\~oes adicionais.  O que podemos  tirar disso n\~ao \'e surpreendente: no curso de uma prova, temos que acompanhar com muito cuidado as suposi\c c\~oes que estamos fazendo uso, em qualquer momento.  Nosso sistema de prova faz isso graficamente bem. (De fato, \'e exatamente por isso que escolhemos usar  \emph{este}  sistema de prova.)

Uma vez que come\c camos a pensar sobre o que podemos mostrar fazendo suposi\c c\~oes adicionais, nada nos impede de perguntar  o que poder\'iamos mostrar se fiz\'essemos  \emph{ainda mais}  suposi\c c\~oes?  Isso pode nos motivar a introduzir uma subprova dentro de uma subprova.  Aqui est\'a um exemplo usando apenas as regras que consideramos at\'e agora:


\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
		\hypo{c}{C}
		\have{ab}{A \eand B}\ai{a,b}
	\close
	\have{cab}{C \eif (A \eand B)}\ci{c-ab}
\close
\have{bcab}{B \eif (C \eif (A \eand B))}\ci{b-cab}
\end{fitchproof}
 Observe que a cita\c c\~ao na linha~$4$ se refere \`a suposi\c c\~ao inicial (na linha 1) e uma suposi\c c\~ao de uma subprova (na linha~$2$). Isso est\'a perfeitamente em ordem, pois nenhuma suposi\c c\~ao foi descartada no momento (isto \'e, pela linha~$4$).  

Mais uma vez, por\'em, precisamos acompanhar cuidadosamente o que estamos assumindo a cada momento. Suponha que tentamos continuar a prova da seguinte maneira:
\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
		\hypo{c}{C}
		\have{ab}{A \eand B}\ai{a,b}
	\close
	\have{cab}{C \eif (A \eand B)}\ci{c-ab}
\close
\have{bcab}{B \eif(C \eif (A \eand B))}\ci{b-cab}
\have{bcab}{C \eif (A \eand B)}\by{tentativa impr\'opria}{}
\have [\ ]{x}{} \by{de invocar $\eif$I}{c-ab}
\end{fitchproof}
 Isso seria terr\'ivel. Se tiv\'essemos dito  que Ana \'e inteligente, voc\^e n\~ao seria capaz de deduzir que, se Carla \'e inteligente (simbolizada por  `$C$') ent\~ao \emph{ambas} Ana \'e inteligente  e a rainha Bela estava feliz. Mas isso \'e exatamente o que essa prova sugeriria, se fosse permiss\'ivel.

O problema essencial \'e que a subprova que come\c cou com a suposi\c c\~ao~`$C$' dependia crucialmente do fato de termos assumido `$B$' como uma suposi\c c\~ao na linha~$2$.  Pela linha~$6$, \emph{descartamos} a suposi\c c\~ao~`$B$': entretanto,  neste ponto questionamos  o que poder\'iamos mostrar, se assum\'issemos tamb\'em `$B$'. Tentar justificar a linha~$7$ com a subprova que come\c cou com a suposi\c c\~ao~`$C$', \'e simplesmente uma trapa\c ca.  Assim estipulamos, como antes, que uma subprova s\'o pode ser citada em uma linha se ela n\~ao ocorrer dentro de outra subprova que j\'a esteja fechada nessa linha. A tentativa desastrosa da prova viola esta estipula\c c\~ao.  A subprova de linhas $3$--$4$ ocorre dentro de uma subprova que termina na linha~$5$. Portanto, n\~ao pode ser invocada na linha~$7$.


Aqui temos mais um caso que devemos excluir:
\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
	\hypo{c}{C}
	\have{bc}{B \eand C}\ai{b,c}
	\have{c2}{C}\ae{bc}
	\close
\close
\have{bcab}{B \eif C}\by{tentativa impr\'opria}{}
\have [\ ]{x}{} \by{de invocar $\eif$I}{b-c2}
\end{fitchproof}
Aqui, estamos tentando citar uma subprova que come\c ca na linha~$2$ e termina na linha~$5$ -  mas a senten\c ca na linha~$5$ depende n\~ao apenas da suposi\c c\~ao da linha~$2$, mas tamb\'em de uma outra suposi\c c\~ao (linha~$3$) que n\~ao descartamos no final da subprova.  A subprova iniciada na linha~$3$ ainda est\'a aberta na linha~$5$.  Mas $\eif$I requer que a \'ultima linha da subprova seja baseada \emph{apenas} na suposi\~ao da subprova  que est\'a sendo citada, ou seja, a subprova come\c cando na linha~$2$ (e qualquer coisa antes dela), e n\~ao nas suposi\c c\~oees de quaisquer subprovas dentro dela.  Em particular, a \'ultima linha da subprova citada n\~ao deve estar em si mesma dentro de uma subprova aninhada.


\factoidbox{Para citar uma subprova ao aplicar uma regra:
\begin{enumerate} 
\item a subprova citada deve vir inteiramente antes da aplica\c c\~ao da regra em que \'e citada,
\item a subprova citada n\~ao deve estar dentro de outra subprova fechada, que foi fechada na linha em que \'e citada, e
\item  A \'ultima linha da subprova  citada n\~ao deve ocorrer dentro de uma subprova aninhada. 
\end{enumerate}}

Um \'ultimo ponto a enfatizar como as regras podem ser aplicadas: onde uma regra exige que voc\^e cite uma linha individual, n\~ao \'e poss\'ivel citar uma subprova; e onde for necess\'ario citar uma subprova, n\~ao ser\'a poss\'ivel citar uma linha individual.  Assim, por exemplo, isso est\'a incorreto:
\begin{fitchproof}
\hypo{a}{A}
\open
	\hypo{b}{B}
	\open
	\hypo{c}{C}
	\have{bc}{B \eand C}\ai{b,c}
	\have{c2}{C}\ae{bc}
	\close
	\have{c3}{C}\by{tentativa impr\'opria}{}
\have [\ ]{x}{} \by{de invocar R}{c-c2}
\close
\have[7]{bcab}{B \eif C}\ci{b-c3}
\end{fitchproof}
Aqui, tentamos justificar $C$ na linha~$6$ como a regra de reitera\c c\~ao, mas citamos a subprova das linhas $3$--$5$. Esta subprova est\'a fechada e pode, em princ\'ipio, ser citada na linha 6.  (Por exemplo, poder\'iamos us\'a-la para justificar 
 $C \eif C$ por $\eif$I.) Por\'em,  a regra de reitera\c c\~ao~R exige que voc\^e cite uma linha individual, assim, \'e inadmiss\'ivel citar a subprova inteira (mesmo que essa subprova  contenha a sentan\c ca~$C$  que queremos reiterar).

 

\'E sempre permitido abrir uma subprova com qualquer suposi\c c\~ao.  No entanto, existem algumas estrat\'egias envolvidas na escolha eficiente de uma suposi\c c\~ao.
Iniciar uma subprova com uma suposi\c c\~ao arbitr\'aria e maluca apenas desperdi\c caria as linhas da prova.  A fim de obter um condicional usando a regra {\eif}I, por exemplo, voc\^e deve assumir o antecedente do condicional em uma subprova.

Igualmente, \'e sempre permitido fechar uma subprova (e descartar suas suposi\c c\~oes). No entanto, n\~ao ser\'a \'util faz\^e-lo at\'e que voc\^e alcance algo eficiente.  Depois que a subprova for fechada, voc\^e poder\'a citar a subprova inteira em qualquer justificativa.  As regras aplicadas a uma subprova ou subprovas, por sua vez, exigem que  a \'ultima linha da subprova seja uma senten\c ca de uma forma ou de outra.   Por exemplo, voc\^e s\'o pode citar uma subprova para $\eif$I se a linha que voc\^e est\'a justificando \'e da forma $\meta{A} \eif \meta{B}$, $\meta{A}$  \'e a suposi\~ao de sua subprova, e $\meta{B}$ \'e a \'utima linha da sua subprova.

%%%%%% ---------------------------------------------------------- 26.6   Biconditional 

\section{Bicondicional}
As regras para o bicondicional ser\~ao como vers\~oes de via de m\~ao dupla das regras para o condicional. 

Para provar `$F \eiff G$',  por exemplo, voc\^e deve ser capaz de provar `$G$' a partir da  suposi\c c\~ao `$F$' \emph{e}  provar `$F$' a partir da suposi\c c\~ao `$G$'. A regra de introdu\c c\~ao do bicondicional ({\eiff}I) requer, portanto, duas subprovas.  Esquematicamente, a regra funciona assim: 

 

\factoidbox{
\begin{fitchproof}
	\open
		\hypo[i]{a1}{\meta{A}}
		\have[j]{b1}{\meta{B}}
	\close
	\open
		\hypo[k]{b2}{\meta{B}}
		\have[l]{a2}{\meta{A}}
	\close
	\have[\ ]{ab}{\meta{A}\eiff\meta{B}}\bi{a1-b1,b2-a2}
\end{fitchproof}}
Pode haver tantas linhas quantas voc\^e quiser entre $i$ e $j$, e tantas linhas quantas voc\^e quiser entre $k$ e $l$.  Al\'em disso, as subprovas podem vir em qualquer ordem, e a segunda subprova n\~ao precisa vir imediatamente ap\'os a primeira.

A regra de elimina\c c\~ao do bicondicional({\eiff}E) permite fazer um pouco mais do que a regra do condicional.  Se voc\^e tem a senten\c ca do lado esquerdo do bicondicional, voc\^e pode obter a senten\c ca que est\'a no lado direito. E inversamente, se voc\^e tem a senten\c ca que est\'a no lado direito do bicondicional, pode obter a senten\c ca que est\'a no lado esquerdo. Assim temos:
\factoidbox{
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eiff\meta{B}}
	\have[n]{a}{\meta{A}}
	\have[\ ]{b}{\meta{B}} \be{ab,a}
\end{fitchproof}}
e igualmente:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eiff\meta{B}}
	\have[n]{a}{\meta{B}}
	\have[\ ]{b}{\meta{A}} \be{ab,a}
\end{fitchproof}}
Observe que o bicondicional, e o lado  direito ou esquerdo podem ser separados um  do outro e podem aparecer em qualquer ordem. No entanto, na cita\c c\~ao de $\eiff$E, sempre citamos o  bicondicional primeiro.

%%%%%% --------------------------------------------------------------- 26.7 Disjunao

\section{Disjun\c c\~ao}
Vamos supor que Louis seja reservado.  Ent\~ao Louis \'e reservado ou leal. Afinal, dizer que Louis \'e reservado ou leal \'e dizer algo mais fraco do que dizer que Louis \'e reservado. 

Vamos enfatizar esse ponto. Suponha que Louis seja reservado. Disto segue que  Louis \'e \emph{ou} reservado \emph{ou} vegetariano.  Igualmente,  disto segue que \emph{ou} Louis   \'e reservado \emph{ou} estudante. Tamb\'em   Igualmente segue que   \emph{ou} Louis \'e reservado ou a lua \'e redonda. Muitas dessas s\~ao infer\^encias estranhas, mas n\~ao h\'a nada \emph{logicamente} errado com elas, mesmo que eles violem todos os tipos de normas impl\'icitas de conversa\c c\~ao.

Munido com tudo isso, apresentamos as regras de introdu\c c\~ao da disjun\c c\~ao:

\factoidbox{\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{ab}{\meta{A}\eor\meta{B}}\oi{a}
\end{fitchproof}}
e
\factoidbox{\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[\ ]{ba}{\meta{B}\eor\meta{A}}\oi{a}
\end{fitchproof}}

 

Observe que $\meta{B}$ pode ser \emph{qualquer} senten\c ca, ent\~ao a seguir temos uma prova perfeitamente aceit\' avel: 
\begin{fitchproof}
	\hypo{m}{M}
	\have{mmm}{M \eor ([(A\eiff B) \eif (C \eand D)] \eiff [E \eand F])}\oi{m}
\end{fitchproof}


Observamos que a tabela de verdade para mostrar isso teria 128 linhas.

A regra da elimina\c c\~ao da disjun\c c\~ao \'e, no entanto, um pouco mais complicada Vamos supor que  Louis \'e reservado ou leal.  O que voc\^e pode concluir? Caso  Louis  n\~ao seja reservado; pode ser que ele seja leal.   Igualmente, caso  Louis  n\~ao seja leal; pode ser que ele seja reservado.  Disjun\c c\~oes, por si s\'o, s\~ao dif\'iceis de trabalhar.

Mas suponha que, de alguma forma, possamos mostrar os dois seguinte fatos: primeiro, que sendo Louis reservado implica que ele seja um economista; segundo, que sendo Louis leal implica que ele seja um economista.
Ent\~ao, se sabemos que Louis \'e reservado ou leal, ent\~ao sabemos que, seja ele o que for, Louis \'e um economista.   Esse insight pode ser expresso na regra a seguir, que \'e a regra de elimina\c c\~ao da disjun\c c\~ao  ($\eor$E):
\factoidbox{
	\begin{fitchproof}
		\have[m]{ab}{\meta{A}\eor\meta{B}}
		\open
			\hypo[i]{a}{\meta{A}} {}
			\have[j]{c1}{\meta{C}}
		\close
		\open
			\hypo[k]{b}{\meta{B}}{}
			\have[l]{c2}{\meta{C}}
		\close
		\have[ ]{c}{\meta{C}}\oe{ab, a-c1,b-c2}
	\end{fitchproof}}
Obviamente, isso \'e um pouco mais complicado do que as regras anteriores, mas o argumento \'e bastante simples. Suponha que temos uma disjun\c c\~ao, $\meta{A} \eor \meta{B}$. Suponha tamb\'em que temos duas subprovas, mostrando que $\meta{C}$ segue da suposi\c c\~ao $\meta{A}$, e que $\meta{C}$ segue da suposi\c c\~ao $\meta{B}$. Ent\~ao podemos deduzir o p\'oprio $\meta{C}$. 
 Como sempre, pode haver  tantas linhas quantas  voc\^e quiser entre   $i$ and $j$,   e tantas linhas quantas voc\^e quiser entre $k$ and $l$. Al\'em disso, as subprovas e a disjun\c c\~ao podem vir em qualquer ordem e n\~ao precisam ser vizinhas.

Alguns exemplos podem ajudar a ilustrar isso. Considere este argumento:
$$(P \eand Q) \eor (P \eand R) \therefore P$$
A prova desse exemplo pode ser executada assim:
	\begin{fitchproof}
		\hypo{prem}{(P \eand Q) \eor (P \eand R) }
			\open
				\hypo{pq}{P \eand Q}
				\have{p1}{P}\ae{pq}
			\close
			\open
				\hypo{pr}{P \eand R}
				\have{p2}{P}\ae{pr}
			\close
		\have{con}{P}\oe{prem, pq-p1, pr-p2}
	\end{fitchproof}
Agora temos  um exemplo um pouco mais dif\'icil:  
	$$ A \eand (B \eor C) \therefore (A \eand B) \eor (A \eand C)$$
Aqui est\'a uma prova correspondente a este argumento:
	\begin{fitchproof}
		\hypo{aboc}{A \eand (B \eor C)}
		\have{a}{A}\ae{aboc}
		\have{boc}{B \eor C}\ae{aboc}
		\open
			\hypo{b}{B}
			\have{ab}{A \eand B}\ai{a,b}
			\have{abo}{(A \eand B) \eor (A \eand C)}\oi{ab}
		\close
		\open
			\hypo{c}{C}
			\have{ac}{A \eand C}\ai{a,c}
			\have{aco}{(A \eand B) \eor (A \eand C)}\oi{ac}
		\close
	\have{con}{(A \eand B) \eor (A \eand C)}\oe{boc, b-abo, c-aco}
	\end{fitchproof}
 

N\~ao se assuste se voc\^e acha que n\~ao seria capaz de fazer essa prova. A habilidade de fazer novas provas vem com a pr\'atica, e abordaremos algumas estrat\'egias para construuir provas no cap\'itulo \ref{s:stratTFL}. A quest\~ao principal nesta fase \'e se, olhando a prova, voc\^e pode reconhecer que ela est\'a em conformidade com as regras que estabelecemos.  Isso envolve apenas verificar todas as linhas e garantir que elas sejam justificadas de acordo com as regras que estabelecemos.

%%%%%% -------- ------------- ---------- ------- ------ ------  26..8  Contradicao e negacao

\section{Contradi\c c\~ao e nega\c c\~ao}

Trataremos agora da nega\c c\~ao, o nosso  último conectivo. Entretanto, temos que fazer mais esfor\c cos para lidar com ele, pois precisamos conectar nega\c c\~ao e  \emph{contradi\c c\~ao}. 

Uma forma eficaz de argumentar \'e demonstrar que o seus oponentes se contradizem. Nesse ponto, voc\^e os tem sob controle. Eles t\^em que desistir de pelo menos uma de suas suposi\c c\~oes. Vamos usar essa ideia em nosso sistema de prova, adicionando um novo s\'imbolo, `$\ered$', \`as nossas provas. Esse s\'imbolo deve ser lido como algo como `contradi\c c\~ao!'\ ou `redu\c c\~ao!'\ ou `isto \'e um absurdo!'  Podemos usar   a regra para a introdu\c c\~ao desse s\'imbolo sempre que nos contradizermos explicitamente, ou seja, sempre que encontrarmos uma senten\c ca e sua nega\c c\~ao aparecendo em nossa prova:
\factoidbox{
\begin{fitchproof}
  \have[m]{na}{\enot\meta{A}}
  \have[n]{a}{\meta{A}}
  \have[ ]{bot}{\ered}\ne{na, a}
\end{fitchproof}}
N\~ao importa em que ordem a senten\c ca e sua nega\c c\~ao aparecem, e elas n\~ao precisam aparecer em linhas vizinhas. No entanto, sempre citamos o n\'umero da linha da nega\c c\~ao primeiro, seguido pelo da senten\c ca em que foi negada.

Obviamente, existe um v\'inculo estreito entre contradi\c c\~ao e nega\c c\~ao. 
A regra $\enot$E permite obter uma contradi\c c\~ao expl\'icita, ~$\ered$,  
 a partir de duas senten\c cas contradit\'orias, $\meta{A}$ e sua nega\c c\~ao $\enot \meta{A}$. 
Escolhemos essa regra como uma regra de elimina\c c\~ao pelo seguinte  motivo: \'e a regra mais b\'asica que nos permite passar de uma premissa que contenha uma nega\c c\~ao, ou seja $\enot\meta{A}$, 
para uma senten\c ca que n\~ao a contenha, ou seja,  $\ered$.  Portanto, \'e uma regra que \emph{elimina}~$\enot$.


Dissemos que  `$\ered$'  deve ser visto como uma  `contradi\c c\~ao!', mas isso n\~ao nos diz muito sobre este s\'imbolo. Existem, aproximadamente, tr\^es maneiras de abordar o s\'imbolo `$\ered$'.
	\begin{ebullet}
		\item Podemos considerar `$\ered$'. como uma nova senten\c ca at\^omica da LVF, mas que s\'o pode ter o valor de verdade Falso.  
		\item Podemos considerar  `$\ered$' como uma abrevia\c c\~ao de alguma contradi\c c\~ao can\^onica, como `$A \eand \enot A$'. Isso ter\'a o mesmo efeito que o descrito acima - obviamente, `$A \eand \enot A$' sempre tem o valor de verdade Falso - mas significa que, oficialmente, n\~ao precisamos adicionar um novo s\'imbolo a LVF.
		\item Podemos considerar `$\ered$', n\~ao como um s\'imbolo da LVF, mas como um \emph{sinal de pontua\c c\~ao} que aparece em nossas provas.  (Digamos que \'e compar\'avel aos n\'umeros das linhas e \`as linhas verticais.)
			\end{ebullet}
			
Existe algo filosoficamente  muito atraente na terceira op\c c\~ao, mas aqui adotaremos \emph{oficialmente} a primeira. `$\ered$'  deve ser lido como uma letra sentencial que \'e sempre falsa. Isso significa que podemos manipul\'a-lo, em nossas provas, como qualquer outra senten\c ca.

Ainda precisamos estabelecer uma regra para a introdu\c c\~ao da nega\c c\~ao. A regra \'e muito simples: se assumirmos algo que leva a uma contradi\c c\~ao, a suposi\c c\~ao deve estar errada. Esse pensamento motiva a seguinte regra:

\factoidbox{\begin{fitchproof}
\open
	\hypo[i]{a}{\meta{A}}
	\have[j]{nb}{\ered}
\close
\have[\ ]{na}{\enot\meta{A}}\ni{a-nb}
\end{fitchproof}}
Pode haver tantas linhas quantas voc\^e desejar entre $i$ and $j$. Para ver isso na pr\'atica e interagir com a nega\c c\~ao, considere esta prova: 
	\begin{fitchproof}
		\hypo{d}{D}
		\open
			\hypo{nd}{\enot D}
			\have{ndr}{\ered}\ne{nd, d}
		\close
		\have{con}{\enot\enot D}\ni{nd-ndr}
	\end{fitchproof}

Se a suposi\c c\~ao de que $\meta{A}$ \'e verdadeira leva a uma contradi\c c\~ao, $\meta{A}$ n\~ao pode ser verdadeira, isto \'e, deve ser falsa, ou seja, $\enot\meta{A}$ deve ser verdadeira. Obviamente, se a suposi\c c\~ao de que $\meta{A}$ \'e falsa (ou seja, a suposi\c c\~ao de que $\enot\meta{A}$ \'e verdadeira)  leva a uma contradi\c c\~ao, ent\~ao $\meta{A}$ n\~ao pode ser falsa, ou seja, $\meta{A}$ deve ser verdadeira. Portanto, podemos considerar a seguinte regra:
\factoidbox{\begin{fitchproof}
\open
	\hypo[i]{a}{\enot\meta{A}}
	\have[j]{nb}{\ered}
\close
\have[\ ]{na}{\meta{A}}\ip{a-nb}
\end{fitchproof}}
Essa regra \'e chamada de \emph{prova indireta}, pois permite provar $\meta{A}$  indiretamente, assumindo sua nega\c c\~ao. Formalmente, a regra \'e muito semelhante a $\enot$I, mas $\meta{A}$ e $\enot\meta{A}$ mudaram de lugar. Como $\enot\meta{A}$ n\~ao \'e a conclus\~ao da regra, n\~ao estamos introduzindo~$\enot$, ent\~ao  IP n\~ao \'e uma regra que introduz qualquer conectivo. Tamb\'em n\~ao elimina um conectivo, pois n\~ao possui premissas aut\^onomas que contenham~$\enot$, apenas uma subprova com uma suposi\c c\~ao da forma~$\enot\meta{A}$. Por outro lado, $\enot$E tem uma premissa da forma $\enot\meta{A}$: \'e por isso que $\enot$E elimina~$\enot$, mas a regra IP n\~ao.\footnote{Existem l\'ogicos que n\~ao aceitam a regra IP, mas aceitam $\enot$E. Eles s\~ao chamados de "intuicionistas". Os intuicionistas n\~ao aceitam nossa suposi\c c\~ao b\'asica de que cada senten\c ca tem um dos dois valores de verdade, verdadeiro ou falso. Eles tamb\'em acham que $\enot$ funciona diferentemente - para eles, uma prova do $\ered$ a partir de $\meta{A}$ garante $\enot \meta{A}$, mas uma prova do $\ered$ a partir de $\enot\meta{A}$ n\~ao garante que~$\meta{A}$, mas apenas $\enot\enot\meta{A}$. Portanto, para eles, $\meta{A}$ e $\enot\enot\meta{A}$ n\~ao s\~ao equivalentes.}


Usando $\enot$I, fomos capazes de dar uma prova de $\enot\enot\meta{D}$ a partir de $\meta{D}$. Usando IP, podemos ir na outra dire\c c\~ao (com essencialmente a mesma prova).
	\begin{fitchproof}
		\hypo{d}{\enot\enot D}
		\open
			\hypo{nd}{\enot D}
			\have{ndr}{\ered}\ne{d, nd}
		\close
		\have{con}{D}\ip{nd-ndr}
	\end{fitchproof}

Precisamos de uma \'ultima regra. \'E uma esp\'ecie de regra de elimina\c c\~ao para `$\ered$', e conhecida como \emph{explos\~ao}.\footnote{O nome latino para esse princ\'ipio \'e  \emph{ex contradictione quod libet}, ``da contradi\c c\~ao, qualquer coisa.''}  Se obtemos uma contradi\c c\~ao, simbolizada por `$\ered$', podemos concluir o que quisermos.  Como isso pode ser motivado, como uma regra de argumenta\c c\~ao? Bem, considere o dispositivo ret\'orico `\ldots e se \emph{isso for} verdade, eu comerei o meu chap\'eu'. Como as contradi\c c\~oes simplesmente n\~ao podem ser verdadeiras, se isto \emph{for} verdadeiro, n\~ao apenas comerei o meu chap\'eu, como eu terei isto tamb\'em. Aqui est\'a a regra formal:
\factoidbox{\begin{fitchproof}
\have[m]{bot}{\ered}
\have[ ]{}{\meta{A}}\re{bot}
\end{fitchproof}}
Observe que  \meta{A} pode ser \emph{qualquer} senten\c ca.

A regra de explos\~ao \'e um pouco estranha. Parece que  \meta{A}  chega em nossa prova como um coelho que sai de uma cartola. Ao tentar encontrar provas, \'e muito tentador tentar us\'a-lo em qualquer lugar, pois parece muito poderoso. Resista a essa tenta\c c\~ao: voc\^e s\'o pode aplic\'a-la quando j\'a tiver~$\ered$!   E voc\^e obt\'em $\ered$   somente quando suas suposi\c c\~oes s\~ao contradit\'orias.
 

Ainda assim, n\~ao \'e estranho que, de uma contradi\c c\~ao, alguma coisa deva seguir? N\~ao de acordo com nossa no\c c\~ao de sustenta\c c\~ao e validade. Para, \meta{A} sustenta \meta{B} se e somente se  n\~ao exise nenhuma valora\c c\~ao de letras sentenciais que  tornam \meta{A} verdadeira e \meta{B} falsa ao mesmo tempo. Mas $\ered$  \'e uma contradi\c c\~ao, nunca \'e verdadeiro, seja qual for a valora\c c\~ao das letras sentenciais.  Como n\~ao existe nenhuma valora\c c\~ao que faz $\ered$ verdadeiro, claro que tamb\'em n\~ao existe nenhuma valora\c c\~ao que faz  $\ered$  verdadeiro e \meta{B} falsa! Ent\~ao, de acordo com a nossa defini\c c\~ao de sustenta\c c\~ao,  $\ered \entails \meta{B}$,  para qualquer que seja \meta{B}. Uma contradi\c c\~ao sustenta qualquer coisa.\footnote{Existem alguns l\'ogicos que n\~ao aceitam isso. Eles acham que se \meta{A} implica \meta{B}, deve haver alguma \emph{conex\~ao relevante} entre \meta{A} e \meta{B}, mas n\~ao h\'a uma entre $\ered$ e alguma senten\c ca arbitr\'aria~\meta{B}. Portanto, esses l\'ogicos desenvolvem outras l\'ogicas "relevantes" nas quais  a regra de explos\~ao \'e n\~ao permitida.}

\emph{Estas s\~ao todas as regras b\'asicas para o sistema de prova da LVF.}

%%%%%% ----------------------------------------——-CAP 26 -  EXERCICIOS   ------- -------   

\practiceproblems

\problempart
As duas "provas" a seguir est\~ao  \emph{incorretas}. Explique quais s\~ao os seus erros.
\begin{fitchproof}
\hypo{abc}{(\enot L \eand A) \eor L}
\open
\hypo{nla}{\enot L \eand A}
\have{nl}{\enot L}\ae{nl}
	\have{a}{A}\ae{abc}
\close
\open
	\hypo{l}{L}
	\have{red}{\ered}\ne{nl, l}
	\have{a2}{A}\re{red}
\close
\have{con}{A}\oe{abc, nla-a, l-a2}
\end{fitchproof}

\begin{fitchproof}
\hypo{abc}{A \eand (B \eand C)}
\hypo{bcd}{(B \eor C) \eif D}
\have{b}{B}\ae{abc}
\have{bc}{B \eor C}\oi{b}
\have{d}{D}\ce{bc, bcd}
\end{fitchproof}

\problempart
As tr\^es provas a seguir est\~ao sem cita\c c\~oes (n\'umeros de regra e linha). Adicione-os, para transform\'a-las  em provas fidedignas.  Al\'em disso, anote o argumento que corresponde a cada prova.
\begin{multicols}{2}
\begin{fitchproof}
\hypo{ps}{P \eand S}
\hypo{nsor}{S \eif R}
\have{p}{P}%\ae{ps}
\have{s}{S}%\ae{ps}
\have{r}{R}%\ce{nsor, s}
\have{re}{R \eor E}%\oi{r}
\end{fitchproof}

\begin{fitchproof}
\hypo{ad}{A \eif D}
\open
	\hypo{ab}{A \eand B}
	\have{a}{A}%\ae{ab}
	\have{d}{D}%\ce{ad, a}
	\have{de}{D \eor E}%\oi{d}
\close
\have{conc}{(A \eand B) \eif (D \eor E)}%\ci{ab-de}
\end{fitchproof}

\begin{fitchproof}
\hypo{nlcjol}{\enot L \eif (J \eor L)}
\hypo{nl}{\enot L}
\have{jol}{J \eor L}%\ce{nlcjol, nl}
\open
	\hypo{j}{J}
	\have{jj}{J \eand J}%\ai{j}
	\have{j2}{J}%\ae{jj}
\close
\open
	\hypo{l}{L}
	\have{red}{\ered}%\ne{nl, l}
	\have{j3}{J}%\re{red}
\close
\have{conc}{J}%\oe{jol, j-j2, l-j3}
\end{fitchproof}
\end{multicols}

\solutions
\problempart
\label{pr.solvedTFLproofs}
Apresente uma prova para cada um dos doze seguintes argumentos:
\begin{earg}
\item $J\eif\enot J \therefore \enot J$
\item $Q\eif(Q\eand\enot Q) \therefore \enot Q$
\item $A\eif (B\eif C) \therefore (A\eand B)\eif C$
\item $K\eand L \therefore K\eiff L$
\item $(C\eand D)\eor E \therefore E\eor D$
\item $A\eiff B, B\eiff C \therefore A\eiff C$
\item $\enot F\eif G, F\eif H \therefore G\eor H$
\item $(Z\eand K) \eor (K\eand M), K \eif D \therefore D$
\item $P \eand (Q\eor R), P\eif \enot R \therefore Q\eor E$
\item $S\eiff T \therefore S\eiff (T\eor S)$
\item $\enot (P \eif Q) \therefore \enot Q$
\item $\enot (P \eif Q) \therefore P$
\end{earg}

%%%%%% ---------------------------------------------------CAPITULO 27   -   Construindo provas 

\chapter{Construindo provas}\label{s:stratTFL}

 N\~ao existe uma receita simples para encontrar provas e n\~ao h\'a substituto para a pr\'atica. Aqui, entretanto, apresentaremos algumas regras pr\'aticas e estrat\'egias a serem lembradas.

%%%%%% ----------------  27.1  Trabalhando do fim para o come\c co para chegar onde queremos. 
\section{Trabalhando do fim para o come\c co para chegar onde queremos}

 Voc\^e est\'a tentando encontrar uma prova de alguma conclus\~ao~$\meta{C}$, que ser\'a a \'ultima linha da sua prova. A primeira coisa que voc\^e faz \'e olhar para~$\meta{C}$ e perguntar qual \'e a regra de introdu\c c\~ao para seu principal operador l\'ogico. Isso lhe d\'a uma ideia do que deve acontecer \emph{antes} da \'ultima linha da prova. 

 As justificativas para a regra de introdu\c c\~ao requerem uma ou duas outras senten\c cas acima da \'ultima linha, ou uma ou duas subprovas. Al\'em disso, voc\^e pode dizer a partir de~$\meta{C}$ quais s\~ao essas senten\c cas ou quais s\~ao as suposi\c c\~oes e conclus\~oes das subprovas. Em seguida, voc\^e pode escrever essas senten\c cas ou delinear as subprovas acima da \'ultima linha e trat\'a-las como seus novos objetivos.

 Por exemplo: se sua conclus\~ao \'e um condicional $\meta{A}\eif\meta{B}$,  planeje usar a regra {\eif}I.  Isso requer iniciar uma subprova na qual voc\^e assume~\meta{A}. A subprova deve terminar com~\meta{B}. Depois, continue pensando no que voc\^e deve fazer para obter $\meta{B}$ dentro dessa subprova,  e como voc\^e pode usar a suposi\c c\~ao~$\meta{A}$.

 Se seu objetivo for provar uma conjun\c c\~ao, um condicional ou uma senten\c ca negada, voc\^e deve come\c car trabalhando dessa maneira, do fim para o come\c co. Descreveremos o que voc\^e deve fazer em cada um desses casos em detalhes.
 
\subsection*{Provando uma conjn\c c\~ao do fim para o come\c co}

Se quisermos provar  $\meta{A} \eand \meta{B}$,  trabalhando do fim para o come\c co, significa que devemos escrever $\meta{A} \eand \meta{B}$ na parte inferior da prova e tentar prov\'a-la usando a regra $\eand$I. No topo de uma folha de papel, escreveremos as premissas  da prova, se houver alguma. E  na parte inferior, escrevemos a senten\c ca que queremos provar. Se for uma conjun\c c\~ao, vamos prov\'a-la usando $\eand$I.
  \begin{fitchproof}
	\have{1}{\meta{P}_1}
	\ellipsesline 
	\hypo[k]{k}{\meta{P}_k}
\ellipsesline
    \have[n]{n}{\meta{A}}{} 
    \ellipsesline 
	\have[m]{m}{\meta{B}}
    \have{4}{\meta{A} \eand \meta{B}}\ai{n,m}
  \end{fitchproof}
Para $\eand$I, precisamos provar primeiro $\meta{A}$, depois provar $\meta{B}$. Na \'ultima linha, temos que citar as linhas em que provamos $\meta{A}$ e  $\meta{B}$, e usar~$\eand$I. As partes da prova marcadas por $\vdots$ ainda precisam ser preenchidas. Vamos marcar os n\'umeros de linha $m$, $n$ e $k$ por enquanto. Quando a prova estiver conclu\'ida, esses espa\c cos reservados podem ser substitu\'idos por n\'umeros reais.
 

\subsection*{Provando um condicional do fim para o come\c co}

Se nosso objetivo for provar um condicional,  $\meta{A} \eif \meta{B}$, teremos que usar a regra $\eif$I. Isso requer uma subprova come\c cando com $\meta{A}$ e terminando com~$\meta{B}$. Vamos configurar nossa prova da seguinte forma:
\begin{fitchproof}
\open
\hypo[n]{2}{\meta{A}}
\ellipsesline 
\have[m]{3}{\meta{B}}
\close
\have{4}{\meta{A} \eif \meta{B}}\ci{2-3}
\end{fitchproof} 
Mais uma vez, deixaremos espa\c cos reservados entre as  linhas numeradas por $m$ e $n$. Vamos registrar a \'ultima infer\^encia como uma aplica\c c\~ao da regra $\eif$I, citando a subprova.

\subsection*{Provando uma senten\c ca negada do fim para o come\c co}

Se queremos provar $\enot \meta{A}$, devemos usar a regra $\enot$I.
\begin{fitchproof}
\open
\hypo[n]{2}{\meta{A}}
\ellipsesline 
\have[m]{3}{\ered}
\close
\have{4}{\enot \meta{A}}\ni{2-3}
\end{fitchproof} 
Para aplicar a regra $\enot$I, temos que iniciar uma subprova com a suposi\c c\~ao $\meta{A}$; a \'ultima linha da subprova tem que ser $\ered$.  Vamos citar a subprova e usar~$\enot$I como regra.  

Aconselhamos a trabalhar do fim para o come\c co,  o m\'aximo que puder. Assim, se voc\^e est\'a trabalhando do fim para o come\c co, para provar $\meta{A} \eif \meta{B}$ e construiu uma subprova com o objetivo de  provar $\meta{B}$. Agora olhe para a senten\c ca~$\meta{B}$. Se ela for uma conjun\c c\~ao, por exemplo, trabalhe do fim para o come\c co e insira na subprova os dois conjuntos dessa conjun\c c\~ao,  etc.


\subsection*{Provando uma  disjun\c c\~ao do fim para o come\c co}

Obviamente, voc\^e tamb\'em pode trabalhar do fim para o come\c co para provar  uma disjun\c c\~ao $\meta{A} \eor \meta{B}$, se esse for seu objetivo. A regra
 $\eor$I exige que voc\^e tenha um dos disjuntos para deduzir $\meta{A} \eor \meta{B}$.
 Assim, escolha um dos disjuntos e,  em seguida,  procure uma prova para esse  disjunto  que voc\^e escolheu:
\begin{fitchproof}
	\ellipsesline
	\have[n]{2}{\meta{A}} 
	\have{3}{\meta{A} \eor \meta{B}}\oi{2}
\end{fitchproof}
 No entanto, voc\^e pode n\~ao conseguir provar o  disjunto que escolheu. Nesse caso, voc\^e precisa voltar atr\'as, quando voc\^e n\~ao conseguir preencher as linha anteriores a $n$, isto \'e, em $\vdots$, apague tudo e tente com o outro disjunto:
\begin{fitchproof}
	\ellipsesline 
	\have[n]{2}{\meta{B}} 
	\have{3}{\meta{A} \eor \meta{B}}\oi{2}
\end{fitchproof}
 Obviamente, apagar tudo e recome\c car \'e frustrante;  assim, voc\^e deve evitar fazer isto. Se seu objetivo \'e  provar uma disjun\c c\~ao,  voc\^e \emph{n\~ao deve come\c car} trabalhando do fim para o come\c co: tente trabalhar primeiro do in\'icio para o fim e s\'o use a estrat\'egia  do fim para o come\c co para $\eor$I   quando essa \'ultima n\~ao funcionar mais (e trabalhar do fim para o come\c co quando aplicar as regras $\eand$I, $\eif$I, e $\enot$I) 

%%%%%% -------------------  27.2  Trabalhando do come\c co para o fim a partir do que voc\^e tem

\section{Trabalhando do come\c co para o fim a partir do que voc\^e tem}

Sua prova pode ter premissas. E se voc\^e trabalhou de tr\'as para frente para provar um condicional ou uma senten\c ca negada, voc\^e inseriu subprovas com uma suposi\c c\~ao e tentou provar uma senten\c ca final na subprova.  Essas premissas e suposi\c c\~oes s\~ao senten\c cas as quais voc\^e pode trabalhar do come\c co para o fim para preencher as etapas ausentes na sua prova. Isso significa, aplicar regras de  elimina\c c\~ao para os principais operadores dessas senten\c cas. A forma das regras dir\~ao o que voc\^e dever\'a fazer.
 

\subsection*{Trabalhando do come\c co para o fim a partir de uma conjun\c c\~ao}

Para usar a estrat\'egia de provar do  come\c co para fim a partir de uma senten\c ca da forma $\meta{A} \eand \meta{B}$, usamos $\eand$E. Essa regra nos permite fazer duas coisas: inferir $\meta{A}$, e inferir $\meta{B}$. Assim, em uma prova em que temos $\meta{A} \eand \meta{B}$, podemos avan\c car escrevendo $\meta{A}$ e/ou $\meta{B}$  imediatamente abaixo da conjun\c c\~ao:

\begin{fitchproof}
  \have[n]{1}{\meta{A} \eand \meta{B}}
  \have{2}{\meta{A}}\ae{1}
  \have{3}{\meta{B}}\ae{1}
\end{fitchproof}
Geralmente fica claro a situa\c c\~ao espec\'ifica que voc\^e vai  precisar usar uma das senten\c cas \meta{A} ou \meta{B}.  Mas, n\~ao custa nada escrever as  duas senten\c cas. 

\subsection*{Trabalhando do come\c co para o fim a partir de uma disjun\c c\~ao}

Trabalhar do come\c co para o fim a partir de uma disjun\c c\~ao funciona um pouco diferente. Para usar uma disjun\c c\~ao, usamos a regra $\eor$E e para aplicar essa regra n\~ao basta saber quais s\~ao os disjuntos da disjun\c c\~ao que queremos usar. Tamb\'em devemos ter em mente o que queremos provar. Suponha que queremos provar~$\meta{C}$,  e temos $\meta{A} \eor B$ para trabalhar. (Que $\meta{A} \eor B$ pode ser uma premissa da prova, uma suposi\c c\~ao de uma subprova ou algo j\'a provado.) Para poder aplicar a regra $\eor$E teremos de inserir duas subprovas:
 

\begin{fitchproof}
	\have[n]{1}{\meta{A} \eor \meta{B}}
	\open
	\hypo{2}{\meta{A}} 
	\ellipsesline 
	\have[m]{3}{\meta{C}}
	\close 
	\open
	\hypo{4}{\meta{B}}
	\ellipsesline
	\have[k]{5}{\meta{C}}
	\close
	\have{6}{\meta{C}}\oe{1,(2)-3,(4)-5} 
\end{fitchproof} 
A primeira subprova come\c ca com o primeiro disjunto $\meta{A}$, e termina com a senten\c ca que estamos procurando, $\meta{C}$. A segunda subprova come\c ca com o outro disjunto $\meta{B}$, e tamb\'em termina com  a senten\c ca~$\meta{C}$. Cada uma dessas subprovas deve ser preenchida ainda mais. Podemos ent\~ao justificar a senten\c ca $\meta{C}$ usando $\eor$E, citando a linha com $\meta{A} \eor \meta{B}$ e as duas subprovas.

\subsection*{ Trabalhando do come\c co para o fim a partir de um condicional}

Para usar um condicional $\meta{A} \eif \meta{B}$, voc\^e tamb\'em precisa do antecedente $\meta{A}$ para aplicar a regra~$\eif$E. Assim, para trabalhar do come\c co para o fim a partir de um condicional, voc\^e obter\'a $\meta{B}$, justificando com a regra $\eif$E, e estabelecendo $\meta{A}$  como um  novo subobjetivo.
 

\begin{fitchproof}
	\have[n]{1}{\meta{A} \eif \meta{B}}
	\ellipsesline 
	\have[m]{2}{\meta{A}}
	\have{3}{\meta{B}}\ce{1,2} 
\end{fitchproof}

\subsection*{ Trabalhando do come\c co para o fim a partir de uma senten\c ca negada}

Finalmente, para usar uma senten\c ca negada $\enot \meta{A}$, voc\^e deve aplicar a regra $\enot$E. Isto requer, al\'em de  $\enot \meta{A}$,  tamb\'em a senten\c ca correspondente~$\meta{A}$ sem a nega\c c\~ao. A senten\c ca que voc\^e ir\'a obter \'e sempre a mesma: $\ered$. Assim, trabalhar do come\c co para o fim a partir de uma senten\c ca negada funciona especialmente bem dentro de uma subprova que voc\^e deseja usar em uma aplica\c c~ao da regra $\enot$I (ou IP).  Voc\^e trabalha a partir de $\enot \meta{A}$ se voc\^e j\'a tem $\enot \meta{A}$ e deseja provar~$\ered$. Para isso, voc\^e estabelece $\meta{A}$ como um novo subobjetivo.
\begin{fitchproof}
	\have[n]{1}{\enot \meta{A}}
	\ellipsesline 
	\have[m]{2}{\meta{A}}
	\have{3}{\ered}\ne{1,2} 
\end{fitchproof}

%%%%%% -----------------------        27.3  Estrat\'egias  -----------------------

\section{Estrat\'egias }

Vamos supor que queremos mostrar que o argumento $(A \eand B) \eor (A \eand C) \therefore A \eand (B \eor C)$ \'e v\'alido. Come\c camos a prova escrevendo a premissa e a conclus\~ao em baixo. (Com o m\'aximo de espa\c co poss\'ivel entre elas.) 
\begin{fitchproof}
   \hypo{1}{(A \eand B) \eor (A \eand C)}
\ellipsesline
  \have[n]{2}{A \eand (B \eor C)}
\end{fitchproof}
Agora, temos duas op\c c\~oes: trabalhar do fim para o come\c co a partir da conclus\~ao ou trabalhar come\c co para o fim a partir da partir da premissa. Escolheremos a segunda estrat\'egia: usamos a disjun\c c\~ao na linha~$1$ e configuramos as subprovas que precisamos para  $\eor$E. A disjun\c c\~ao na linha~$1$ tem dois disjuntos, $A \eand B$ e $A \eand C$. 
O nosso objetivo \'e provar a senten\c ca $A \eand (B \eor C)$. Assim, neste caso, voc\^e  deve criar duas subprovas:  uma com a suposi\c c\~ao $A \eand B$ e a \'ultima linha $A \eand (B \eor C)$, e a  outra com a suposi\c c\~ao $A \eand C$ e a \'ultima linha $A \eand (B \eor C)$. A justificativa para a conclus\~ao na linha $n$  ser\'a  $\eor$E,  citando a disjun\c c\~ao na linha~$1$ e as duas subprovas. Assim, sua prova at\'e  agora \'e esta :
 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline 
	\have[n]{6}{A \eand (B \eor C)}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,7-11}
\end{fitchproof}
Agora voc\^e tem duas tarefas separadas, a saber,  preencher cada uma das duas subprovas. Na primeira subprova, trabalhamos do fim para o come\c co a partir da conclus\~ao $A \eand (B \eor C)$. Isso \'e uma conjun\c c\~ao, assim dentro da primeira subprova, voc\^e ter\'a dois subobjetivos separados: provar $A$, e provar $B \eor C$. Esses subobjetivos permitem justificar a linha $n$ usando~$\eand$I. A sua prova agora \'e assim:
 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline
	\have[i]{4}{A}
	\ellipsesline
	\have[n][-1]{5}{B \eor C}
	\have[n]{6}{A \eand (B \eor C)}\ai{4,5}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,(7)-11}
\end{fitchproof}
Vimos imediatamente que podemos obter a linha $i$ a partir da linha~$2$ por $\eand$E. No entanto, a linha $i$ \'e na verdade a linha~$3$ e pode ser justificada com $\eand$E  da linha~$2$. O outro subobjetivo $B \eor C$ \'e uma disjun\c c\~ao.
Aplicaremos a estrat\'egia de trabalhar do fim para o come\c co a partir de uma disjun\c c\~ao at\'e a linha $n-1$. Temos que escolher um dos disjuntos, $B$ ou~$C$. 
Escolhendo $C$  n\~ao funcionaria e ter\'iamos que voltar atr\'as. Agora voc\^e j\'a pode ver que, se voc\^e escolheu $B$ como subobjetivo, poder\'a conseguir isso trabalhando novamente do come\c co para o fim a partir da conjun\c c\~ao $A \eand B$ na linha~$2$. Assim, podemos concluir a primeira subprova como segue:
 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\have{3}{A}\ae{2}
	\have{4}{B}\ae{2}
	\have{5}{B \eor C}\oi{4}
	\have{6}{A \eand (B \eor C)}\ai{3,5}
	\close
	\open
	\hypo{7}{A \eand C}
	\ellipsesline
	\have[m]{11}{A \eand (B \eor C)}
	\close
	\have{12}{A \eand (B \eor C)}\oe{1,2-6,7-11}
\end{fitchproof}
Na primeira subprova, obtemos as linha $3$ e $4$ da mesma forma, i.e.,  de $2$ por  $\eand$E. A linha $5$  \'e justificada por $\eor$I da linha~$4$, pois estamos trabalhando do fim para o come\c co a partir de uma disjun\c c\~ao.

A segunda subprova \'e quase exatamente a mesma. Vamos deixar isso como um exerc\'icio.

Lembre-se de que, quando come\c camos, t\'inhamos a op\c c\~ao de come\c car a partir da premissa ou come\c car pela conclus\~ao, e escolhemos a primeira op\c c\~ao. A segunda op\c c\~ao tamb\'em leva a uma prova, mas ser\'a diferente. Os primeiros passos seriam trabalhar a partir da conclus\~ao e estabelecer dois subobjetivos, $A$ e $B \eor C$, e depois trabalhar a partir da premissa para prov\'a-las, por exemplo:
 

\begin{fitchproof}
	\hypo{1}{(A \eand B) \eor (A \eand C)}
	\open
	\hypo{2}{A \eand B}
	\ellipsesline
	\have[k]{3}{A}
	\close
	\open
	\hypo{4}{A \eand C}
	\ellipsesline
	\have[n][-1]{5}{A}
	\close
	\have{6}{A}\oe{1,2-3,(4)-(5)}
	\open
	\hypo{7}{A \eand B}
	\ellipsesline
	\have[l]{8}{B \eor C}
	\close
	\open
	\hypo{9}{A \eand C}
	\ellipsesline
	\have[m][-1]{10}{B \eor C}
	\close
	\have{11}{B \eor C}\oe{1,(7)-8,(9)-(10)}	
	\have{12}{A \eand (B \eor C)}\ai{6,11}
\end{fitchproof}
Deixaremos que voc\^e preencha as linhas ausentes indicadas por ~$\vdots$.

Vamos dar outro exemplo para ilustrar como aplicar as estrat\'egias ao lidar com condicionais e nega\c c\~ao. A senten\c ca $(A \eif B) \eif (\enot B \eif \enot A)$ \'e uma tautologia. 
Vamos ver se conseguimos encontrar uma prova disso, sem premissas, usando as estrat\'egias. Primeiro escrevemos a senten\c ca no final de uma folha de papel. Como trabalhar do come\c co para o fim n\~ao \'e uma boa op\c c\~ao (n\~ao h\'a nada a partir do qual trabalhar), trabalhamos do fim para o come\c co e criamos uma subprova para obter a  senten\c ca que queremos $(A \eif B) \eif (\enot B \eif \enot A)$ usando a regra  $\eif$I. A sua suposi\c c\~ao deve ser o antecedente do condicional que queremos provar, ou seja, $A \eif B$, e sua \'ultima linha, o consequente $\enot B \eif \enot A$.
 

\begin{fitchproof}
\open
\hypo{1}{A \eif B}
\ellipsesline
\have[n]{7}{\enot B \eif \enot A}
\close
\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
O novo objetivo, $\enot B \eif \enot A$ \'e  tamb\'em  um  condicional, assim, trabalhando do fim para o come\c co, criamos outra subprova:

\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\ellipsesline
	\have[n][-1]{6}{\enot A}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-(6)}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
Trabalhamos novamente do fim para o come\c co a partir de $\enot A$.  Para fazer isso, veja a regra $\enot$I. Ela requer uma subprova com~$A$ como suposi\c c\~ao, e $\ered$ como sua \'ultima linha. Ent\~ao a prova agora \'e:
 
\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\open\hypo{3}{A}
	\ellipsesline
	\have[n][-2]{5}{\ered}
	\close
	\have{6}{\enot A}\ni{3-(5)}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-(6)}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}
Agora nosso objetivo \'e provar~$\ered$. Dissemos acima, ao discutir como trabalhar a partir de uma senten\c ca negada, que a regra $\enot$E permite que voc\^e prove~$\ered$, o qual \'e o nosso objetivo na subprova interior. Ent\~ao, procuramos uma senten\c ca negada  que a partir da qual possamos trabalhar do come\c co para o fim: esta senten\c ca seria $\enot B$ da linha~$2$. Isso significa que temos que derivar $B$ dentro da subprova, pois $\enot$E requer n\~ao apenas $\enot B$ (o que j\'a temos), mas tamb\'em~$B$. E $B$, por sua vez, conseguimos a partir de $A \eif B$, j\'a que $\eif$E nos permitir\'a justificar o consequente~$B$ do condicional por $\eif$E. A regra $\eif$E tamb\'em requer o antecedente~$A$ do condicional, mas isso tamb\'em j\'a est\'a dispon\'ivel (na linha~$3$). Ent\~ao, conclu\'imos  com:


\begin{fitchproof}
	\open
	\hypo{1}{A \eif B}
	\open
	\hypo{2}{\enot B}
	\open\hypo{3}{A}
	\have{4}{B}\ce{1,3}
	\have{5}{\ered}\ne{2,4}
	\close
	\have{6}{\enot A}\ni{3-5}
	\close
	\have{7}{\enot B \eif \enot A}\ci{2-6}
	\close
	\have{8}{(A \eif B) \eif (\enot B \eif \enot A)}\ci{1-7}
\end{fitchproof}

%%%%%% -----------------------27.4 Trabalhando do come\c co para o fim a partir de absourdo

\section{Trabalhando do come\c co para o fim a partir de $\ered$}\label{sec:backred}

Ao aplicar as estrat\'egias, \`as vezes voc\^e se encontra em uma situa\c c\~ao em que pode justificar~$\ered$. Usando a regra de explos\~ao, isso permitiria justificar \emph{qualquer coisa}. Assim $\ered$ funciona como um curinga nas provas. Por exemplo, suponha que voc\^e queira fornecer uma prova do argumento $A \eor B, \enot A \therefore B$. Voc\^e configura sua prova, escrevendo as premissas $A \eor B$ e $\enot A$ na parte superior das linhas $1$ e $2$ e a conclus\~ao $B$ na parte inferior da p\'agina. $B$ n\~ao tem conectivo principal, ent\~ao voc\^e n\~ao pode usar a estrat\'egia do fim para o come\c co. Em vez disso, voc\^e deve trabalhar a partir de $A \eor B$: Isso requer duas subprovas,  tais como:


\begin{fitchproof}
	\hypo{1}{A \eor B}
	\hypo{7}{\enot A}
	\open
	\hypo{2}{A} 
	\ellipsesline 
	\have[m]{3}{B}
	\close 
	\open
	\hypo{4}{B}
	\ellipsesline
	\have[k]{5}{B}
	\close
	\have{6}{B}\oe{1,2-3,(4)-5} 
\end{fitchproof} 
Observe que voc\^e possui   $\enot A$ na linha~$2$ e $A$ como suposi\c c\~ao da sua primeira subprova. Isso lhe d\'a  $\ered$  usando $\enot$E, e de $\ered$ voc\^e obt\'em a conclus\~ao~$B$ da primeira subprova usando~X. Lembre-se de que voc\^e pode repetir uma senten\c ca que j\'a apareceu na prova  usando a regra de reitera\c c\~ao~R. Portanto, nossa prova seria:
\begin{fitchproof}
	\hypo{1}{A \eor B}
	\hypo{7}{\enot A}
	\open
	\hypo{2}{A} 
	\have{8}{\ered}\ne{7,2} 
	\have{3}{B}\re{8}
	\close 
	\open
	\hypo{4}{B}
	\have{5}{B}\by{R}{4}
	\close
	\have{6}{B}\oe{1,2-3,4-5} 
\end{fitchproof} 
%%%%%% -----------------------------------------------------27.5  Seguindo indiretamente
\section{Seguindo indiretamente}

Em muitos casos, as estrat\'egias de trabalhar do come\c co para o fim  e do fim para o come\c co d\~ao certo. Mas h\'a casos em que elas n\~ao funcionam. Se voc\^e n\~ao conseguir encontrar uma maneira de mostrar $\meta{A}$ diretamente usando essas estrat\'egias,  use a regra IP. Para fazer isso, configure uma subprova na qual voc\^e assume  $\enot\meta{A}$  e procure uma prova para $\ered$ dentro dessa subprova.

\begin{fitchproof}
\open
\hypo[n]{2}{\enot A}
\ellipsesline 
\have[m]{3}{\ered}
\close
\have{4}{\meta{A}}\ip{2-3}
\end{fitchproof}
Aqui, temos que iniciar uma subprova com a suposi\c c\~ao $\enot \meta{A}$;
a \'ultima linha da subprova deve ser~$\ered$. Vamos citar a subprova e usar  IP como regra. Na subprova, agora temos uma suposi\c c\~ao adicional (na linha $n$) para trabalhar.

Suponha que usamos a estrat\'egia de prova indireta ou estamos em outra situa\c c\~ao em que procuramos uma prova para  $\ered$.   O que \'e um bom candidato? \'e claro que o candidato \'obvio seria usar uma senten\c ca negada, pois (como vimos acima) com $\enot$E podemos obter~$\ered$. 
 Se voc\^e configurar uma prova como acima, tentando provar \meta{A} usando~IP, voc\^e ter\'a $\enot \meta{A}$ como suposi\c c\~ao de sua subprova - ent\~ao trabalhando a partir dela para justificar $\ered$ dentro de sua subprova, voc\^e estabelece \meta{A} como uma meta dentro de sua subprova. Assim, se voc\^e estiver usando  IP, voc\^e se encontrar\'a na seguinte situa\c c\~ao:
\begin{fitchproof}
\open
\hypo[n]{2}{\enot \meta{A}}
\ellipsesline
\have[m][-1]{3}{\meta{A}}
\have{4}{\ered}\ne{2,3}
\close
\have{5}{\meta{A}}\ip{2-4}
\end{fitchproof} 


Isso parece estranho: quer\'iamos provar $\meta{A}$ e as estrat\'egias fracassaram; ent\~ao usamos a regra  IP como \'ultimo recurso. E agora nos encontramos na mesma situa\c c\~ao: estamos novamente procurando uma prova de ~$\meta{A}$. Mas observe que agora estamos \emph{dentro} de uma subprova, e nessa subprova temos uma suposi\c c\~ao adicional ($\enot \meta{A}$) para trabalhar a qual n\~ao t\'inhamos antes. Vamos ver um exemplo.

%%%%%% -----------------------27.6  Prova indireta do terceiro excluido ---------- ---------

\section{Prova indireta do terceiro exclu\'ido}\label{s:proofLEM}

A senten\c ca $A \eor \enot A$ \'e uma tautologia e, portanto, deve ter uma prova mesmo sem quaisquer premissas. Mas trabalhar do fim para o come\c co falha nessa situa\c c\~ao: para obter $A \eor \enot A$ usando $\eor$I ter\'iamos que provar $A$ ou $\enot A$; novamente, sem premissas. Nenhuma dessas \'e uma tautologia, portanto tamb\'em n\~ao podemos provar. Trabalhar  do come\c co para o fim tamb\'em n\~ao funciona, j\'a que n\~ao h\'a nada para assumir. Portanto, a \'unica op\c c\~ao \'e a prova indireta.
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\ellipsesline
	\have[m]{8}{\ered}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}
Agora temos algo a partir do qual trabalhar: a suposi\c c\~ao  $\enot(A \eor \enot A)$. Para us\'a-la, justificamos $\ered$ com a regra $\enot$E, citando o pressuposto na linha~$1$, e tamb\'em a senten\c ca n\~ao negada correspondente $A \eor \enot A$, ainda a ser provada
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\ellipsesline
	\have[m][-1]{7}{A \eor \enot A}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}


No in\'icio, trabalhando  do come\c co par o fim para provar $A \eor\enot A$ com a regra $\eor$I n\~ao funcionou. Mas agora estamos em uma situa\c c\~ao diferente: queremos provar $A \eor\enot A$ dentro de uma subprova. Em geral, ao lidar com novas metas, devemos voltar e come\c car com as estrat\'egias b\'asicas. Nesse caso, devemos primeiro tentar trabalhar do fim para o come\c co a partir da disjun\c c\~ao $A \eor \enot A$, ou seja, precisamos escolher um dos disjuntos  e tentar prov\'a-lo. Vamos escolher~$\enot A$. Isso permitiria justificar $A \eor \enot A$ na linha~$m - 1$ usando $\eor$I. Ent\~ao, trabalhando novamente de fim para o come\c co a partir de $\enot A$, iniciamos outra subprova a fim de justificar  $\enot A$ usando $\enot$I. Essa subprova deve ter $A$ acomo suposi\c c\~ao e~$\ered$ como sua \'ultima linha.
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\open
	\hypo{3}{A}
	\ellipsesline
	\have[m][-3]{5}{\ered}
	\close
	\have{6}{\enot A}\ni{3-(5)}
	\have{7}{A \eor \enot A}\oi{6}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}
Dentro dessa nova subprova, precisamos novamente justificar $\ered$. A melhor maneira de fazer isso \'e come\c car com uma senten\c ca negada; $\enot(A \eor \enot A)$ na linha~$1$ \'e a \'unica senten\c ca negada que podemos usar. A senten\c ca n\~ao negada correspondente,  $A \eor \enot A$, no entanto, segue diretamente de $A$ (que temos na linha~$2$) por $\eor$I. Nossa prova completa \'e:
\begin{fitchproof}
	\open
	\hypo{2}{\enot (A \eor \enot A)}
	\open
	\hypo{3}{A}
	\have{4}{A \eor \enot A}\oi{3}
	\have{5}{\ered}\ne{2,4}
	\close
	\have{6}{\enot A}\ni{3-5}
	\have{7}{A \eor \enot A}\oi{6}
	\have{8}{\ered}\ne{2,7}
	\close
	\have{9}{A \eor \enot A}\ip{2-8}
\end{fitchproof}

%%%%%% ----------------------------- -CAP 27 -  EXERCICIOS  --------------------------------------------------  

\practiceproblems

\problempart
Use as estrat\'egias  para encontrar provas para cada um dos oito seguintes argumentos:
\begin{earg}
\item $A \eif B, A \eif C \therefore A \eif (B \eand C)$
\item $(A \eand B) \eif C \therefore A \eif (B \eif C)$
\item $A \eif (B \eif C) \therefore (A \eif B) \eif (A \eif C)$
\item $A \eor (B \eand C) \therefore (A \eor B) \eand (A \eor C)$
\item $(A \eand B) \eor (A \eand C) \therefore A \eand (B \eor C)$
\item $A \eor B, A \eif C, B \eif D \therefore C \eor D$
\item $\enot A \lor \enot B \therefore \enot(A \eand B)$
\item $A \eand \enot B \therefore \enot(A \eif B)$
\end{earg}

\problempart
Formule estrat\'egias para trabalhar do fim para o come\c co e do come\c co para o fim a partir de $\meta{A} \eiff \meta{B}$.

\problempart
Use as estrat\'egias para encontrar provas para cada uma das cinco seguintes senten\c cas:
\begin{earg}
\item $\enot A \eif (A \eif \ered)$
\item $\enot(A \eand \enot A)$
\item $[(A \eif C) \eand (B \eif C)] \eif [(A \lor B) \eif C]$
\item $\enot(A \eif B) \eif (A \eand \enot B)$
\item $(A \eor \enot B) \eif (A \eif B)$
\end{earg}


Como essas devem ser provas de senten\c cas a partir de nenhuma premissa, voc\^e come\c car\'a com a respectiva senten\c ca \emph{na parte inferior} da prova, as quais n\~ao ter\~ao premissas.

\problempart
Use as estrat\'egias para encontrar provas para cada um dos seguintes argumentos e senten\c cas:
\begin{earg}
\item $\enot\enot A \eif A$
\item $\enot A \eif \enot B \therefore B \eif A$
\item $A \eif B \therefore \enot A \eor B$
\item $\enot(A \eand B) \eif (\enot A \eor \enot B)$
\item $A \eif (B \eor C) \therefore (A \eif B) \eor (A \eif C)$
\item $(A \eif B) \lor (B \eif A)$
\item $((A \eif B) \eif A) \eif A$
\end{earg}
Todos exigir\~ao a estrat\'egia de IP. Os \'ultimos tr\^es especialmente s\~ao bastante dif\'iceis!

%%%%%%------------------------   CAPITULO  28  -   Regras adicionais da LVF    --------------------- 

\chapter{Regras adicionais da LVF}\label{s:Further}
No Cap\'itulo \ref{s:BasicTFL}, introduzimos as regras b\'asicas de nosso sistema de provas para a LVF e nesta se\c c\~ao, apresentaremos algumas regras adicionais a esse sistema.  Veremos que em  nosso sistema de prova estendido \'e um pouco mais f\'acil de trabalhar.  No entanto, veremos, no Cap\'itulo \ref{s:Derived} que essas regras adicionais n\~ao s\~ao, estritamente falando,\emph{necess\'arias}.

% \section{Reiteration}
% The first additional rule is \emph{reiteration} (R). This just allows us to repeat ourselves:
% \factoidbox{\begin{fitchproof}
% 	\have[m]{a}{\meta{A}}
% 	\have[\ ]{b}{\meta{A}} \by{R}{a}
% \end{fitchproof}}
% Such a rule is obviously legitimate; we could have used it in our proof in \S\ref{sec:backred}:
% \begin{fitchproof}
% 	\hypo{1}{A \eor B}
% 	\hypo{7}{\enot A}
% 	\open
% 	\hypo{2}{A} 
% 	\have{8}{\ered}\ne{7,2} 
% 	\have{3}{B}\re{8}
% 	\close 
% 	\open
% 	\hypo{4}{B}
% 	\have{5}{B}\by{R}{4}
% 	\close
% 	\have{6}{B}\oe{1,2-3,4-5} 
% \end{fitchproof}
% This is a fairly typical use of the R rule.

%%%%%%———————————  --------  28.1   Silogismo disjuntivo  ---------------------
\section{Silogismo disjuntivo}
Vejamos uma forma de argumento muito natural.
	\begin{quote}
		Maria est\'a em Natal ou em Lisboa. Ela n\~ao est\'a em Lisboa. Portanto, ela est\'a em Natal.
	\end{quote}
Isso \'e chamado  \emph{silogismo disjuntivo}. N\'os o adicionamos ao nosso sistema de prova da seguinte maneira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A} \eor \meta{B}}
	\have[n]{nb}{\enot \meta{A}}
	\have[\ ]{con}{\meta{B}}\by{SD}{ab, nb}
\end{fitchproof}}
e
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A} \eor \meta{B}}
	\have[n]{nb}{\enot \meta{B}}
	\have[\ ]{con}{\meta{A}}\by{SD}{ab, nb}
\end{fitchproof}}

Como usual, a disjun\c c\~ao e a nega\c c\~ao de um dos disjuntos podem ocorrer em qualquer ordem e n\~ao precisam estar visinhos. No entanto, sempre citamos a disjun\c c\~ao primeiro.

 %%%%%% ----------------------------------  28.2 Modus tollens   ---------------------
\section{Modus tollens}
Outro padr\~ao  \'util de infer\^encia \'e incorporado no seguinte argumento:
	\begin{quote}
		Se Carlos venceu a elei\c c\~ao, ele est\'a em Natal. Ele n\~ao est\'a em Natal. Portanto ele n\~ao venceu a elei\c c\~ao.
	\end{quote}
Este padr\~ao de infer\^encia \'e chamado \emph{modus tollens}. A regra correspondente \'e:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\enot\meta{B}}
	\have[\ ]{b}{\enot\meta{A}}\mt{ab,a}
\end{fitchproof}}
Como sempre, as premissas podem ocorrer em qualquer ordem, mas sempre citamos o condicional primeiro. 
 %%%%%% ---------------------------------- 28.3    Eliminacao da dupla negacao

\section{Elimina\c c\~ao da dupla nega\c c\~ao}
Outra regra  \'util \'e a  \emph{elimina\c c\~ao da dupla nega\c c\~ao}. Faz exatamente o que diz:
\factoidbox{\begin{fitchproof}
		\have[m]{dna}{\enot \enot \meta{A}}
		\have[ ]{a}{\meta{A}}\dne{dna}
	\end{fitchproof}}
A justificativa para isso \'e que, em linguagem natural, as duplas nega\c c\~oes tendem a se anular.

Dito isto, você deve estar ciente de que o contexto e a ênfase podem impedi-los de fazê-lo. Considere a senten\c ca `Jane \emph{n\~ao} \'e infeliz’.  A partir dessa afirma\c c\~ao  n\~ao podemos necessariamente concluir `Jane \'e feliz’, pois a primeira senten\c ca deve ser entendida como  `Jane est\'a em um estado de profunda indiferen\c ca’. 
  Como sempre, mudar para a LVF nos obriga a sacrificar certas nuances das express\~oes em portugu\^es. 

%%%%%%———————————  28.4 Terceiro excluido
\section{Terceiro exclu\'ido}

Suponha que possamos mostrar que, se estiver ensolarado l\'a fora, Bento levar\'a um guarda-chuva (por medo de se queimar). Suponha   tamb\'em que possamos mostrar que, se n\~ao estiver ensolarado l\'a fora, Bento levar\'a um guarda-chuva (por medo de se molhar). Bem, n\~ao h\'a um terceiro caminho para o clima. Portanto, \emph{qualquer que seja}   o clima, Bento levar\'a um guarda-chuva.

Essa linha de pensamento motiva a seguinte regra:

\factoidbox{\begin{fitchproof}
		\open
			\hypo[i]{a}{\meta{A}}
			\have[j]{c1}{\meta{B}}
		\close
		\open
			\hypo[k]{b}{\enot\meta{A}}
			\have[l]{c2}{\meta{B}}
		\close
		\have[\ ]{ab}{\meta{B}}\tnd{a-c1,b-c2}
	\end{fitchproof}}
 Essa regra   \'e  \`as vezes   chamada lei do  \emph{terceiro exclu\'ido}, pois encapsula a ideia de que \meta{A} pode ser verdadeira ou $\enot \meta{A}$ pode ser verdadeira, mas n\~ao h\'a meio caminho em que nenhum dos dois seja verdadeira.\footnote{Voc\^e pode \`as vezes encontrar l\'ogicos ou fil\'osofos falando sobre "tertium non datur". Esse \'e o mesmo princ\'ipio que o terceiro exclu\'ido; significa "n\~ao h\'a terceira via". L\'ogicos que t\^em d\'uvidas sobre provas indiretas tamb\'em t\^em d\'uvidas sobre a LEM.} Pode haver tantas linhas quantas voc\^e quiser entre $i$ e $j$, e tantas linhas quantas quiser entre $k$ e $l$.  Al\'em disso, as subprovas podem vir em qualquer ordem, e a segunda subprova n\~ao precisa vir imediatamente ap\'os a primeira.

Para ver a regra em a\c c\~ao, considere:
 
	$$P \therefore (P \eand D) \eor (P \eand \enot D)$$
Aqui est\'a uma prova correspondente ao argumento:
	\begin{fitchproof}
		\hypo{a}{P}
		\open
			\hypo{b}{D}
			\have{ab}{P \eand D}\ai{a, b}
			\have{abo}{(P \eand D) \eor (P \eand \enot D)}\oi{ab}
		\close
		\open
			\hypo{nb}{\enot D}
			\have{anb}{P \eand \enot D}\ai{a, nb}
			\have{anbo}{(P \eand D) \eor (P \eand \enot D)}\oi{anb}
		\close
		\have{con}{(P \eand D) \eor (P \eand \enot D)}\tnd{b-abo, nb-anbo}
	\end{fitchproof}
Aqui est\'a outro exemplo:
\begin{fitchproof}
	\hypo{ana}{A \eif \enot A}
	\open
		\hypo{a}{A}
		\have{na}{\enot A}\ce{ana, a}
	\close
	\open
		\hypo{na1}{\enot A}
		\have{na2}{\enot A}\by{R}{na1}
	\close
	\have{na3}{\enot A}\tnd{a-na, na1-na2}
\end{fitchproof}

%%%%%%———————--------------——  28.5 Regras De Morgan  --------- ---------

\section{Regras de De Morgan}
Nossas regras adicionais finais s\~ao chamadas de Leis de De~Morgan (em homenagem a Augustus De~Morgan). A forma das regras deve ser familiar nas tabelas de verdade.

 A primeira regra de De~Morgan \'e:
 
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot (\meta{A} \eand \meta{B})}
	\have[\ ]{dm}{\enot \meta{A} \eor \enot \meta{B}}\dem{ab}
\end{fitchproof}}
A segunda regra de De~Morgan \'e o inverso da primeira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot \meta{A} \eor \enot \meta{B}}
	\have[\ ]{dm}{\enot (\meta{A} \eand \meta{B})}\dem{ab}
\end{fitchproof}}
A terceira regra de De~Morgan \'e dual da primeira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot (\meta{A} \eor \meta{B})}
	\have[\ ]{dm}{\enot \meta{A} \eand \enot \meta{B}}\dem{ab}
\end{fitchproof}}
E a quarta regra de De~Morgan \'e o inverso da terceira:
\factoidbox{\begin{fitchproof}
	\have[m]{ab}{\enot \meta{A} \eand \enot \meta{B}}
	\have[\ ]{dm}{\enot (\meta{A} \eor \meta{B})}\dem{ab}
\end{fitchproof}}
\emph{Essas s\~ao todas as regras adicionais do nosso sistema de prova para a  LVF.}

 %%%%%% -------------------------CAP 28  - EXERCICIOS   ------------------------------------------------ 
\practiceproblems
\solutions
\problempart
\label{pr.justifyTFLproof}
As provas a seguir est\~ao sem cita\c c\~oes (n\'umeros de regra e linha). Adicione-os sempre que necess\'ario:

\begin{earg}
\item 
	\begin{fitchproof}
\hypo{1}{W \eif \enot B}
\hypo{2}{A \eand W}
\hypo{2b}{B \eor (J \eand K)}
\have{3}{W}{}
\have{4}{\enot B} {}
\have{5}{J \eand K} {}
\have{6}{K}{}
\end{fitchproof}
\item\begin{fitchproof}
\hypo{1}{L \eiff \enot O}
\hypo{2}{L \eor \enot O}
\open
	\hypo{a1}{\enot L}
	\have{a2}{\enot O}{}
	\have{a3}{L}{}
	\have{a4}{\ered}{}
\close
\have{3b}{\enot\enot L}{}
\have{3}{L}{}
\end{fitchproof}
\item\begin{fitchproof}
\hypo{1}{Z \eif (C \eand \enot N)}
\hypo{2}{\enot Z \eif (N \eand \enot C)}
\open
	\hypo{a1}{\enot(N \eor  C)}
	\have{a2}{\enot N \eand \enot C} {}
	\have{a6}{\enot N}{}
	\have{b4}{\enot C}{}
		\open
		\hypo{b1}{Z}
		\have{b2}{C \eand \enot N}{}
		\have{b3}{C}{}
		\have{red}{\ered}{}
	\close
	\have{a3}{\enot Z}{}
	\have{a4}{N \eand \enot C}{}
	\have{a5}{N}{}
	\have{a7}{\ered}{}
\close
\have{3b}{\enot\enot(N \eor C)}{}
\have{3}{N \eor C}{}
\end{fitchproof}
\end{earg}

\problempart 
D\^e uma prova para cada um desses argumentos:
\begin{earg}
\item $E\eor F$, $F\eor G$, $\enot F \therefore E \eand G$
\item $M\eor(N\eif M) \therefore \enot M \eif \enot N$
\item $(M \eor N) \eand (O \eor P)$, $N \eif P$, $\enot P \therefore M\eand O$
\item $(X\eand Y)\eor(X\eand Z)$, $\enot(X\eand D)$, $D\eor M \therefore M$
\end{earg}

%%%%%% ---------------------------CAP 29 -  Conceitos de teoria da prova ------------------

\chapter{Conceitos de teoria da prova}\label{s:ProofTheoreticConcepts}

 Neste cap\'itulo, apresentaremos um novo vocabul\'ario. A seguinte express\~ao:
 
$$\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n \proves \meta{C}$$
significa que existe uma prova que termina com $\meta{C}$  cujas suposi\c c\~oes n\~ao descartadas est\~ao entre $\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n$. Quando queremos dizer que  \emph{n\~ao} \'e o caso que existe uma prova que termine com $\meta{C}$ a partir de $\meta{A}_1$, $\meta{A}_2$, \dots,~$\meta{A}_n$, escrevemos:  $$\meta{A}_1, \meta{A}_2, \ldots, \meta{A}_n \nproves \meta{C}$$  

O s\'imbolo `$\proves$'  \'e chamado de  \emph{roleta \'unica}. Queremos enfatizar que este n\~ao \'e o s\'imbolo do roleta dupla (`$\entails$') que introduzimos no cap\'itulo~\ref{s:SemanticConcepts}  para simbolizar sustenta\c c\~ao. O s\'imbolo roleta \'unica, `$\proves$', diz respeito \`a exist\^encia de provas; enquanto que a roleta dupla, `$\entails$', diz respeito \`a exist\^encia de valora\c c\~oes (ou interpreta\c c\~oes, quando usadas para FOL). \emph{Elas s\~ao no\c c\~oes muito diferentes}.

Com o nosso s\'imbolo  `$\proves$',  podemos introduzir um pouco mais de terminologia. Para dizer que existe uma prova de $\meta{A}$ sem suposi\c c\~oes n\~ao descartadas, escrevemos: ${} \proves \meta{A}$. Nesse caso, dizemos que $\meta{A}$ \'e um \define{teorema}.
	\factoidbox{\label{def:syntactic_tautology_in_sl}
		$\meta{A}$ \'e um  \define{teorema} se e somente se $\proves \meta{A}$
	}
\newglossaryentry{teorema}
{
name=teorema,
description={Uma senten\c ca que \'e provada sem nenhuma premissa}
}

Para ilustrar isso, suponha que desejamos mostrar que `$\enot (A \eand \enot A)$' \'e um teorema. Assim, precisamos de uma prova de `$\enot(A \eand \enot A)$' que \emph{n\~ao} tenha suposi\c c\~oes n\~ao descartadas. No entanto, como queremos provar uma senten\c ca cujo operador l\'ogico principal \'e uma nega\c c\~ao, vamos come\c car com uma \emph{subprova}  dentro da qual assumimos `$A \eand \enot A$', e mostrar que essa suposi\c c\~ao leva a uma contradi\c c\~ao. Levando em considera\c c\~ao tudo isso, a prova \'e assim:
	\begin{fitchproof}
		\open
			\hypo{con}{A \eand \enot A}
			\have{a}{A}\ae{con}
			\have{na}{\enot A}\ae{con}
			\have{red}{\ered}\ne{na, a}
		\close
		\have{lnc}{\enot (A \eand \enot A)}\ni{con-red}
	\end{fitchproof}
Provamos ent\~ao `$\enot (A \eand \enot A)$' sem nenhuma suposi\c c\~ao (n\~ao descartada).  Esse teorema em particular \'e uma inst\^ancia do que \`as vezes \'e chamado de \emph{Lei da N\~ao Contradi\c c\~ao}.

Para mostrar que algo \'e um teorema, voc\^e apenas precisa encontrar uma prova adequada. Normalmente, \'e muito mais dif\'icil mostrar que algo \emph{n\~ao} \'e um teorema. Para fazer isso, voc\^e precisaria demonstrar, n\~ao apenas que certas estrat\'egias de prova falham, mas que \emph{nenhuma} prova \'e poss\'ivel. Mesmo que voc\^e n\~ao consiga provar uma senten\c ca de mil maneiras diferentes, talvez a prova seja longa e complexa demais para voc\^e entender. Talvez voc\^e n\~ao tenha se esfor\c cado o suficiente.

Aqui temos um pouco mais de terminologia:
	\factoidbox{
		Duas senten\c cas \meta{A} e \meta{B} s\~ao \define{dedutivamente equivalentes} se e somente se cada  uma puder ser provada a partir da outra.   i.e,  ambas $\meta{A}\proves\meta{B}$ e $\meta{B}\proves\meta{A}$.
	}
        
\newglossaryentry{dedutivamente equivalente}
{
  name=dedutivamente equivalente,
  text = dedutivamente equivalente,
description={Duas senten\c cas A e B s\~ao  dedutivamente equivalentes  se e somente se cada  uma puder ser provada a partir da outra.}
}


Assim como no caso de mostrar que uma senten\c ca \'e um teorema, \'e relativamente f\'acil mostrar que duas senten\c cas s\~ao dedutivamente equivalentes: isto requer apenas um par de provas. Entretanto, mostrar que senten\c cas \emph{n\~ao} s\~ao dedutivamente equivalentes seria muito mais dif\'icil: \'e t\~ao dif\'icil quanto mostrar que uma senten\c ca n\~ao \'e um teorema.

Um pouco mais de terminologia:
	\factoidbox{
		As senten\c cas  $\meta{A}_1,\meta{A}_2,\ldots, \meta{A}_n$  s\~ao \define{DEDUTIVAMENTE INCONSISTENTES} se e somente se uma  contradi\c c\~ao puder ser provada a partir delas, ou seja, $\meta{A}_1,\meta{A}_2,\ldots, \meta{A}_n \proves \ered$. Se elas n\~ao s\~ao \define{inconsistentes}, dizemos que elas s\~ao \define{DEDUTIVAMENTE CONSISTENTES}.
	}
        
\newglossaryentry{dedutivamente inconsistente}
{    name={dedutivamente inconsistente}, 
  description={Senten\c cas  s\~ao dedutivamente inconsistentes  se e somente se uma  contradi\c c\~ao puder ser provada a partir delas}
}

        \'E f\'acil mostrar que um conjunto de senten\c cas \'e dedutivamente inconsistente: voc\^e s\'o precisa provar uma contradi\c c\~ao a partir delas.  Entretanto,  mostrar que um conjunto de senten\c cas n\~ao \'e dedutivamente inconsistentes \'e muito mais dif\'icil. Exigiria mais do que apenas fornecer uma ou duas provas; exigiria mostrar que nenhuma prova de um determinado tipo \'e \emph{poss\'ivel}.

\
\\
Esta tabela resume se uma ou duas provas s\~ao bem sucedidas ou se devemos raciocinar sobre todas as provas poss\'iveis.

\begin{center}
\begin{tabular}{l l l}
%\cline{2-3}
 & \textbf{Sim} & \textbf{ N\~ao}\\
 \hline
%\cline{2-3}
teorema? & uma prova & todas as provas poss\'iveis\\
inconsistente? &  uma prova  & todas as provas poss\'iveis\\
equivalente? & duas provas & todas as provas poss\'iveis\\
consistente? & todas as provas poss\'iveis & uma prova\\
\end{tabular}
\end{center}

 %%%%%% ------------------------CAP  29  - EXERCICIOS   ------------------------------------------------ 
\practiceproblems
\problempart
Mostre que cada uma das seguintes senten\c cas \'e um teorema:
\begin{earg}
\item $O \eif O$
\item $N \eor \enot N$
\item $J \eiff [J\eor (L\eand\enot L)]$
\item $((A \eif B) \eif A) \eif A$ 
\end{earg}

\problempart
Forne\c ca provas para mostrar cada um dos seguintes argumentos:
\begin{earg}
\item $C\eif(E\eand G), \enot C \eif G \proves G$
\item $M \eand (\enot N \eif \enot M) \proves (N \eand M) \eor \enot M$
\item $(Z\eand K)\eiff(Y\eand M), D\eand(D\eif M) \proves Y\eif Z$
\item $(W \eor X) \eor (Y \eor Z), X\eif Y, \enot Z \proves W\eor Y$
\end{earg}

\problempart
Mostre que cada um dos seguintes pares de senten\c cas \'e dedutivamente equivalente:
\begin{earg}
\item $R \eiff E$, $E \eiff R$
\item $G$, $\enot\enot\enot\enot G$
\item $T\eif S$, $\enot S \eif \enot T$
\item $U \eif I$, $\enot(U \eand \enot I)$
\item $\enot (C \eif D), C \eand \enot D$
\item $\enot G \eiff H$, $\enot(G \eiff H)$ 
\end{earg}

\problempart
 Se voc\^e sabe que $\meta{A}\proves\meta{B}$, o que voc\^e pode dizer sobre $(\meta{A}\eand\meta{C})\proves\meta{B}$? E quanto a $(\meta{A}\eor\meta{C})\proves\meta{B}$? Explique suas respostas.

\

\problempart Neste cap\'itulo, alegamos que \'e muito dif\'icil mostrar que duas senten\c cas n\~ao s\~ao dedutivamente equivalentes, assim como mostrar que uma senten\c ca n\~ao \'e um teorema. Por que afirmamos isso? (\emph{Sugest\~ao}: pense em uma senten\c ca que seria um teorema se e somente se \meta{A} e \meta{B} fossem dedutivamente equivalentes.)

%%%%%% --------------------------  CAP  30  -   Regras derivadas--------------------------------------

\chapter{Regras derivadas}\label{s:Derived}
Nesta se\c c\~ao, veremos por que introduzimos as regras do nosso sistema de prova em dois lotes separados. Em particular, queremos mostrar que as regras adicionais do cap\'itulo \ref{s:Further} n\~ao s\~ao estritamente necess\'arias, mas podem ser derivadas das regras b\'asicas aprestadas no cap\'itulo \ref{s:BasicTFL}. 

%%%%%% ———— -- - - - - -  -  —  30.1  Derivcao de reiteracao  - ---- - - - -  ---- 
\section{Deriva\c c\~ao da Reitera\c c\~ao}
Para ilustrar o que significa derivar uma   \emph{regra} de outras regras, primeiro considere a reitera\c c\~ao. \'E uma regra b\'asica do nosso sistema, mas tamb\'em n\~ao \'e necess\'aria. Suponha que voc\^e tenha alguma senten\c ca em alguma linha de sua dedu\c c\~ao:
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
\end{fitchproof}
Agora voc\^e deseja repeti-la em alguma linha~$k$. Voc\^e poderia simplesmente invocar a regra~R. Mas igualmente bem, voc\^e pode fazer isso com outras regras b\'asicas do cap\'itulo \ref{s:BasicTFL}:
\begin{fitchproof}
	\have[m]{a}{\meta{A}}
	\have[k]{aa}{\meta{A} \eand \meta{A}}\ai{a, a}
	\have{a2}{\meta{A}}\ae{aa}
\end{fitchproof}


Para ser claro: isso n\~ao \'e uma prova, mas um \emph{esquema} de prova. Afinal, foi usada  uma vari\'avel, `$\meta{A}$',  em vez de uma senten\c ca da LVF, entretanto o ponto \'e simples: quaisquer que sejam as senten\c cas da LVF que atribu\'imos \`a `$\meta{A}$', e quaisquer que sejam as linhas em que estiv\'essemos trabalhando, poder\'iamos produzir uma  prova genu\'ina. Assim, voc\^e pode pensar nisso como uma receita para produzir provas.

De fato, \'e uma receita que nos mostra o seguinte: qualquer coisa que possamos provar usando a regra R, podemos provar (com mais uma linha) usando apenas as regras b\'asicas do cap\'itulo \ref{s:BasicTFL} sem R. \'E isso que significa dizer que a regra R pode ser derivada de outras regras b\'asicas: qualquer coisa que possa ser justificada usando R pode ser justificada usando apenas as outras regras b\'asicas.

%%%%%% ——— - - - ——-------------——  30.2  Derivacao de silogismo disjuntivo  -------
\section{Deriva\c c\~ao do Silogismo Disjuntivo}
Suponha que voc\^e esteja em uma prova e tenha algo desta forma:
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eor\meta{B}}
	\have[n]{na}{\enot \meta{A}}
\end{fitchproof}
Agora voc\^e deseja, na linha~$k$, provar $\meta{B}$. Voc\^e pode fazer isso com a regra DS, introduzida no cap\'itulo \ref{s:Further}, mas igualmente, voc\^e pode fazer isso com as regras  \emph{b\'asicas} do cap\'itulo \ref{s:BasicTFL}:
 

	\begin{fitchproof}
		\have[m]{ab}{\meta{A}\eor\meta{B}}
		\have[n]{na}{\enot \meta{A}}
		\open
			\hypo[k]{a}{\meta{A}}
			\have{red}{\ered}\ne{na, a}
			\have{b1}{\meta{B}}\re{red}
		\close
		\open
			\hypo{b}{\meta{B}}
			\have{b2}{\meta{B}}\by{R}{b}
		\close
	\have{con}{\meta{B}}\oe{ab, a-b1, b-b2}
\end{fitchproof}
A regra DS, igualmente, pode ser derivada de nossas regras mais b\'asicas. Adicion\'a-la ao nosso sistema n\~ao possibilitou novas provas. Sempre  que voc\^e usar a regra DS, voc\^e pode provar a mesma coisa usando algumas linhas extras aplicando apenas as nossas regras b\'asicas. Assim, DS \'e uma regra \emph{derivada}.

%%%%%% ——— - - - ————  30.3  Derivacao de Modus Tollens  ----- - - ---  -- - - 
\section{Deriva\c c\~ao de Modus Tollens}
Suponha que voc\^e tenha o seguinte em sua prova:
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{a}{\enot\meta{B}}
\end{fitchproof}
Agora voc\^e deseja, na linha~$k$, provar $\enot \meta{A}$. Voc\^e pode fazer isso com a regra  MT, introduzida no cap\'itulo \ref{s:Further}.  Igualmente aqui, voc\^e pode fazer isso com as regras  \emph{b\'asicas} do cap\'itulo \ref{s:BasicTFL}:
 
\begin{fitchproof}
	\have[m]{ab}{\meta{A}\eif\meta{B}}
	\have[n]{nb}{\enot\meta{B}}
		\open
		\hypo[k]{a}{\meta{A}}
		\have{b}{\meta{B}}\ce{ab, a}
		\have{nb1}{\ered}\ne{nb, b}
		\close
	\have{no}{\enot\meta{A}}\ni{a-nb1}
\end{fitchproof}
Novamente, a regra  MT pode ser derivada das regras  \emph{b\'asicas} do cap\'itulo \ref{s:BasicTFL}.

%%%%%% ——— - - - ——  30.4  Derivacao da Eliminacao da dupla negacao

\section{Deriva\c c\~ao da Elimina\c c\~ao da Dupla Nega\c c\~ao}
Considere o seguinte esquema de dedu\c c\~ao:
	\begin{fitchproof}
	\have[m]{m}{\enot \enot \meta{A}}
	\open
		\hypo[k]{a}{\enot\meta{A}}
		\have{a1}{\ered}\ne{m, a}
	\close
	\have{con}{\meta{A}}\ip{a-a1}
\end{fitchproof}
Aqui tamb\'em podemos derivar a regra DNE das regras \emph{b\'asicas} do cap\'itulo \ref{s:BasicTFL}.

%%%%%% ——— - - - ——  30.5   Derivacao do terceiro excluido  ----------------------
\section{Deriva\c c\~ao do terceiro exclu\'ido}
Suponha que voc\^e queira provar algo usando a regra LEM, ou seja, voc\^e tem em sua prova
 
\begin{fitchproof}
  \open
  \hypo[m]{a}{\meta{A}}
  \have[n]{aaa}{\meta{B}}
  \close
  \open
  \hypo[k]{b}{\enot\meta{A}}
  \have[l]{bbb}{\meta{B}}
  \close
\end{fitchproof}
Agora voc\^e deseja, na linha~$l+1$, provar $\meta{B}$. A regra LEM do cap\'itulo \ref{s:Further} permitiria que voc\^e fizesse isso. Mas, voc\^e pode obter $\meta{B}$ usando apenas as regras  \emph{b\'asicas} do Cap\'itulo \ref{s:BasicTFL}.

Uma op\c c\~ao \'e primeiro provar  $\meta{A} \eor \enot\meta{A}$, e depois aplicar a regra $\eor$E, ou seja, provar por casos:
\begin{fitchproof}
  \open
  \hypo[m]{a}{\meta{A}}
  \have[n]{aaa}{\meta{B}}
  \close
  \open
  \hypo[k]{b}{\enot\meta{A}}
  \have[l]{bbb}{\meta{B}}
  \close
  \ellipsesline
  \have[i]{tnd}{\meta{A} \eor \enot \meta{A}}
  \have[i+1]{fin}{\meta{B}}\oe{tnd, a-aaa,b-bbb}
\end{fitchproof}
(Na Seç\~ao \ref{s:proofLEM} fizemos uma prova de $\meta{A} \eor \enot\meta{A}$  usando apenas nossas regras b\'asicas.)

Aqui est\'a outra maneira que \'e um pouco mais complicada do que as anteriores. O que voc\^e precisa fazer \'e incorporar suas duas subprovas dentro de outra subprova. A suposi\c c\~ao da subprova ser\'a $\enot \meta{B}$, e a  \'ultima linha $\ered$. Assim,  para obter a subprova completa voc\^e precisa concluir \meta{B} usando IP. Dentro da prova, voc\^e precisa trabalhar um pouco mais para obter~$\ered$:

\begin{fitchproof}
  \open
  \hypo[m]{nb}{\enot\meta{B}}
  \open
  \hypo{a}{\meta{A}}
  \ellipsesline
  \have[n]{aaa}{\meta{B}}
  \have{aaaa}{\ered}\ne{nb, aaa}
  \close
  \open
  \hypo{b}{\enot\meta{A}}
  \ellipsesline
  \have[l]{bbb}{\meta{B}}
  \have{bbbb}{\ered}\ne{nb, bbb}
  \close
  \have{na}{\enot\meta{A}}\ni{(a)-(aaaa)}
  \have{nna}{\enot\enot\meta{A}}\ni{(b)-(bbbb)}
  \have{bot}{\ered}\ne{nna, na}
  \close
  \have{B}{\meta{B}}\ip{nb-(bot)}
\end{fitchproof}
Observe que, como adicionamos uma suposi\c c\~ao na parte superior e conclus\~oes adicionais dentro das subprovas, os n\'umeros das linhas mudam. Voc\^e pode ter que aceitar isso por enquanto at\'e entender o que est\'a acontecendo.

%%%%%% ——— - - - ——  30.6  Derivacao das regras de De Morgan ___________
\section{Deriva\c c\~ao das regras de De Morgan}
Aqui est\'a uma demonstra\c c\~ao de como poder\'iamos derivar a primeira regra de De Morgan:
 
 	\begin{fitchproof}
		\have[m]{nab}{\enot (\meta{A} \eand \meta{B})}
		\open
			\hypo[k]{a}{\meta{A}}
			\open
				\hypo{b}{\meta{B}}
				\have{ab}{\meta{A} \eand \meta{B}}\ai{a,b}
				\have{nab1}{\ered}\ne{nab, ab}
			\close
			\have{nb}{\enot \meta{B}}\ni{b-nab1}
			\have{dis}{\enot\meta{A} \eor \enot \meta{B}}\oi{nb}
		\close
		\open
			\hypo{na1}{\enot \meta{A}}
			\have{dis1}{\enot\meta{A} \eor \enot \meta{B}}\oi{na1}
		\close
		\have{con}{\enot \meta{A} \eor \enot \meta{B}}\tnd{a-dis, na1-dis1}
	\end{fitchproof}
E agora, veremos como poder\'iamos derivar a segunda regra de De Morgan:
 	\begin{fitchproof}
		\have[m]{nab}{\enot \meta{A} \eor \enot \meta{B}}
		\open
			\hypo[k]{ab}{\meta{A} \eand \meta{B}}
			\have{a}{\meta{A}}\ae{ab}
			\have{b}{\meta{B}}\ae{ab}
			\open
				\hypo{na}{\enot \meta{A}}
				\have{c1}{\ered}\ne{na, a}
			\close
			\open
				\hypo{nb}{\enot \meta{B}}
				\have{c2}{\ered}\ne{nb, b}
			\close
			\have{con2}{\ered}\oe{nab, na-c1, nb-c2}
		\close
		\have{nab}{\enot (\meta{A} \eand \meta{B})}\ni{ab-con2}
	\end{fitchproof}
 
Demonstra\c c\~oes semelhantes podem ser apresentadas, explicando como poder\'iamos derivar a terceira e a quarta regra de De Morgan. Estas s\~ao deixadas como exerc\'icios.

%%%%%% ---------------------------CAP  30   EXECICIOS  -----------------------------------------------  
\practiceproblems

\problempart
Forne\c ca esquemas de prova que justifiquem a adi\c c\~ao da terceira e quarta regras de De Morgan como regras derivadas.

\

\problempart
As provas que voc\^e ofereceu em resposta aos exerc\'icios dos cap\'itulos  \ref{s:Further} e \ref{s:ProofTheoreticConcepts} usavam regras derivadas. Substitua o uso de regras derivadas, nessas provas, por apenas regras b\'asicas. Voc\^e encontrar\'a algumas `repeti\c c\~oes' nas provas resultantes; nesses casos, apresentar uma prova simplificada usando apenas regras b\'asicas. (Isso lhe dar\'a uma id\'eia, do poder das regras derivadas e de como todas as regras interagem.)

\

\problempart
D\^e uma prova para $\meta{A} \eor \enot\meta{A}$. Em seguida, fa\c ca uma prova que \emph{use apenas as regras b\'asicas}.

\

\problempart
Mostre que se voc\^e tivesse LEM como regra b\'asica, poderia justificar IP como regra derivada. Ou seja, suponha que voc\^e tenha a prova:
\begin{fitchproof}
  \open
  \hypo[m]{a}{\enot\meta{A}}
  \have[\ ]{aa}{\dots}
  \have[n]{aaa}{\ered}
  \close
\end{fitchproof}
Como voc\^e pode usar isto para provar \meta{A} sem usar IP, mas usando
LEM, bem como todas as outras regras b\'asicas?

\

\problempart
D\^e uma prova da primeira regra de De Morgan, mas usando apenas as regras b\'asicas, em particular,  \emph{sem} usar o LEM. (Obviamente, voc\^e pode combinar a prova usando LEM com a prova  \emph{do}~LEM. Tente encontrar uma prova diretamente.)

%%%%%% ----------------------   CPA 31  -   Correcao e completude  --------------------------

\chapter{Corre\c c\~ao e completude}
\label{sec:soundness_and_completeness}

No cap\'itulo \ref{s:ProofTheoreticConcepts}, vimos que poder\'iamos usar deriva\c c\~oes para testar os mesmos conceitos testados antes com tabelas de verdade. Poder\'iamos, al\'em de usar deriva\c c\~oes para provar que um argumento \'e v\'alido, tamb\'em poder\'iamos us\'a-las para testar se uma senten\c ca \'e uma tautologia ou se um par de senten\c cas \'e equivalente. Tamb\'em come\c camos a usar o roleta \'unica da mesma maneira que usamos a roleta  dupla.  Se pud\'essemos provar que \meta{A} era uma tautologia com uma tabela de verdade,  escrever\'iamos  $\entails \meta{A}$, e se pud\'essemos prov\'a-la usando uma deriva\c c\~ao, escrever\'iamos $\proves \meta{A}.$ 

Voc\^e pode ter se perguntado naquele momento se os dois tipos de roletas sempre funcionavam da mesma maneira. Se voc\^e pode mostrar que \meta{A} \'e uma tautologia usando tabelas de verdade, tamb\'em pode sempre mostrar que \'e um teorema usando uma deriva\c c\~ao? O inverso \'e verdadeiro? Essas coisas tamb\'em s\~ao verdadeiras para argumentos v\'alidos e pares de senten\c cas equivalentes? Como se v\^e, a resposta para todas essas perguntas e muitas outras como essas \'e sim. Podemos mostrar isso definindo todos esses conceitos separadamente e depois provar que eles s\~ao equivalentes.  Isto \'e, imaginamos que realmente temos duas no\c c\~oes de validade, validade$_{\entails}$ e validade$_{\proves}$ e, em seguida, mostramos que os dois conceitos sempre funcionam da mesma maneira.


Para come\c car, precisamos definir todos os nossos conceitos l\'ogicos separadamente para tabelas de verdade e  para deriva\c c\~oes. Muito deste trabalho j\'a foi feito.  Manuseamos com todas as defini\c c\~oes de tabela de verdade no cap\'itulo \ref{s:SemanticConcepts}. Tamb\'em j\'a fornecemos defini\c c\~oes sint\'aticas para tautologias (teoremas) e pares de senten\c cas logicamente equivalentes. As outras defini\c c\~oes seguem naturalmente. Para a maioria das propriedades l\'ogicas, podemos test\'a-las usando deriva\c c\~oes, e aquelas que n\~ao podemos testar diretamente podem ser definidas em termos dos conceitos que podemos definir.

Por exemplo, definimos um teorema como uma senten\c ca que pode ser derivada sem quaisquer premissas (p.~\pageref{def:syntactic_tautology_in_sl}). Como a nega\c c\~ao de uma contradi\c c\~ao \'e uma tautologia, podemos definir uma \define{CONTRADI\c C\~AO SINT\'ATICA NA LVF} \label{def:syntactic_contradiction_in_sl} como uma senten\c ca cuja nega\c c\~ao pode ser derivada sem quaisquer premissas. A defini\c c\~ao sint\'atica de uma senten\c ca contingente \'e um pouco diferente. N\~ao temos nenhum m\'etodo pr\'atico e finito para provar que uma senten\c ca \'e contingente usando deriva\c c\~oes, da mesma maneira que fizemos usando tabelas de verdade. Portanto, precisamos nos contentar em definir "senten\c ca contingente" negativamente. Uma senten\c ca \'e \define{{SINTATICAMENTE CONTINGENTE NA LVF}} \label{def:syntactically_contingent_in_sl} se ela  n\~ao for um teorema ou uma contradi\c c\~ao. 
 

Um  conjunto de senten\c cas \'e \define{DEDUTIVAMENTE INCONSISTENTE NA LVF} \label{def:syntactically_inconsistent_ in_sl}  se e somente se pode-se derivar uma contradi\c c\~ao dele. A consist\^encia, por outro lado, \'e como conting\^encia na medida em que n\~ao temos um m\'etodo finito pr\'atico para test\'a-la diretamente. Ent\~ao, novamente, temos que definir um termo negativamente. Um  conjunto de senten\c cas \'e \define{DEDUTIVAMENTE CONSISTENTE NA LVF} \label{def:syntactically consistent in SL} se e somente se ele n\~ao for dedutivamente inconsistente.
    
Finalmente, um argumento \'e  \define{DEDUTIVAMENTE V\'ALIDO NA LVF} \label{def:syntactically_valid_in_SL}se e somente se houver uma deriva\c c\~ao de sua conclus\~ao a partir de suas premissas. Todas essas defini\c c\~oes s\~ao apresentadas na Tabela \ref{table:truth_tables_or_derivations}.

\begin{sidewaystable}\small
\tabulinesep=1ex
\begin{tabu}{X[.5,c,m] ||X[1,l,m] |X[1,l,m]}
\textbf{Conceito} 		&	\textbf{Defini\c c\~ao (sem\^antica): tabela de verdade} 	&	\textbf{ Defini\c c\~ao  (sint\'atica):  teoria da prova} \\ \hline \hline

Tautologia  &	Uma senten\c ca cuja tabela de verdade s\'o tem Vs sob o conectivo principal  & Uma senten\c ca que pode ser derivada sem nenhuma premissa	 \\ \hline
 
Contradi\c c\~ao		&	Uma senten\c ca cuja tabela de verdade s\'o tem Fs sob o conectivo principal  &	Uma senten\c ca cuja nega\c c\~ao pode ser derivada sem quaisquer premissas\\ \hline

Senten\c ca contingente	&	Uma senten\c ca cuja tabela de verdade cont\'em Vs e Fs sob o  conectivo principal & Uma senten\c ca que n\~ao \'e um teorema nem uma contradi\c c\~ao \\ \hline

Senten\c cas equivalentes  &	As colunas sob os conectivos principais s\~ao id\^enticas & As senten\c cas podem ser derivadas uma da outra	\\ \hline

Senten\c cas  insatisfat\'orias / inconsistentes	&	Senten\c cas que n\~ao possuem uma \'unica linha na tabela de verdade, onde todas s\~ao verdadeiras	& Senten\c cas a partir das quais se pode derivar uma contradi\c c\~ao \\ \hline

Senten\c cas  satisfat\'orias  / consistentes	&	Senten\c cas que tenham pelo menos uma linha na tabela de verdade onde elas todas s\~ao verdadeiras & Senten\c cas  a partir das quais n\~ao se pode derivar uma contradi\c c\~ao.	\\ \hline

Argumento v\'alido 		&	Um argumento cuja tabela de verdade n\~ao tem  nenhuma linha  na qual  tem Vs sob todos os conectivos principais das premissas e F sob o conectivo principal da conclus\~ao  & Um argumento em que se pode derivar a conclus\~ao a partir das premissas	\\ 
\end{tabu}
\caption{Duas maneiras de definir conceitos l\'ogicos.}
\label{table:truth_tables_or_derivations}
\end{sidewaystable}


Todos os nossos conceitos foram definidos agora sem\^antica e sintaticamente. Como podemos provar que essas defini\c c\~oes sempre funcionam da mesma maneira? Uma prova completa aqui vai muito al\'em do escopo deste livro. No entanto, podemos fazer um esbo\c co de como ela seria. Vamos nos concentrar em mostrar que as duas no\c c\~oes de validade s\~ao equivalentes. A partir disso, os outros conceitos seguir\~ao rapidamente. A prova vai em duas dire\c c\~oes. Primeiro,  mostraremos que tudo que \'e sintaticamente v\'alido tamb\'em \'e semanticamente v\'alido. Em outras palavras, tudo o que podemos provar usando deriva\c c\~oes tamb\'em pode ser comprovado usando tabelas de verdade. Simbolicamente,  queremos mostrar que  v\'alido$_{\proves}$ implica v\'alido$_{\entails}$. Depois, mostraremos a outra  dire\c c\~ao, v\'alido$_{\entails}$ implica v\'alido$_{\proves}$

  
%%%%%% ---------------CORRECAO  ???????-----------------  

\newglossaryentry{correcao}
{
name=correcao,
description={A property held by logical systems if and only if $\proves $ implies $\entails $}
}

Mostrar que $\proves $ implica  $\entails $  \'e  o problema da \define{\gls{correcao}}. \label{def:soundness} Um sistema de prova \'e  \define{CORRETO} se n\~ao houver deriva\c c\~oes de argumentos que possam ser mostrados inv\'alidos pelas tabelas de verdade. 
 \label{def_Soundness} 

Demonstrar que o sistema de prova \'e correto exigiria mostrar que  \emph{qualquer} prova poss\'ivel \'e a prova de um argumento v\'alido. N\~ao seria suficiente ter sucesso ao tentar provar muitos argumentos v\'alidos e falhar ao tentar provar argumentos inv\'alidos.

A prova que iremos esbo\c car depende do fato de que inicialmente definimos uma senten\c ca da LVF usando uma defini\c c\~ao indutiva (ver p.~\pageref{TFLsentences}). Tamb\'em poder\'iamos ter usado defini\c c\~oes indutivas para definir uma prova na LVF e uma tabela de verdade \nix{Later this will be a truth assignment}(mas n\~ao o fizemos.)  Se tiv\'essemos essas defini\c c\~oes, poder\'iamos usar uma \emph{prova indutiva} para mostrar a corre\c c\~ao da LVF. Uma prova indutiva funciona da mesma maneira que uma defini\c c\~ao indutiva. Com a defini\c c\~ao indutiva, identificamos um grupo de elementos b\'asicos que foram estipulados como exemplos da coisa que est\'avamos tentando definir. No caso de uma senten\c ca da LVF, a classe base foi o conjunto de letras sentenciais $A$, $B$, $C$, \dots. 

Apenas anunciamos que existiam essas senten\c cas. O segundo passo de uma defini\c c\~ao indutiva \'e dizer que qualquer coisa constru\'ida a partir da sua classe base usando certas regras tamb\'em conta como um exemplo do que voc\^e est\'a definindo. No caso da defini\c c\~ao de uma senten\c ca, as regras correspondiam aos cinco conectivos sentenciais (ver  p.~\pageref{TFLsentences}).Uma vez  estabelecida uma defini\c c\~ao indutiva, voc\^e pode us\'a-la para mostrar que todos os membros da classe que voc\^e definiu possuem uma determinada propriedade. Voc\^e simplesmente prova que a propriedade \'e verdadeira para os membros da classe base e depois prova que as regras para estender a classe base n\~ao alteram a propriedade. Isto \'e o que significa dar uma prova indutiva.
 
 Mesmo que n\~ao tenhamos uma defini\c c\~ao indutiva de prova na LVF, podemos esbo\c car como seria uma prova indutiva da corre\c c\~ao da LVF. Imagine uma classe base de provas de uma linha, uma para cada uma das nossas onze regras de infer\^encia. Os membros dessa classe seriam da forma $\meta{A}, \meta{B} \proves  \meta{A} \eand \meta{B}$; $\meta{A} \eand \meta{B} \proves \meta{A}$; $\meta{A} \eor \meta{B}, \enot\meta{A} \proves  \meta{B}$ \ldots{} etc. Como algumas regras t\^em duas formas diferentes, ter\'iamos que adicionar alguns membros a essa classe base, por exemplo $\meta{A} \eand \meta{B} \proves  \meta{B}$.  Observe que essas s\~ao todas declara\c c\~oes na metalinguagem. A prova  que a LVF \'e correta n\~ao faz parte da LVF, porque a LVF n\~ao tem o poder de falar sobre si mesma.

Voc\^e pode usar as tabelas de verdade para mostrar que cada uma dessas provas de uma linha  nesta classe base \'e v\'alida$_{\entails}$. Por exemplo, a prova de $\meta{A}, \meta{B} \proves \meta{A} \eand \meta{B}$ corresponde a uma tabela de verdade que mostra, $\meta{A}, \meta{B} \entails  \meta{A} \eand \meta{B}$. Isso estabelece a primeira parte de nossa prova indutiva.  

O pr\'oximo passo \'e mostrar que a adi\c c\~ao de linhas em qualquer prova nunca transformar\'a uma prova v\'alida$_{\entails}$ em uma inv\'alida$_{\entails}$. Precisar\'iamos fazer isso para cada uma das nossas onze regras b\'asicas de infer\^encia. Assim, por exemplo, para  \eand{I} precisamos mostrar que, para qualquer prova $\meta{A}_{1}$, \dots, $\meta{A}_{n} \proves  \meta {B}$ adicionando uma linha onde usamos a  regra \eand{I} para inferir $\meta{C} \eand \meta{D}$, onde $\meta{C} \eand \meta{D}$ pode ser legitimamente derivada de $\meta{A}_{1}$, \dots, $\meta{A}_{n}$,~$\meta{B}$,  n\~ao transformaria uma prova v\'alida em uma prova inv\'alida. Mas aten\c c\~ao, se podemos derivar legitimamente $\meta{C} \eand \meta{D}$ dessas premissas, ent\~ao $\meta{C}$ e $\meta{D}$  j\'a estavam dispon\'iveis na prova. Elas j\'a estavam entre $\meta{A}_{1}$, \dots, $\meta{A}_{n}$,~$\meta {B}$, ou foram legitimamente derivadas delas.  Assim sendo, qualquer linha da tabela  de verdade na qual as premissas s\~ao verdadeiras deve ser uma linha da tabela de verdade na qual \meta{C} e \meta{D} s\~ao verdadeiras. De acordo com a tabela de verdade caracter\'istica de \eand, isso significa que $\meta{C} \eand \meta{D}$ tamb\'em \'e verdadeira nessa linha. Portanto,  $\meta{C} \eand \meta{D}$ segue validamente a partir das premissas. Isso significa que o uso da regra {\eand}E rule para estender uma prova v\'alida produz outra prova v\'alida.


Para mostrar que o sistema de prova \'e coreto, precisar\'iamos mostrar isso para as outras regras de infer\^encia. Como as regras derivadas s\~ao consequ\^encias das regras b\'asicas, seria suficiente fornecer argumentos semelhantes para as 11 outras regras b\'asicas. Este exerc\'icio tedioso est\'a al\'em do escopo deste livro.


Assim, mostramos que $\meta{A} \proves  \meta{B}$ implica $\meta{A} \entails \meta{B}.$ A outra dire\c c\~ao seria pensar que \emph{todo} argumento que pode ser mostrado v\'alido usando tabelas de verdade tamb\'em pode ser mostrado usando uma deriva\c c\~ao.

\newglossaryentry{completude}
{
name=completude,
description={A property held by logical systems if and only if $\entails $ implies $\proves $}
}

Esse \'e o problema da completude. Um sistema de prova tem a propriedade da   \define{\gls{completude}} \label{def:completeness} se e somente se houver uma deriva\c c\~ao de todo argumento semanticamente v\'alido. Provar que um sistema \'e completo \'e geralmente mais dif\'icil do que provar que \'e correto. Provar que um sistema \'e correto significa mostrar que todas as regras do seu sistema de prova funcionam da maneira como deveriam.
Mostrar que um sistema \'e completo significa mostrar que voc\^e incluiu \emph{todas} as regras necess\'arias e que n\~ao deixou nada de fora. Mostrar isso est\'a al\'em do escopo deste livro. O ponto importante \'e que, felizmente, o sistema de prova da LVF \'e coreto e completo. Este n\~ao \'e o caso de todos os sistemas de prova ou todas as linguagens formais. Por ser o caso da LVF, podemos optar por fornecer provas ou fornecer tabelas de verdade, o que for mais f\'acil para a tarefa em quest\~ao.

Agora que sabemos que o m\'etodo da tabela de verdade \'e intercambi\'avel com o m\'etodo de deriva\c c\~oes, voc\^e pode escolher qual m\'etodo deseja usar para qualquer problema. Os alunos geralmente preferem usar tabelas de verdade, porque elas podem ser produzidas apenas mecanicamente, e isso parece 'mais f\'acil'. No entanto, j\'a vimos que as tabelas de verdade se tornam impossivelmente grandes com um pouco mais de letras sentenciais.
Por outro lado, existem algumas situa\c c\~oes em que o uso de provas simplesmente n\~ao \'e poss\'ivel. Definimos sintaticamente uma senten\c ca contingente como uma senten\c ca que n\~ao pode ser provada ser uma tautologia ou uma contradi\c c\~ao. N\~ao existe um modo pr\'atica de provar esse tipo de declara\c c\~ao negativa. Nunca saberemos se n\~ao existe alguma prova de que uma declara\c c\~ao \'e uma contradi\c c\~ao e ainda n\~ao a encontramos. N\~ao temos nada a fazer nessa situa\c c\~ao, se n\~ao recorrer a tabelas de verdade. Da mesma forma, podemos usar deriva\c c\~oes para provar que duas senten\c cas s\~ao equivalentes, mas e se quisermos provar que elas \emph{n\~ao} s\~ao equivalentes? N\~ao temos como provar que nunca encontraremos a prova relevante. Ent\~ao, temos que voltar \`as tabelas de verdade de novo.

A tabela \ref{table.ProofOrModel} resume quando \'e melhor usar provas e quando \'e melhor usar tabelas de verdade. 

\begin{table}\small
\tabulinesep=1ex
\begin{tabu}{X[.7,c,m] ||X[1,l,m] |X[1,l,m]}
\textbf{Propriedade l\'ogica} 	&	\textbf{Para provar que est\'a presente} 	&	\textbf{Para provar que est\'a ausente} \\ \hline \hline
Ser um teorema  &  Derivar a senten\c ca 	& Encontrar uma linha falsa na tabela de verdade para a senten\c ca \\ \hline
Ser uma contradi\c c\~ao  &  Derivar a nega\c c\~ao da senten\c ca   &  Encontrar uma linha verdadeira na tabela de verdade para a senten\c ca\\ \hline
Conting\^encia 			&  Encontrar uma linha falsa e uma linha verdadeira na tabela de verdade para a senten\c ca & Provar a senten\c ca ou sua nega\c c\~ao \\ \hline

Equival\^encia	& Derivar cada senten\c ca da outra 	 & Encontrar uma linha na tabelas de verdade  para a senten\c ca onde elas tenham valores diferentes\\ \hline
Consist\^encia		& Encontrar uma linha na tabela de verdade para a senten\c ca em que todas elas s\~ao verdadeiras & Derivar uma contradi\c c\~ao das senten\c cas\\ \hline
Validade				&  Derivar a conclus\~ao a partir das premissas & Encontrar uma linha na tabela de verdade onde as premissas s\~ao todas verdadeiras e a conclus\~ao \'e falsa. \\ 
\end{tabu}
\caption{Quando fornecer uma tabela de verdade e quando fornecer uma prova.}
\label{table.ProofOrModel}
\end{table}

 %%%%%% ---------------------------CAP  31   EXECICIOS  -----------------------------------------------  
 
\practiceproblems
\noindent\problempart Em cada um dos casos abaixo, use uma  deriva\c c\~ao ou uma tabela de verdade para mostrar que: 
\begin{enumerate}%[label=(\arabic*)]
\item  A senten\c ca $A \eif [((B \eand C) \eor D) \eif A]$  \'e um teorema.
\item  A senten\c ca $A \eif (A \eif B)$  n\~ao \'e um teorema.
\item  A senten\c ca $A \eif \enot{A}$ n\~ao \'e uma contradi\c c\~ao. 
\item  A senten\c ca $A \eiff \enot A$ \'e uma contradi\c c\~ao.  

\item  A senten\c ca $ \enot (W \eif (J \eor J)) $  \'e contingente.
\item  A senten\c ca $ \enot(X \eor (Y \eor Z)) \eor (X \eor (Y \eor Z))$  n\~ao \'e contingente
 \item  A senten\c ca $B \eif \enot S$  \'e equivalente \`a senten\c ca $\enot \enot B \eif \enot S$.
\item  A senten\c ca $ \enot (X \eor O) $ n\~ao \'e equivalente \`a senten\c ca $X \eand O$.
\item  As senten\c cas $\enot(A \eor B)$, $C$, $C \eif A$  s\~ao conjuntamente inconsistentes
\item  As senten\c cas $\enot(A \eor B)$, $\enot{B}$, $B \eif A$ s\~ao conjuntamente consistentes.
\item  O argumento $\enot(A \eor (B \eor C)) $ \therefore $ \enot{C}$ \'e v\'alido.
\item  O argumento $\enot(A \eand (B \eor C))$ \therefore $ \enot{C}$ \'e  inv\'alido
\end{enumerate}


\noindent\problempart Em cada um dos casos abaixo, use uma  deriva\c c\~ao ou uma tabela de verdade para mostrar que:
\begin{enumerate}%[label=(\arabic*)]
\item A senten\c ca $A \eif (B \eif A)$ \'e um teorema
\item A senten\c ca$\enot (((N \eiff Q) \eor Q) \eor N)$ n\~ao \'e um teorema.
\item A senten\c ca $ Z \eor (\enot Z \eiff Z) $ \'e contingente.
\item A senten\c ca $ (L \eiff ((N \eif N) \eif L)) \eor H $ n\~ao \'e contingente.
\item A senten\c ca $ (A \eiff A) \eand (B \eand \enot B)$ \'e uma contradi\c c\~ao.
\item A senten\c ca$ (B \eiff (C \eor B)) $ n\~ao \'e uma contradi\c c\~ao. 
\item A senten\c ca$ ((\enot X \eiff X) \eor X) $  \'e equivalente \`a senten\c ca $X$.
\item A senten\c ca $F \eand (K \eand R) $ n\~ao  \'e equivalente \`a senten\c ca. $ (F \eiff (K \eiff R)) $.
\item As senten\c cas $ \enot (W \eif W)$, $(W \eiff W) \eand W$, $E \eor (W \eif \enot (E \eand W))$ s\~ao conjuntamente inconsistentes. 

\item As senten\c cas  $\enot R \eor C $, $(C \eand R) \eif \enot R$, $(\enot (R \eor R) \eif R) $ s\~ao conjuntamente consistentes.
\item O argumento $\enot \enot (C \eiff \enot C), ((G \eor C) \eor G) \therefore ((G \eif C) \eand G) $ \'e v\'alido.
\item O argumento $ \enot \enot L,  (C \eif \enot L) \eif C) \therefore \enot C$  \'e  inv\'alido
\end{enumerate}

